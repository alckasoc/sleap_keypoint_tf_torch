{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "df6ec7bf027647e39a970d568b14ccdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c2a93d67931046f3a7108d7d46ee2733",
              "IPY_MODEL_2d98f8bd8f124badbb20943dafe69803"
            ],
            "layout": "IPY_MODEL_70454460df1845e4878424c24923a011"
          }
        },
        "c2a93d67931046f3a7108d7d46ee2733": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b6c6a9622054d6f81ee7e5445298d1d",
            "placeholder": "​",
            "style": "IPY_MODEL_c532a7934dff43f7826109776336270c",
            "value": "0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "2d98f8bd8f124badbb20943dafe69803": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6878df96cb9e4938ae524857b25442a8",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d1610903f88f48da8cacb099ad7764ea",
            "value": 1
          }
        },
        "70454460df1845e4878424c24923a011": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b6c6a9622054d6f81ee7e5445298d1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c532a7934dff43f7826109776336270c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6878df96cb9e4938ae524857b25442a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1610903f88f48da8cacb099ad7764ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bf3d7070064f4a15b41ff5922bc1624f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_48acf8047769425792af037153ebfb3c",
              "IPY_MODEL_ba4ddbde288c4adba7bb954367996799"
            ],
            "layout": "IPY_MODEL_da12f08b508745dc9d98a8267de9a811"
          }
        },
        "48acf8047769425792af037153ebfb3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5009a9e6777f4b9091e884a6fbc336a2",
            "placeholder": "​",
            "style": "IPY_MODEL_bb81174b21b3439d957b3e0b9fde4c0e",
            "value": "0.001 MB of 0.011 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "ba4ddbde288c4adba7bb954367996799": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_976326c6ce004f14b3544317c1602a6a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ce8f575b05ce4388871b079d09bb6282",
            "value": 0.10581590327420351
          }
        },
        "da12f08b508745dc9d98a8267de9a811": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5009a9e6777f4b9091e884a6fbc336a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb81174b21b3439d957b3e0b9fde4c0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "976326c6ce004f14b3544317c1602a6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce8f575b05ce4388871b079d09bb6282": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Below are links to resources related to this notebook:\n",
        "* [W&B Project](https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab?workspace=user-vincenttu)\n",
        "* [GitHub](https://github.com/alckasoc/sleap_keypoint_tf_torch)"
      ],
      "metadata": {
        "id": "TvWGTvH2gxDa"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeeqrLbdupmE"
      },
      "source": [
        "# Install SLEAP\n",
        "Don't forget to set **Runtime** -> **Change runtime type...** -> **GPU** as the accelerator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYxJ2rJOMW8B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfe5ffe5-a47a-405b-9249-bf77bc54d714"
      },
      "source": [
        "!pip install sleap -qqq\n",
        "!pip install albumentations -qqq\n",
        "!pip install nvidia-ml-py3 -qqq"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.4/64.4 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.5/60.5 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.9/84.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m904.1/904.1 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.9/228.9 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.3/214.3 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.2/149.2 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.9/131.9 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.2/88.2 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m498.1/498.1 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.1/156.1 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m832.9/832.9 kB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.3/462.3 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.9/196.9 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.1/109.1 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m97.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.6/485.6 kB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pykalman (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for jsmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "flax 0.6.9 requires rich>=11.1, but you have rich 10.16.1 which is incompatible.\n",
            "tensorflow-datasets 4.9.2 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jftAOyvvuQeh",
        "outputId": "1247c42d-fd0b-4d03-a323-1b0413ed3390"
      },
      "source": [
        "import os\n",
        "import gc\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "import collections\n",
        "from typing import Sequence, Tuple, Text, Union, Optional, List\n",
        "\n",
        "import nvidia_smi\n",
        "\n",
        "import numpy as np\n",
        "import albumentations as A\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import sleap\n",
        "\n",
        "sleap.versions()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SLEAP: 1.3.0\n",
            "TensorFlow: 2.8.4\n",
            "Numpy: 1.22.4\n",
            "Python: 3.10.11\n",
            "OS: Linux-5.10.147+-x86_64-with-glibc2.31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb -qqq\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F31Z_dQfA3Hj",
        "outputId": "73dcf5c3-2ceb-4115-f753-41e5a8871217"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.3/203.3 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "PWl3cG1_9WTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "def get_vram():\n",
        "    nvidia_smi.nvmlInit()\n",
        "\n",
        "    deviceCount = nvidia_smi.nvmlDeviceGetCount()\n",
        "    for i in range(deviceCount):\n",
        "        handle = nvidia_smi.nvmlDeviceGetHandleByIndex(i)\n",
        "        info = nvidia_smi.nvmlDeviceGetMemoryInfo(handle)\n",
        "        output = (\"Device {}: {}, Memory : ({:.2f}% free): {} (total), {} (free), {} (used)\"\n",
        "              .format(i, nvidia_smi.nvmlDeviceGetName(handle), 100*info.free/info.total, \n",
        "                      info.total/(1024 ** 3), info.free/(1024 ** 3), info.used/(1024 ** 3)))\n",
        "\n",
        "    nvidia_smi.nvmlShutdown()\n",
        "\n",
        "    return output\n",
        "\n",
        "def get_param_count(model):\n",
        "  trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "  total_params = sum(p.numel() for p in model.parameters())\n",
        "  nontrainable_params = total_params - trainable_params\n",
        "\n",
        "  return trainable_params, nontrainable_params, total_params"
      ],
      "metadata": {
        "id": "X2ESLmrn9VnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 42\n",
        "seed_everything(seed)"
      ],
      "metadata": {
        "id": "2pEmfBalS51R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSdTJYOdu4L6"
      },
      "source": [
        "# Download training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDIF3RKdM86u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4f71fe5-fd24-49aa-999e-6ce834b86e33"
      },
      "source": [
        "!curl -L --output labels.slp https://storage.googleapis.com/sleap-data/datasets/wt_gold.13pt/tracking_split2/train.pkg.slp\n",
        "!ls -lah\n",
        "\n",
        "!curl -L --output val_labels.slp https://storage.googleapis.com/sleap-data/datasets/wt_gold.13pt/tracking_split2/val.pkg.slp\n",
        "!ls -lah"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  619M  100  619M    0     0  50.6M      0  0:00:12  0:00:12 --:--:-- 57.2M\n",
            "total 620M\n",
            "drwxr-xr-x 1 root root 4.0K May 12 04:39 .\n",
            "drwxr-xr-x 1 root root 4.0K May 12 04:31 ..\n",
            "drwxr-xr-x 4 root root 4.0K May 10 13:35 .config\n",
            "-rw-r--r-- 1 root root 620M May 12 04:39 labels.slp\n",
            "drwxr-xr-x 1 root root 4.0K May 10 13:36 sample_data\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 77.2M  100 77.2M    0     0  28.2M      0  0:00:02  0:00:02 --:--:-- 28.2M\n",
            "total 697M\n",
            "drwxr-xr-x 1 root root 4.0K May 12 04:39 .\n",
            "drwxr-xr-x 1 root root 4.0K May 12 04:31 ..\n",
            "drwxr-xr-x 4 root root 4.0K May 10 13:35 .config\n",
            "-rw-r--r-- 1 root root 620M May 12 04:39 labels.slp\n",
            "drwxr-xr-x 1 root root 4.0K May 10 13:36 sample_data\n",
            "-rw-r--r-- 1 root root  78M May 12 04:39 val_labels.slp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lugn7a_HC0Q"
      },
      "source": [
        "# Load the training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMkSIZrTHCMr",
        "outputId": "445f45e3-ea9f-46b9-a2de-c44c528f11f2"
      },
      "source": [
        "# SLEAP Labels files (.slp) can include the images as well as labeled instances and\n",
        "# other metadata for a project.\n",
        "labels = sleap.load_file(\"labels.slp\")\n",
        "labels = labels.with_user_labels_only()\n",
        "labels.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skeleton: Skeleton(description=None, nodes=[head, thorax, abdomen, wingL, wingR, forelegL4, forelegR4, midlegL4, midlegR4, hindlegL4, hindlegR4, eyeL, eyeR], edges=[thorax->head, thorax->abdomen, thorax->wingL, thorax->wingR, thorax->forelegL4, thorax->forelegR4, thorax->midlegL4, thorax->midlegR4, thorax->hindlegL4, thorax->hindlegR4, head->eyeL, head->eyeR], symmetries=[eyeL<->eyeR, wingL<->wingR, midlegL4<->midlegR4, forelegL4<->forelegR4, hindlegL4<->hindlegR4])\n",
            "Videos: ['labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp']\n",
            "Frames (user/predicted): 1,600/0\n",
            "Instances (user/predicted): 3,200/0\n",
            "Tracks: [Track(spawned_on=0, name='female'), Track(spawned_on=0, name='male')]\n",
            "Suggestions: 0\n",
            "Provenance: {}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's also do the same for the val labels.\n",
        "val_labels = sleap.load_file(\"val_labels.slp\")\n",
        "val_labels = val_labels.with_user_labels_only()\n",
        "val_labels.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sklyy8NWEyff",
        "outputId": "ab25b252-aaaa-4cae-8a93-f5f55836b322"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skeleton: Skeleton(description=None, nodes=[head, thorax, abdomen, wingL, wingR, forelegL4, forelegR4, midlegL4, midlegR4, hindlegL4, hindlegR4, eyeL, eyeR], edges=[thorax->head, thorax->abdomen, thorax->wingL, thorax->wingR, thorax->forelegL4, thorax->forelegR4, thorax->midlegL4, thorax->midlegR4, thorax->hindlegL4, thorax->hindlegR4, head->eyeL, head->eyeR], symmetries=[midlegL4<->midlegR4, hindlegL4<->hindlegR4, eyeL<->eyeR, forelegL4<->forelegR4, wingL<->wingR])\n",
            "Videos: ['val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp']\n",
            "Frames (user/predicted): 200/0\n",
            "Instances (user/predicted): 400/0\n",
            "Tracks: [Track(spawned_on=0, name='female'), Track(spawned_on=0, name='male')]\n",
            "Suggestions: 0\n",
            "Provenance: {}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EK8DDPHDHBr_",
        "outputId": "eb48e7f5-48a0-4758-df08-c40c3f654aad"
      },
      "source": [
        "# Labels are list-like containers whose elements are LabeledFrames\n",
        "print(f\"Number of labels: {len(labels)}\")\n",
        "\n",
        "labeled_frame = labels[0]\n",
        "labeled_frame"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of labels: 1600\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LabeledFrame(video=HDF5Video('labels.slp'), frame_idx=166050, instances=2)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pP5uXrU3HX6o",
        "outputId": "f8508d1b-9472-4c75-fcb6-01963732a2ff"
      },
      "source": [
        "# LabeledFrames are containers for instances that were labeled in a single frame\n",
        "instance = labeled_frame[0]\n",
        "instance"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Instance(video=Video(filename=labels.slp, shape=(66, 1024, 1024, 1), backend=HDF5Video), frame_idx=166050, points=[head: (491.6, 187.7), thorax: (474.4, 224.8), abdomen: (459.9, 262.2), wingL: (448.3, 271.7), wingR: (452.1, 273.5), forelegL4: (478.5, 175.9), forelegR4: (499.9, 177.9), midlegL4: (440.6, 216.4), midlegR4: (510.1, 242.7), hindlegL4: (437.2, 234.3), hindlegR4: (490.9, 266.7), eyeL: (477.5, 193.2), eyeR: (498.4, 201.2)], track=Track(spawned_on=0, name='female'))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "700fTPs4Hurg",
        "outputId": "fcd8de26-6bf2-424f-8777-7cf2bc1717ee"
      },
      "source": [
        "# They can be converted to numpy arrays where each row corresponds to the coordinates\n",
        "# of a different body part:\n",
        "pts = instance.numpy()\n",
        "pts"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "rec.array([[491.58118169, 187.72078779],\n",
              "           [474.3603939 , 224.80196948],\n",
              "           [459.90098474, 262.16236338],\n",
              "           [448.26137864, 271.72078779],\n",
              "           [452.08118169, 273.54059084],\n",
              "           [478.5       , 175.90098474],\n",
              "           [499.94157558, 177.90098474],\n",
              "           [440.58118169, 216.3603939 ],\n",
              "           [510.12177253, 242.72078779],\n",
              "           [         nan,          nan],\n",
              "           [490.90098474, 266.72078779],\n",
              "           [477.54059084, 193.16236338],\n",
              "           [498.40098474, 201.18019695]],\n",
              "          dtype=float64)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vYsPusvviiu"
      },
      "source": [
        "# Setup training data generation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def update_not_shown_nodes(not_shown_nodes, node_names, new_nodes):\n",
        "  nodes_not_in_aug = np.array(list(set(node_names).difference(set(new_nodes))))\n",
        "  not_shown_in_aug_or_original_ind = np.in1d(node_names, nodes_not_in_aug).nonzero()[0]\n",
        "  not_shown_nodes[not_shown_in_aug_or_original_ind] = True \n",
        "\n",
        "  return not_shown_nodes\n",
        "\n",
        "\n",
        "def update_kp(kp, not_shown_nodes, node_names, new_nodes):\n",
        "  shown_after_aug_ind = np.in1d(node_names, new_nodes).nonzero()[0]\n",
        "  shown_ind = np.in1d(not_shown_nodes, True).nonzero()[0]\n",
        "\n",
        "  assert len(shown_after_aug_ind) == kp.shape[0]\n",
        "\n",
        "  kp_ = np.zeros((len(node_names), 2))\n",
        "  kp_[shown_after_aug_ind] = kp\n",
        "  kp_[shown_ind] = 0\n",
        "\n",
        "  return kp_\n",
        "\n",
        "\n",
        "def make_grid_vectors(\n",
        "    image_height: int, image_width: int, output_stride: int = 1):\n",
        "\n",
        "    xv = torch.arange(0, image_width, step=output_stride).to(torch.float32)\n",
        "    yv = torch.arange(0, image_height, step=output_stride).to(torch.float32)\n",
        "    return xv, yv\n",
        "\n",
        "def make_confmaps(\n",
        "    points: torch.Tensor, xv: torch.Tensor, yv: torch.Tensor, sigma: float):\n",
        "\n",
        "    x = torch.reshape(points[:, 0], (1, 1, -1))\n",
        "    y = torch.reshape(points[:, 1], (1, 1, -1))\n",
        "    cm = torch.exp(\n",
        "        -((torch.reshape(xv, (1, -1, 1)) - x) ** 2 + (torch.reshape(yv, (-1, 1, 1)) - y) ** 2)\n",
        "        / (2 * sigma ** 2)\n",
        "    )\n",
        "\n",
        "    # Replace NaNs with 0.\n",
        "    cm = torch.where(torch.isnan(cm), 0.0, cm)\n",
        "    return cm\n",
        "\n",
        "def get_bbox_coords_on_centroid(anchor_coords, crop_size, img_size):\n",
        "    (cx, cy) = anchor_coords\n",
        "\n",
        "    # [bottom left     top right]\n",
        "    # [  x1, y1,         x2, y2 ]\n",
        "    bbox = [\n",
        "        max(-crop_size / 2 + cx, 0),\n",
        "        max(-crop_size / 2 + cy, 0),\n",
        "        min(crop_size / 2 + cx, img_size[0]),\n",
        "        min(crop_size / 2 + cy, img_size[1])\n",
        "    ]\n",
        "\n",
        "    return bbox\n",
        "\n",
        "# My refactored version of this dataset generator.\n",
        "class DataGenerator(Dataset):\n",
        "    def __init__(self, \n",
        "      labels, \n",
        "      img_size=160,\n",
        "      anchor_name=\"thorax\",\n",
        "      sigma=1.5,\n",
        "      output_stride=2,\n",
        "      rot_range=(-180, 180),\n",
        "      is_train=True\n",
        "    ):\n",
        "        self.labels = labels.with_user_labels_only()\n",
        "        self.labels.remove_empty_instances(keep_empty_frames=False)\n",
        "\n",
        "        self.indices = []\n",
        "        for frame_idx, l in enumerate(self.labels):\n",
        "          inst_indices = np.arange(0, len(l.instances)).tolist()\n",
        "          self.indices.extend([(frame_idx, i) for i in inst_indices])\n",
        "\n",
        "        self.img_size = img_size\n",
        "\n",
        "        assert anchor_name in self.labels.skeleton.node_names\n",
        "        self.anchor_name = anchor_name\n",
        "\n",
        "        # Assuming 1 skeleton.\n",
        "        assert len(labels.skeletons) == 1\n",
        "        self.node_names = labels.skeletons[0].node_names\n",
        "\n",
        "        self.sigma = sigma\n",
        "        self.output_stride = output_stride\n",
        "        self.rot_range = rot_range\n",
        "\n",
        "        self.tfm = A.Compose([\n",
        "            A.Rotate(limit=list(self.rot_range), p=0.5)\n",
        "        ], keypoint_params=A.KeypointParams(format='xy', label_fields=['class_labels']))\n",
        "\n",
        "        self.xv, self.yv = make_grid_vectors(\n",
        "            image_height=self.img_size, \n",
        "            image_width=self.img_size, \n",
        "            output_stride=self.output_stride\n",
        "        )\n",
        "\n",
        "        self.is_train = is_train\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        frame_idx, inst_idx = self.indices[idx]\n",
        "        lf = self.labels[frame_idx]\n",
        "        instance = lf[inst_idx]\n",
        "        img = lf.image\n",
        "        kp = instance.numpy()\n",
        "\n",
        "        # NaNs to 0 and clip.\n",
        "        assert kp.shape == (len(self.node_names), 2)\n",
        "        not_shown_nodes = np.isnan(kp).any(axis=1)\n",
        "        kp = np.nan_to_num(kp, nan=0)\n",
        "        kp = np.concatenate((np.clip(kp[:, :1], 0, img.shape[1]), \n",
        "                              np.clip(kp[:, 1:], 0, img.shape[0])), \n",
        "                            axis=1)\n",
        "\n",
        "        if self.is_train:\n",
        "            # Apply augmentations.\n",
        "            output = self.tfm(image=img, keypoints=kp, class_labels=self.node_names)\n",
        "            img, kp, new_nodes = output[\"image\"], np.array(output[\"keypoints\"]), output[\"class_labels\"]\n",
        "\n",
        "            # Update not_shown_nodes and kp.\n",
        "            not_shown_nodes = update_not_shown_nodes(not_shown_nodes, self.node_names, new_nodes)\n",
        "            kp = update_kp(kp, not_shown_nodes, self.node_names, new_nodes)\n",
        "\n",
        "        # Get bbox coordinate based on centroid.\n",
        "        bbox = get_bbox_coords_on_centroid(\n",
        "          kp[self.node_names.index(self.anchor_name)].tolist(), \n",
        "          self.img_size, img.shape[:2]\n",
        "        )\n",
        "\n",
        "        # Crop and pad.\n",
        "        x1, y1, x2, y2 = bbox\n",
        "        tfm_crop = A.Compose([\n",
        "          A.Crop(int(round(x1)), int(round(y1)), int(round(x2)), int(round(y2))),\n",
        "          A.PadIfNeeded(min_height=self.img_size, min_width=self.img_size)\n",
        "        ], keypoint_params=A.KeypointParams(format='xy', label_fields=['class_labels']))\n",
        "\n",
        "        crop_kp = tfm_crop(image=img, keypoints=kp, class_labels=self.node_names)\n",
        "        crop, kp, new_nodes = crop_kp[\"image\"], np.array(crop_kp[\"keypoints\"]), crop_kp[\"class_labels\"]\n",
        "        crop = torch.Tensor(crop).permute(2, 0, 1)\n",
        "\n",
        "        # Update not_shown_nodes and kp.\n",
        "        not_shown_nodes = update_not_shown_nodes(not_shown_nodes, self.node_names, new_nodes)\n",
        "        kp = update_kp(kp, not_shown_nodes, self.node_names, new_nodes)\n",
        "        kp = torch.Tensor(kp)\n",
        "\n",
        "        # Get confidence map.\n",
        "        xv, yv = make_grid_vectors(\n",
        "          image_height=self.img_size, \n",
        "          image_width=self.img_size, \n",
        "          output_stride=self.output_stride\n",
        "        )\n",
        "\n",
        "        cm = make_confmaps(\n",
        "          points=kp, \n",
        "          xv=self.xv, \n",
        "          yv=self.yv, \n",
        "          sigma=self.sigma\n",
        "        )\n",
        "        cm = cm.permute(2, 0, 1)\n",
        "\n",
        "        return crop, cm"
      ],
      "metadata": {
        "id": "l8Q-1ehtVWbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yo95XzRKkba"
      },
      "source": [
        "# Setting up a neural network model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MaxPool2dWithSamePadding(nn.MaxPool2d):\n",
        "\n",
        "    def _calc_same_pad(self, i: int, k: int, s: int, d: int) -> int:\n",
        "        return max((math.ceil(i / s) - 1) * s + (k - 1) * d + 1 - i, 0)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        if self.padding == \"same\":\n",
        "            ih, iw = x.size()[-2:]\n",
        "\n",
        "            pad_h = self._calc_same_pad(i=ih, \n",
        "                                        k=self.kernel_size if type(self.kernel_size) is int else self.kernel_size[0], \n",
        "                                        s=self.stride if type(self.stride) is int else self.stride[0], \n",
        "                                        d=self.dilation if type(self.dilation) is int else self.dilation[0])\n",
        "            pad_w = self._calc_same_pad(i=iw, \n",
        "                                        k=self.kernel_size if type(self.kernel_size) is int else self.kernel_size[1], \n",
        "                                        s=self.stride if type(self.stride) is int else self.stride[1], \n",
        "                                        d=self.dilation if type(self.dilation) is int else self.dilation[1])\n",
        "\n",
        "            if pad_h > 0 or pad_w > 0:\n",
        "                x = F.pad(\n",
        "                    x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2]\n",
        "                )\n",
        "            self.padding = 0\n",
        "\n",
        "        return F.max_pool2d(x, self.kernel_size, self.stride,\n",
        "                                    self.padding, self.dilation, ceil_mode=self.ceil_mode,\n",
        "                                    return_indices=self.return_indices)\n",
        "\n",
        "def get_act_fn(activation: str) -> nn.Module:\n",
        "    activations = {\n",
        "        'relu': nn.ReLU(),\n",
        "        'sigmoid': nn.Sigmoid(),\n",
        "        'tanh': nn.Tanh()\n",
        "    }\n",
        "\n",
        "    return activations[activation]\n",
        "\n",
        "class SimpleConvBlock(nn.Module):\n",
        "    def __init__(self,\n",
        "        in_channels: int,\n",
        "        pool: bool = True,\n",
        "        pooling_stride: int = 2,\n",
        "        pool_before_convs: bool = False,\n",
        "        num_convs: int = 2,\n",
        "        filters: int = 32,\n",
        "        kernel_size: int = 3,\n",
        "        use_bias: bool = True,\n",
        "        batch_norm: bool = False,\n",
        "        activation: Text = \"relu\"\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.pool = pool\n",
        "        self.pooling_stride = pooling_stride\n",
        "        self.pool_before_convs = pool_before_convs\n",
        "        self.num_convs = num_convs\n",
        "        self.filters = filters\n",
        "        self.kernel_size = kernel_size\n",
        "        self.use_bias = use_bias\n",
        "        self.batch_norm = batch_norm\n",
        "        self.activation = activation\n",
        "\n",
        "        self.blocks = []\n",
        "        if pool and pool_before_convs:\n",
        "            self.blocks.append(\n",
        "                MaxPool2dWithSamePadding(\n",
        "                    kernel_size=2,\n",
        "                    stride=pooling_stride,\n",
        "                    padding=\"same\"\n",
        "                )\n",
        "            )\n",
        "\n",
        "        for i in range(num_convs):\n",
        "            self.blocks.append(\n",
        "                nn.Conv2d(\n",
        "                    in_channels=in_channels if i == 0 else filters,\n",
        "                    out_channels=filters,\n",
        "                    kernel_size=kernel_size,\n",
        "                    stride=1,\n",
        "                    padding=\"same\",\n",
        "                    bias=use_bias\n",
        "                )\n",
        "            )\n",
        "\n",
        "            if batch_norm:\n",
        "                self.blocks.append(\n",
        "                    nn.BatchNorm2d(filters)\n",
        "                )\n",
        "\n",
        "            self.blocks.append(\n",
        "                get_act_fn(activation)  \n",
        "            )\n",
        "\n",
        "\n",
        "        if pool and not pool_before_convs:\n",
        "            self.blocks.append(\n",
        "                MaxPool2dWithSamePadding(\n",
        "                    kernel_size=2,\n",
        "                    stride=pooling_stride,\n",
        "                    padding=\"same\"\n",
        "                )\n",
        "            )\n",
        "\n",
        "        self.blocks = nn.Sequential(*self.blocks)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.blocks(x)\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self,\n",
        "        in_channels: int = 3,\n",
        "        filters: int = 64,\n",
        "        down_blocks: int = 4, \n",
        "        filters_rate: Union[float, int] = 2,\n",
        "        current_stride: int = 2,\n",
        "        stem_blocks: int = 0,\n",
        "        convs_per_block: int = 2,\n",
        "        kernel_size: Union[int, Tuple[int, int]] = 3,\n",
        "        middle_block: bool = True,\n",
        "        block_contraction: bool = False\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.filters = filters\n",
        "        self.down_blocks = down_blocks\n",
        "        self.filters_rate = filters_rate\n",
        "        self.current_stride = current_stride\n",
        "        self.stem_blocks = stem_blocks\n",
        "        self.convs_per_block = convs_per_block\n",
        "        self.kernel_size = kernel_size\n",
        "        self.middle_block = middle_block\n",
        "        self.block_contraction = block_contraction\n",
        "\n",
        "        self.encoder_stack = nn.ModuleList([])\n",
        "        for block in range(down_blocks):\n",
        "            prev_block_filters = -1 if block==0 else block_filters\n",
        "            block_filters = int(\n",
        "                filters * (filters_rate ** (block + stem_blocks))\n",
        "            )\n",
        "\n",
        "            self.encoder_stack.append(\n",
        "                SimpleConvBlock(\n",
        "                    in_channels=in_channels if block == 0 else prev_block_filters,\n",
        "                    pool=(block > 0),\n",
        "                    pool_before_convs=True,\n",
        "                    pooling_stride=2,\n",
        "                    num_convs=convs_per_block,\n",
        "                    filters=block_filters,\n",
        "                    kernel_size=kernel_size,\n",
        "                    use_bias=True,\n",
        "                    batch_norm=False,\n",
        "                    activation=\"relu\"\n",
        "                )\n",
        "            )\n",
        "        after_block_filters = block_filters\n",
        "\n",
        "        self.encoder_stack.append(\n",
        "            MaxPool2dWithSamePadding(\n",
        "                kernel_size=2,\n",
        "                stride=2,\n",
        "                padding=\"same\"\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Create a middle block (like the CARE implementation).\n",
        "        if middle_block:\n",
        "            if convs_per_block > 1:\n",
        "                # First convs are one exponent higher than the last encoder block.\n",
        "                block_filters = int(\n",
        "                    filters * (filters_rate ** (down_blocks + stem_blocks))\n",
        "                )\n",
        "                self.encoder_stack.append(\n",
        "                    SimpleConvBlock(\n",
        "                        in_channels=after_block_filters,\n",
        "                        pool=False,\n",
        "                        pool_before_convs=False,\n",
        "                        pooling_stride=2,\n",
        "                        num_convs=convs_per_block - 1,\n",
        "                        filters=block_filters,\n",
        "                        kernel_size=kernel_size,\n",
        "                        use_bias=True,\n",
        "                        batch_norm=False,\n",
        "                        activation=\"relu\",\n",
        "                    )\n",
        "                )\n",
        "\n",
        "            if block_contraction:\n",
        "                # Contract the channels with an exponent lower than the last encoder block.\n",
        "                block_filters = int(\n",
        "                    filters * (filters_rate ** (down_blocks + stem_blocks - 1))\n",
        "                )\n",
        "            else:\n",
        "                # Keep the block output filters the same.\n",
        "                block_filters = int(\n",
        "                    filters * (filters_rate ** (down_blocks + stem_blocks))\n",
        "                )\n",
        "\n",
        "            self.encoder_stack.append(\n",
        "                SimpleConvBlock(\n",
        "                    in_channels=block_filters,\n",
        "                    pool=False,\n",
        "                    pool_before_convs=False,\n",
        "                    pooling_stride=2,\n",
        "                    num_convs=1,\n",
        "                    filters=block_filters,\n",
        "                    kernel_size=kernel_size,\n",
        "                    use_bias=True,\n",
        "                    batch_norm=False,\n",
        "                    activation=\"relu\",\n",
        "                )\n",
        "            )\n",
        "\n",
        "        self.intermediate_features = {}\n",
        "        for i, block in enumerate(self.encoder_stack):\n",
        "            if isinstance(block, SimpleConvBlock) and block.pool:\n",
        "                current_stride *= block.pooling_stride\n",
        "\n",
        "            if current_stride not in self.intermediate_features.values():\n",
        "                self.intermediate_features[i] = current_stride\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        features = []\n",
        "        for i in range(len(self.encoder_stack)):\n",
        "            x = self.encoder_stack[i](x)\n",
        "            \n",
        "            if i in self.intermediate_features.keys():\n",
        "                features.append(x)\n",
        "\n",
        "        return x, features[1:][::-1]\n",
        "\n",
        "class SimpleUpsamplingBlock(nn.Module):\n",
        "    def __init__(self,\n",
        "        x_in_shape: int, \n",
        "        current_stride: int,\n",
        "        upsampling_stride: int = 2,\n",
        "        interp_method: Text = \"bilinear\",\n",
        "        refine_convs: int = 2,\n",
        "        refine_convs_filters: int = 64,\n",
        "        refine_convs_kernel_size: int = 3,\n",
        "        refine_convs_use_bias: bool = True,\n",
        "        refine_convs_batch_norm: bool = True,\n",
        "        refine_convs_batch_norm_before_activation: bool = True,\n",
        "        refine_convs_activation: Text = \"relu\"\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.x_in_shape = x_in_shape\n",
        "        self.current_stride = current_stride\n",
        "        self.upsampling_stride = upsampling_stride\n",
        "        self.interp_method = interp_method\n",
        "        self.refine_convs = refine_convs\n",
        "        self.refine_convs_filters = refine_convs_filters\n",
        "        self.refine_convs_kernel_size = refine_convs_kernel_size\n",
        "        self.refine_convs_use_bias = refine_convs_use_bias\n",
        "        self.refine_convs_batch_norm = refine_convs_batch_norm\n",
        "        self.refine_convs_batch_norm_before_activation = refine_convs_batch_norm_before_activation\n",
        "        self.refine_convs_activation = refine_convs_activation\n",
        "\n",
        "        self.blocks = nn.ModuleList([])\n",
        "        if current_stride is not None:\n",
        "            # Append the strides to the block prefix.\n",
        "            new_stride = current_stride // upsampling_stride\n",
        "\n",
        "        # Upsample via interpolation.\n",
        "        self.blocks.append(\n",
        "            nn.Upsample(\n",
        "                scale_factor=upsampling_stride,\n",
        "                mode=interp_method,\n",
        "            )\n",
        "        )\n",
        "\n",
        "\n",
        "        # Add further convolutions to refine after upsampling and/or skip.\n",
        "        for i in range(refine_convs):\n",
        "            filters = refine_convs_filters\n",
        "            self.blocks.append(\n",
        "                nn.Conv2d(\n",
        "                    in_channels=x_in_shape if i==0 else filters,\n",
        "                    out_channels=filters,\n",
        "                    kernel_size=refine_convs_kernel_size,\n",
        "                    stride=1,\n",
        "                    padding=\"same\",\n",
        "                    bias=refine_convs_use_bias\n",
        "                )\n",
        "            )\n",
        "\n",
        "            if (\n",
        "                refine_convs_batch_norm\n",
        "                and refine_convs_batch_norm_before_activation\n",
        "            ):\n",
        "                self.blocks.append(nn.BatchNorm2d(num_features=filters))\n",
        "\n",
        "\n",
        "            self.blocks.append(\n",
        "                get_act_fn(refine_convs_activation)  \n",
        "            )\n",
        "\n",
        "            if (\n",
        "                refine_convs_batch_norm\n",
        "                and not refine_convs_batch_norm_before_activation\n",
        "            ):\n",
        "                self.blocks.append(nn.BatchNorm2d(num_features=filters))\n",
        "\n",
        "\n",
        "    def forward(self, x: torch.Tensor, feature: torch.Tensor) -> torch.Tensor:\n",
        "        for idx, b in enumerate(self.blocks):\n",
        "            if idx == 1:  # Right after upsampling or convtranspose2d.\n",
        "                x = torch.concat((x, feature), dim=1)\n",
        "            x = b(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self,\n",
        "        x_in_shape: int,\n",
        "        current_stride: int,\n",
        "        filters: int = 64,\n",
        "        up_blocks: int = 4,\n",
        "        down_blocks: int = 3,\n",
        "        filters_rate: int = 2,\n",
        "        stem_blocks: int = 0,\n",
        "        convs_per_block: int = 2,\n",
        "        kernel_size: int = 3,\n",
        "        block_contraction: bool = False\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.x_in_shape = x_in_shape\n",
        "        self.current_stride = current_stride\n",
        "        self.filters = filters\n",
        "        self.up_blocks = up_blocks\n",
        "        self.down_blocks = down_blocks\n",
        "        self.filters_rate = filters_rate\n",
        "        self.stem_blocks = stem_blocks\n",
        "        self.convs_per_block = convs_per_block\n",
        "        self.kernel_size = kernel_size\n",
        "        self.block_contraction = block_contraction\n",
        "\n",
        "        self.decoder_stack = nn.ModuleList([])\n",
        "        for block in range(up_blocks):\n",
        "            prev_block_filters_in = -1 if block == 0 else block_filters_in\n",
        "            block_filters_in = int(\n",
        "                filters\n",
        "                * (\n",
        "                    filters_rate\n",
        "                    ** (down_blocks + stem_blocks - 1 - block)\n",
        "                )\n",
        "            )\n",
        "            if block_contraction:\n",
        "                block_filters_out = int(\n",
        "                    filters\n",
        "                    * (\n",
        "                        filters_rate\n",
        "                        ** (down_blocks + stem_blocks - 2 - block)\n",
        "                    )\n",
        "                )\n",
        "            else:\n",
        "                block_filters_out = block_filters_in\n",
        "\n",
        "            next_stride = current_stride // 2\n",
        "\n",
        "            self.decoder_stack.append(\n",
        "                SimpleUpsamplingBlock(\n",
        "                    x_in_shape=(x_in_shape + block_filters_in) if block == 0 else (prev_block_filters_in + block_filters_in), \n",
        "                    current_stride=current_stride,\n",
        "                    upsampling_stride=2,\n",
        "                    interp_method=\"bilinear\",\n",
        "                    refine_convs=self.convs_per_block,\n",
        "                    refine_convs_filters=block_filters_out,\n",
        "                    refine_convs_kernel_size=self.kernel_size,\n",
        "                    refine_convs_batch_norm=False,\n",
        "                )\n",
        "            )\n",
        "\n",
        "            current_stride = next_stride\n",
        "\n",
        "    def forward(self, x: torch.Tensor, features: List[torch.Tensor]) -> torch.Tensor:\n",
        "        for i in range(len(self.decoder_stack)):\n",
        "            x = self.decoder_stack[i](x, features[i])\n",
        "\n",
        "        return x\n",
        "\n",
        "class Unet(nn.Module):\n",
        "    def __init__(self,\n",
        "        in_channels: int = 1,\n",
        "        kernel_size: int = 3,\n",
        "        filters: int = 32,\n",
        "        filters_rate: int = 1.5,\n",
        "        stem_blocks: int = 0,\n",
        "        down_blocks: int = 4, \n",
        "        up_blocks: int = 3,\n",
        "        convs_per_block: int = 2,\n",
        "        middle_block: bool = True,\n",
        "        block_contraction: bool = False\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.enc = Encoder(\n",
        "            in_channels=in_channels,\n",
        "            filters=filters,\n",
        "            down_blocks=down_blocks,\n",
        "            filters_rate=filters_rate,\n",
        "            stem_blocks=stem_blocks,\n",
        "            convs_per_block=convs_per_block,\n",
        "            kernel_size=kernel_size,\n",
        "            middle_block=middle_block,\n",
        "            block_contraction=block_contraction\n",
        "        )\n",
        "\n",
        "        current_stride = int(\n",
        "            np.prod(\n",
        "                [block.pooling_stride for block in self.enc.encoder_stack if hasattr(block, \"pool\") and block.pool]\n",
        "                + [1]\n",
        "            )\n",
        "        )\n",
        "        \n",
        "        x_in_shape = int(\n",
        "            filters * (filters_rate ** (down_blocks + stem_blocks))\n",
        "        )\n",
        "\n",
        "        self.dec = Decoder(x_in_shape=x_in_shape, current_stride=current_stride, filters=filters,\n",
        "            up_blocks=up_blocks, down_blocks=down_blocks, filters_rate=filters_rate\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x, features = self.enc(x)\n",
        "        x = self.dec(x, features)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "fCMnTHR9VetA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEfgZT4hLyW4"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filters = 32\n",
        "filters_rate = 1.5\n",
        "down_blocks = 4\n",
        "stem_blocks = 0\n",
        "up_blocks = 3\n",
        "\n",
        "unet = Unet(filters=filters, \n",
        "            filters_rate=filters_rate, \n",
        "            down_blocks=down_blocks, \n",
        "            stem_blocks=stem_blocks, \n",
        "            up_blocks=up_blocks)\n",
        "\n",
        "in_channels = int(\n",
        "    filters\n",
        "    * (\n",
        "        filters_rate\n",
        "        ** (down_blocks + stem_blocks - 1 - up_blocks + 1)\n",
        "    )\n",
        ")\n",
        "model = nn.Sequential(*[\n",
        "    unet, \n",
        "    nn.Conv2d(in_channels=in_channels, out_channels=13, kernel_size=1, padding=\"same\")    \n",
        "])\n",
        "\n",
        "opt = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "scaler = torch.cuda.amp.GradScaler()"
      ],
      "metadata": {
        "id": "QoSLDG5OXWRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "\n",
        "cores = multiprocessing.cpu_count()\n",
        "cores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFNfmlnprhmb",
        "outputId": "e9107963-77ba-407d-cba1-91390ea3a3b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = DataGenerator(labels)\n",
        "train_dl = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=4,\n",
        "    shuffle=True,\n",
        "    num_workers=cores,\n",
        "    pin_memory=True,\n",
        "    drop_last=True,\n",
        "    prefetch_factor=2\n",
        ")\n",
        "\n",
        "val_ds = DataGenerator(val_labels, is_train=False)\n",
        "val_dl = DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=4,\n",
        "    shuffle=False,\n",
        "    num_workers=cores,\n",
        "    pin_memory=True,\n",
        "    drop_last=True,\n",
        "    prefetch_factor=2\n",
        ")"
      ],
      "metadata": {
        "id": "MQgZkAySXpO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze > requirements.txt\n",
        "\n",
        "# Some of this code is redundant. I kept the previous cells un-deleted just for reference.\n",
        "for i in range(5): \n",
        "    train_ds = DataGenerator(labels)\n",
        "    train_dl = DataLoader(\n",
        "        train_ds,\n",
        "        batch_size=4,\n",
        "        shuffle=True,\n",
        "        num_workers=cores,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "        prefetch_factor=2\n",
        "    )\n",
        "\n",
        "    val_ds = DataGenerator(val_labels, is_train=False)\n",
        "    val_dl = DataLoader(\n",
        "        val_ds,\n",
        "        batch_size=4,\n",
        "        shuffle=False,\n",
        "        num_workers=cores,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "        prefetch_factor=2\n",
        "    )\n",
        "\n",
        "    unet = Unet(filters=filters, \n",
        "                filters_rate=filters_rate, \n",
        "                down_blocks=down_blocks, \n",
        "                stem_blocks=stem_blocks, \n",
        "                up_blocks=up_blocks)\n",
        "\n",
        "    in_channels = int(\n",
        "        filters\n",
        "        * (\n",
        "            filters_rate\n",
        "            ** (down_blocks + stem_blocks - 1 - up_blocks + 1)\n",
        "        )\n",
        "    )\n",
        "    model = nn.Sequential(*[\n",
        "        unet, \n",
        "        nn.Conv2d(in_channels=in_channels, out_channels=13, kernel_size=1, padding=\"same\")    \n",
        "    ])\n",
        "\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "    model = model.to(\"cuda\")\n",
        "\n",
        "    run = wandb.init(\n",
        "        project=\"torch_vs_tf_talmo_lab\", \n",
        "        name=f\"torch_baseline_run{i}\", \n",
        "        config={\n",
        "            \"is_tf\": False,\n",
        "            \"device_and_memory\": get_vram(),\n",
        "            \"seed\": seed,\n",
        "            \"model_param_count\": get_param_count(model)\n",
        "        }, \n",
        "        tags=[\"baseline\"],\n",
        "        notes=\"This experiment was done in a Google Colab Notebook.\"\n",
        "    )\n",
        "\n",
        "    # Log dependencies.\n",
        "    artifact = wandb.Artifact(\"Dependencies\", type=\"dependencies\")\n",
        "    artifact.add_file(\"requirements.txt\", name=f\"requirements.txt\")\n",
        "    run.log_artifact(artifact)\n",
        "\n",
        "    for epoch in range(3):\n",
        "        _ = model.train()\n",
        "        start_time = time.time()\n",
        "        train_loss = 0\n",
        "        for idx, batch in enumerate(train_dl):\n",
        "            X, y = batch\n",
        "            X = X.to(\"cuda\")\n",
        "            y = y.to(\"cuda\")\n",
        "            \n",
        "            with torch.autocast(\"cuda\"):\n",
        "                y_preds = model(X)\n",
        "                loss = nn.MSELoss()(y_preds, y)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(opt)\n",
        "            scaler.update()\n",
        "            opt.zero_grad()\n",
        "                    \n",
        "            if idx % 100 == 0:\n",
        "              print(f\"Epoch: {epoch} | Loss: {loss:.5f}\")\n",
        "\n",
        "            train_loss += loss\n",
        "\n",
        "        train_loss /= (idx+1)\n",
        "        train_time = time.time() - start_time\n",
        "        print(f\"TRAIN: --- {train_time}s seconds ---\")\n",
        "\n",
        "        _  = model.eval()\n",
        "        start_time = time.time()\n",
        "        val_loss = 0\n",
        "        for idx, batch in enumerate(val_dl):\n",
        "            X, y = batch\n",
        "            X = X.to(\"cuda\")\n",
        "            y = y.to(\"cuda\")\n",
        "\n",
        "            with torch.no_grad():\n",
        "                y_preds = model(X)\n",
        "                loss = nn.MSELoss()(y_preds, y)\n",
        "\n",
        "            val_loss += loss\n",
        "\n",
        "        val_loss /= (idx+1)\n",
        "        val_time = time.time() - start_time\n",
        "        print(f\"VAL: --- {val_time}s seconds ---\")\n",
        "\n",
        "        run.log({\n",
        "            \"train_loss\": train_loss,\n",
        "            \"val_loss\": val_loss,\n",
        "            \"train_time\": train_time,\n",
        "            \"val_time\": val_time,\n",
        "            \"total_time\": train_time + val_time\n",
        "        })\n",
        "\n",
        "    del model, opt, scaler, train_ds, train_dl, val_ds, val_dl\n",
        "    gc.collect()\n",
        "    run.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "df6ec7bf027647e39a970d568b14ccdd",
            "c2a93d67931046f3a7108d7d46ee2733",
            "2d98f8bd8f124badbb20943dafe69803",
            "70454460df1845e4878424c24923a011",
            "1b6c6a9622054d6f81ee7e5445298d1d",
            "c532a7934dff43f7826109776336270c",
            "6878df96cb9e4938ae524857b25442a8",
            "d1610903f88f48da8cacb099ad7764ea",
            "bf3d7070064f4a15b41ff5922bc1624f",
            "48acf8047769425792af037153ebfb3c",
            "ba4ddbde288c4adba7bb954367996799",
            "da12f08b508745dc9d98a8267de9a811",
            "5009a9e6777f4b9091e884a6fbc336a2",
            "bb81174b21b3439d957b3e0b9fde4c0e",
            "976326c6ce004f14b3544317c1602a6a",
            "ce8f575b05ce4388871b079d09bb6282"
          ]
        },
        "id": "tDMSgbrrY7E0",
        "outputId": "65374261-9a25-40c1-d1f4-760117f74114"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvincenttu\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230512_044033-uzc3eeuz</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab/runs/uzc3eeuz' target=\"_blank\">torch_baseline_run0</a></strong> to <a href='https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab' target=\"_blank\">https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab/runs/uzc3eeuz' target=\"_blank\">https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab/runs/uzc3eeuz</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Loss: 0.04741\n",
            "Epoch: 0 | Loss: 0.00041\n",
            "Epoch: 0 | Loss: 0.00032\n",
            "Epoch: 0 | Loss: 0.00029\n",
            "Epoch: 0 | Loss: 0.00028\n",
            "Epoch: 0 | Loss: 0.00028\n",
            "Epoch: 0 | Loss: 0.00028\n",
            "Epoch: 0 | Loss: 0.00028\n",
            "TRAIN: --- 101.15498280525208s seconds ---\n",
            "VAL: --- 6.934823513031006s seconds ---\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "TRAIN: --- 91.67806005477905s seconds ---\n",
            "VAL: --- 7.779144048690796s seconds ---\n",
            "Epoch: 2 | Loss: 0.00027\n",
            "Epoch: 2 | Loss: 0.00026\n",
            "Epoch: 2 | Loss: 0.00027\n",
            "Epoch: 2 | Loss: 0.00026\n",
            "Epoch: 2 | Loss: 0.00026\n",
            "Epoch: 2 | Loss: 0.00026\n",
            "Epoch: 2 | Loss: 0.00026\n",
            "Epoch: 2 | Loss: 0.00025\n",
            "TRAIN: --- 91.89349865913391s seconds ---\n",
            "VAL: --- 7.905293703079224s seconds ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>total_time</td><td>█▁▁</td></tr><tr><td>train_loss</td><td>█▁▁</td></tr><tr><td>train_time</td><td>█▁▁</td></tr><tr><td>val_loss</td><td>█▆▁</td></tr><tr><td>val_time</td><td>▁▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_time</td><td>99.79879</td></tr><tr><td>train_loss</td><td>0.00026</td></tr><tr><td>train_time</td><td>91.8935</td></tr><tr><td>val_loss</td><td>0.00025</td></tr><tr><td>val_time</td><td>7.90529</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">torch_baseline_run0</strong> at: <a href='https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab/runs/uzc3eeuz' target=\"_blank\">https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab/runs/uzc3eeuz</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230512_044033-uzc3eeuz/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230512_044549-2rp8fh7x</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab/runs/2rp8fh7x' target=\"_blank\">torch_baseline_run1</a></strong> to <a href='https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab' target=\"_blank\">https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab/runs/2rp8fh7x' target=\"_blank\">https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab/runs/2rp8fh7x</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Loss: 0.05251\n",
            "Epoch: 0 | Loss: 0.00043\n",
            "Epoch: 0 | Loss: 0.00033\n",
            "Epoch: 0 | Loss: 0.00030\n",
            "Epoch: 0 | Loss: 0.00028\n",
            "Epoch: 0 | Loss: 0.00027\n",
            "Epoch: 0 | Loss: 0.00028\n",
            "Epoch: 0 | Loss: 0.00028\n",
            "TRAIN: --- 91.68937993049622s seconds ---\n",
            "VAL: --- 8.377355575561523s seconds ---\n",
            "Epoch: 1 | Loss: 0.00028\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "TRAIN: --- 92.15950870513916s seconds ---\n",
            "VAL: --- 6.9007439613342285s seconds ---\n",
            "Epoch: 2 | Loss: 0.00027\n",
            "Epoch: 2 | Loss: 0.00027\n",
            "Epoch: 2 | Loss: 0.00027\n",
            "Epoch: 2 | Loss: 0.00027\n",
            "Epoch: 2 | Loss: 0.00027\n",
            "Epoch: 2 | Loss: 0.00026\n",
            "Epoch: 2 | Loss: 0.00026\n",
            "Epoch: 2 | Loss: 0.00026\n",
            "TRAIN: --- 92.58168983459473s seconds ---\n",
            "VAL: --- 8.63883352279663s seconds ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "df6ec7bf027647e39a970d568b14ccdd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>total_time</td><td>▄▁█</td></tr><tr><td>train_loss</td><td>█▁▁</td></tr><tr><td>train_time</td><td>▁▅█</td></tr><tr><td>val_loss</td><td>█▅▁</td></tr><tr><td>val_time</td><td>▇▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_time</td><td>101.22052</td></tr><tr><td>train_loss</td><td>0.00027</td></tr><tr><td>train_time</td><td>92.58169</td></tr><tr><td>val_loss</td><td>0.00026</td></tr><tr><td>val_time</td><td>8.63883</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">torch_baseline_run1</strong> at: <a href='https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab/runs/2rp8fh7x' target=\"_blank\">https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab/runs/2rp8fh7x</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230512_044549-2rp8fh7x/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230512_045057-eae79yir</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab/runs/eae79yir' target=\"_blank\">torch_baseline_run2</a></strong> to <a href='https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab' target=\"_blank\">https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab/runs/eae79yir' target=\"_blank\">https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab/runs/eae79yir</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Loss: 0.00896\n",
            "Epoch: 0 | Loss: 0.00038\n",
            "Epoch: 0 | Loss: 0.00029\n",
            "Epoch: 0 | Loss: 0.00028\n",
            "Epoch: 0 | Loss: 0.00028\n",
            "Epoch: 0 | Loss: 0.00027\n",
            "Epoch: 0 | Loss: 0.00027\n",
            "Epoch: 0 | Loss: 0.00027\n",
            "TRAIN: --- 91.63160395622253s seconds ---\n",
            "VAL: --- 8.882042407989502s seconds ---\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "TRAIN: --- 91.96590518951416s seconds ---\n",
            "VAL: --- 6.8226964473724365s seconds ---\n",
            "Epoch: 2 | Loss: 0.00026\n",
            "Epoch: 2 | Loss: 0.00026\n",
            "Epoch: 2 | Loss: 0.00026\n",
            "Epoch: 2 | Loss: 0.00027\n",
            "Epoch: 2 | Loss: 0.00027\n",
            "Epoch: 2 | Loss: 0.00027\n",
            "Epoch: 2 | Loss: 0.00026\n",
            "Epoch: 2 | Loss: 0.00027\n",
            "TRAIN: --- 91.46240043640137s seconds ---\n",
            "VAL: --- 8.218801975250244s seconds ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.011 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.105815…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bf3d7070064f4a15b41ff5922bc1624f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>total_time</td><td>█▁▅</td></tr><tr><td>train_loss</td><td>█▁▁</td></tr><tr><td>train_time</td><td>▃█▁</td></tr><tr><td>val_loss</td><td>█▄▁</td></tr><tr><td>val_time</td><td>█▁▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_time</td><td>99.6812</td></tr><tr><td>train_loss</td><td>0.00027</td></tr><tr><td>train_time</td><td>91.4624</td></tr><tr><td>val_loss</td><td>0.00027</td></tr><tr><td>val_time</td><td>8.2188</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">torch_baseline_run2</strong> at: <a href='https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab/runs/eae79yir' target=\"_blank\">https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab/runs/eae79yir</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230512_045057-eae79yir/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230512_045603-vidt8blm</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab/runs/vidt8blm' target=\"_blank\">torch_baseline_run3</a></strong> to <a href='https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab' target=\"_blank\">https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab/runs/vidt8blm' target=\"_blank\">https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab/runs/vidt8blm</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Loss: 0.00980\n",
            "Epoch: 0 | Loss: 0.00038\n",
            "Epoch: 0 | Loss: 0.00030\n",
            "Epoch: 0 | Loss: 0.00028\n",
            "Epoch: 0 | Loss: 0.00028\n",
            "Epoch: 0 | Loss: 0.00028\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-76b2bc92514d>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-7394bc7d4704>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mlf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mframe_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0minstance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minst_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0mkp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sleap/instance.py\u001b[0m in \u001b[0;36mimage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1763\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m         \u001b[0;34m\"\"\"Return the image for this frame of shape (height, width, channels).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1765\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvideo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1767\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sleap/io/video.py\u001b[0m in \u001b[0;36mget_frame\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m   1085\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mvideo\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m         \"\"\"\n\u001b[0;32m-> 1087\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1088\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midxs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sleap/io/video.py\u001b[0m in \u001b[0;36mget_frame\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dataset_h5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"format\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m             \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_UNCHANGED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0;31m# Add dimension for single channel (dropped by opencv).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l_K2JBrPZQVC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}