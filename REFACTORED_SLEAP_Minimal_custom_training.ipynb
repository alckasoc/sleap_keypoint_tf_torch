{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2ba595c04b184a5ebb825ab243056cd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1204337a78e94b5cb373221575f4b85b",
              "IPY_MODEL_1aad45af0010477387ac725c9d590809"
            ],
            "layout": "IPY_MODEL_3694b754c67942fe9d29a491a5de3fc4"
          }
        },
        "1204337a78e94b5cb373221575f4b85b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9fe7c9770bb04ba680a16b6a4a07819a",
            "placeholder": "​",
            "style": "IPY_MODEL_cb11a672ec3c45a5a8333668c335302c",
            "value": "0.019 MB of 0.019 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "1aad45af0010477387ac725c9d590809": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25edb8df3df8454499b4624bf99366fb",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_144f76bf9dc641bebcf23ba805f081b7",
            "value": 0.9859803623848568
          }
        },
        "3694b754c67942fe9d29a491a5de3fc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fe7c9770bb04ba680a16b6a4a07819a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb11a672ec3c45a5a8333668c335302c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25edb8df3df8454499b4624bf99366fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "144f76bf9dc641bebcf23ba805f081b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b521237ca6714d7a885f6353f55ea827": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0fc1afd13aa74548a3158fcfab2c687b",
              "IPY_MODEL_116d13148ac2436f85e06182aba64f70"
            ],
            "layout": "IPY_MODEL_de0eddee21ac47dc9c286fc953efba4c"
          }
        },
        "0fc1afd13aa74548a3158fcfab2c687b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_520d42cced494dd6aa40dd66da9a301c",
            "placeholder": "​",
            "style": "IPY_MODEL_54921a9daff44a90af4dcc65d656dadf",
            "value": "0.001 MB of 0.002 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "116d13148ac2436f85e06182aba64f70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d1ffbd90b04419ebc1d2a3d3e625a11",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_048e850689aa4d48922b2a3540d5a881",
            "value": 0.5175213675213676
          }
        },
        "de0eddee21ac47dc9c286fc953efba4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "520d42cced494dd6aa40dd66da9a301c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54921a9daff44a90af4dcc65d656dadf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d1ffbd90b04419ebc1d2a3d3e625a11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "048e850689aa4d48922b2a3540d5a881": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeeqrLbdupmE"
      },
      "source": [
        "# Install SLEAP\n",
        "Don't forget to set **Runtime** -> **Change runtime type...** -> **GPU** as the accelerator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYxJ2rJOMW8B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f093de18-8ed4-438b-ed47-e704ae019f02"
      },
      "source": [
        "!pip install sleap -qqq\n",
        "!pip install albumentations -qqq\n",
        "!pip install nvidia-ml-py3 -qqq"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.4/64.4 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m498.1/498.1 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.2/88.2 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.9/84.9 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.9/131.9 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.9/228.9 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.5/60.5 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.3/214.3 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.1/156.1 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m904.1/904.1 kB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.2/149.2 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m832.9/832.9 kB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.3/462.3 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.2/192.2 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.0/109.0 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m87.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.6/485.6 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pykalman (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for jsmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\n",
            "flax 0.6.9 requires rich>=11.1, but you have rich 10.16.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jftAOyvvuQeh",
        "outputId": "5435f765-d71c-4910-ff31-a0c025dc4a0a"
      },
      "source": [
        "import os\n",
        "import gc\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "import collections\n",
        "from typing import Sequence, Tuple, Text, Union, Optional, List\n",
        "\n",
        "import nvidia_smi\n",
        "\n",
        "import numpy as np\n",
        "import albumentations as A\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import sleap\n",
        "\n",
        "sleap.versions()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SLEAP: 1.3.0\n",
            "TensorFlow: 2.8.4\n",
            "Numpy: 1.22.4\n",
            "Python: 3.10.11\n",
            "OS: Linux-5.10.147+-x86_64-with-glibc2.31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb -qqq\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "F31Z_dQfA3Hj",
        "outputId": "ab852f36-afda-4ee9-ceb6-51486a60151a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.1/203.1 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "PWl3cG1_9WTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "def get_vram():\n",
        "    nvidia_smi.nvmlInit()\n",
        "\n",
        "    deviceCount = nvidia_smi.nvmlDeviceGetCount()\n",
        "    for i in range(deviceCount):\n",
        "        handle = nvidia_smi.nvmlDeviceGetHandleByIndex(i)\n",
        "        info = nvidia_smi.nvmlDeviceGetMemoryInfo(handle)\n",
        "        output = (\"Device {}: {}, Memory : ({:.2f}% free): {} (total), {} (free), {} (used)\"\n",
        "              .format(i, nvidia_smi.nvmlDeviceGetName(handle), 100*info.free/info.total, \n",
        "                      info.total/(1024 ** 3), info.free/(1024 ** 3), info.used/(1024 ** 3)))\n",
        "\n",
        "    nvidia_smi.nvmlShutdown()\n",
        "\n",
        "    return output\n",
        "\n",
        "def get_param_count(model):\n",
        "  trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "  total_params = sum(p.numel() for p in model.parameters())\n",
        "  nontrainable_params = total_params - trainable_params\n",
        "\n",
        "  return trainable_params, nontrainable_params, total_params"
      ],
      "metadata": {
        "id": "X2ESLmrn9VnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 42\n",
        "seed_everything(seed)"
      ],
      "metadata": {
        "id": "2pEmfBalS51R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSdTJYOdu4L6"
      },
      "source": [
        "# Download training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDIF3RKdM86u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edfe6859-b594-4ca4-bf79-dc79ea37693f"
      },
      "source": [
        "!curl -L --output labels.slp https://storage.googleapis.com/sleap-data/datasets/wt_gold.13pt/tracking_split2/train.pkg.slp\n",
        "!ls -lah\n",
        "\n",
        "!curl -L --output val_labels.slp https://storage.googleapis.com/sleap-data/datasets/wt_gold.13pt/tracking_split2/val.pkg.slp\n",
        "!ls -lah"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  619M  100  619M    0     0  66.7M      0  0:00:09  0:00:09 --:--:-- 73.4M\n",
            "total 620M\n",
            "drwxr-xr-x 1 root root 4.0K May  8 03:33 .\n",
            "drwxr-xr-x 1 root root 4.0K May  8 03:25 ..\n",
            "drwxr-xr-x 4 root root 4.0K May  3 13:30 .config\n",
            "-rw-r--r-- 1 root root 620M May  8 03:33 labels.slp\n",
            "drwxr-xr-x 1 root root 4.0K May  3 13:31 sample_data\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 77.2M  100 77.2M    0     0  61.1M      0  0:00:01  0:00:01 --:--:-- 61.1M\n",
            "total 697M\n",
            "drwxr-xr-x 1 root root 4.0K May  8 03:33 .\n",
            "drwxr-xr-x 1 root root 4.0K May  8 03:25 ..\n",
            "drwxr-xr-x 4 root root 4.0K May  3 13:30 .config\n",
            "-rw-r--r-- 1 root root 620M May  8 03:33 labels.slp\n",
            "drwxr-xr-x 1 root root 4.0K May  3 13:31 sample_data\n",
            "-rw-r--r-- 1 root root  78M May  8 03:34 val_labels.slp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lugn7a_HC0Q"
      },
      "source": [
        "# Load the training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMkSIZrTHCMr",
        "outputId": "4fc3e291-e006-4a56-cdc7-78daf23ad172"
      },
      "source": [
        "# SLEAP Labels files (.slp) can include the images as well as labeled instances and\n",
        "# other metadata for a project.\n",
        "labels = sleap.load_file(\"labels.slp\")\n",
        "labels = labels.with_user_labels_only()\n",
        "labels.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skeleton: Skeleton(description=None, nodes=[head, thorax, abdomen, wingL, wingR, forelegL4, forelegR4, midlegL4, midlegR4, hindlegL4, hindlegR4, eyeL, eyeR], edges=[thorax->head, thorax->abdomen, thorax->wingL, thorax->wingR, thorax->forelegL4, thorax->forelegR4, thorax->midlegL4, thorax->midlegR4, thorax->hindlegL4, thorax->hindlegR4, head->eyeL, head->eyeR], symmetries=[wingL<->wingR, eyeL<->eyeR, midlegL4<->midlegR4, forelegL4<->forelegR4, hindlegL4<->hindlegR4])\n",
            "Videos: ['labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp']\n",
            "Frames (user/predicted): 1,600/0\n",
            "Instances (user/predicted): 3,200/0\n",
            "Tracks: [Track(spawned_on=0, name='female'), Track(spawned_on=0, name='male')]\n",
            "Suggestions: 0\n",
            "Provenance: {}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's also do the same for the val labels.\n",
        "val_labels = sleap.load_file(\"val_labels.slp\")\n",
        "val_labels = val_labels.with_user_labels_only()\n",
        "val_labels.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sklyy8NWEyff",
        "outputId": "59ef7112-08c7-4f60-9f1d-f911f75f117f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skeleton: Skeleton(description=None, nodes=[head, thorax, abdomen, wingL, wingR, forelegL4, forelegR4, midlegL4, midlegR4, hindlegL4, hindlegR4, eyeL, eyeR], edges=[thorax->head, thorax->abdomen, thorax->wingL, thorax->wingR, thorax->forelegL4, thorax->forelegR4, thorax->midlegL4, thorax->midlegR4, thorax->hindlegL4, thorax->hindlegR4, head->eyeL, head->eyeR], symmetries=[eyeL<->eyeR, forelegL4<->forelegR4, hindlegL4<->hindlegR4, midlegL4<->midlegR4, wingL<->wingR])\n",
            "Videos: ['val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp']\n",
            "Frames (user/predicted): 200/0\n",
            "Instances (user/predicted): 400/0\n",
            "Tracks: [Track(spawned_on=0, name='female'), Track(spawned_on=0, name='male')]\n",
            "Suggestions: 0\n",
            "Provenance: {}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EK8DDPHDHBr_",
        "outputId": "8af04ded-f29c-4a20-8061-fb8904ca6445"
      },
      "source": [
        "# Labels are list-like containers whose elements are LabeledFrames\n",
        "print(f\"Number of labels: {len(labels)}\")\n",
        "\n",
        "labeled_frame = labels[0]\n",
        "labeled_frame"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of labels: 1600\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LabeledFrame(video=HDF5Video('labels.slp'), frame_idx=166050, instances=2)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pP5uXrU3HX6o",
        "outputId": "df5596a8-c4f8-4c43-90cc-309c7818ad25"
      },
      "source": [
        "# LabeledFrames are containers for instances that were labeled in a single frame\n",
        "instance = labeled_frame[0]\n",
        "instance"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Instance(video=Video(filename=labels.slp, shape=(66, 1024, 1024, 1), backend=HDF5Video), frame_idx=166050, points=[head: (491.6, 187.7), thorax: (474.4, 224.8), abdomen: (459.9, 262.2), wingL: (448.3, 271.7), wingR: (452.1, 273.5), forelegL4: (478.5, 175.9), forelegR4: (499.9, 177.9), midlegL4: (440.6, 216.4), midlegR4: (510.1, 242.7), hindlegL4: (437.2, 234.3), hindlegR4: (490.9, 266.7), eyeL: (477.5, 193.2), eyeR: (498.4, 201.2)], track=Track(spawned_on=0, name='female'))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "700fTPs4Hurg",
        "outputId": "b300f7c4-e473-49a2-dade-21668bcc18aa"
      },
      "source": [
        "# They can be converted to numpy arrays where each row corresponds to the coordinates\n",
        "# of a different body part:\n",
        "pts = instance.numpy()\n",
        "pts"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "rec.array([[491.58118169, 187.72078779],\n",
              "           [474.3603939 , 224.80196948],\n",
              "           [459.90098474, 262.16236338],\n",
              "           [448.26137864, 271.72078779],\n",
              "           [452.08118169, 273.54059084],\n",
              "           [478.5       , 175.90098474],\n",
              "           [499.94157558, 177.90098474],\n",
              "           [440.58118169, 216.3603939 ],\n",
              "           [510.12177253, 242.72078779],\n",
              "           [         nan,          nan],\n",
              "           [490.90098474, 266.72078779],\n",
              "           [477.54059084, 193.16236338],\n",
              "           [498.40098474, 201.18019695]],\n",
              "          dtype=float64)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vYsPusvviiu"
      },
      "source": [
        "# Setup training data generation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def update_not_shown_nodes(not_shown_nodes, node_names, new_nodes):\n",
        "  nodes_not_in_aug = np.array(list(set(node_names).difference(set(new_nodes))))\n",
        "  not_shown_in_aug_or_original_ind = np.in1d(node_names, nodes_not_in_aug).nonzero()[0]\n",
        "  not_shown_nodes[not_shown_in_aug_or_original_ind] = True \n",
        "\n",
        "  return not_shown_nodes\n",
        "\n",
        "\n",
        "def update_kp(kp, not_shown_nodes, node_names, new_nodes):\n",
        "  shown_after_aug_ind = np.in1d(node_names, new_nodes).nonzero()[0]\n",
        "  shown_ind = np.in1d(not_shown_nodes, True).nonzero()[0]\n",
        "\n",
        "  assert len(shown_after_aug_ind) == kp.shape[0]\n",
        "\n",
        "  kp_ = np.zeros((len(node_names), 2))\n",
        "  kp_[shown_after_aug_ind] = kp\n",
        "  kp_[shown_ind] = 0\n",
        "\n",
        "  return kp_\n",
        "\n",
        "\n",
        "def make_grid_vectors(\n",
        "    image_height: int, image_width: int, output_stride: int = 1):\n",
        "\n",
        "    xv = torch.arange(0, image_width, step=output_stride).to(torch.float32)\n",
        "    yv = torch.arange(0, image_height, step=output_stride).to(torch.float32)\n",
        "    return xv, yv\n",
        "\n",
        "def make_confmaps(\n",
        "    points: torch.Tensor, xv: torch.Tensor, yv: torch.Tensor, sigma: float):\n",
        "\n",
        "    x = torch.reshape(points[:, 0], (1, 1, -1))\n",
        "    y = torch.reshape(points[:, 1], (1, 1, -1))\n",
        "    cm = torch.exp(\n",
        "        -((torch.reshape(xv, (1, -1, 1)) - x) ** 2 + (torch.reshape(yv, (-1, 1, 1)) - y) ** 2)\n",
        "        / (2 * sigma ** 2)\n",
        "    )\n",
        "\n",
        "    # Replace NaNs with 0.\n",
        "    cm = torch.where(torch.isnan(cm), 0.0, cm)\n",
        "    return cm\n",
        "\n",
        "def get_bbox_coords_on_centroid(anchor_coords, crop_size, img_size):\n",
        "    (cx, cy) = anchor_coords\n",
        "\n",
        "    # [bottom left     top right]\n",
        "    # [  x1, y1,         x2, y2 ]\n",
        "    bbox = [\n",
        "        max(-crop_size / 2 + cx, 0),\n",
        "        max(-crop_size / 2 + cy, 0),\n",
        "        min(crop_size / 2 + cx, img_size[0]),\n",
        "        min(crop_size / 2 + cy, img_size[1])\n",
        "    ]\n",
        "\n",
        "    return bbox\n",
        "\n",
        "# My refactored version of this dataset generator.\n",
        "class DataGenerator(Dataset):\n",
        "    def __init__(self, \n",
        "      labels, \n",
        "      img_size=160,\n",
        "      anchor_name=\"thorax\",\n",
        "      sigma=1.5,\n",
        "      output_stride=2,\n",
        "      rot_range=(-180, 180),\n",
        "      is_train=True\n",
        "    ):\n",
        "        self.labels = labels.with_user_labels_only()\n",
        "        self.labels.remove_empty_instances(keep_empty_frames=False)\n",
        "\n",
        "        self.indices = []\n",
        "        for frame_idx, l in enumerate(self.labels):\n",
        "          inst_indices = np.arange(0, len(l.instances)).tolist()\n",
        "          self.indices.extend([(frame_idx, i) for i in inst_indices])\n",
        "\n",
        "        self.img_size = img_size\n",
        "\n",
        "        assert anchor_name in self.labels.skeleton.node_names\n",
        "        self.anchor_name = anchor_name\n",
        "\n",
        "        # Assuming 1 skeleton.\n",
        "        assert len(labels.skeletons) == 1\n",
        "        self.node_names = labels.skeletons[0].node_names\n",
        "\n",
        "        self.sigma = sigma\n",
        "        self.output_stride = output_stride\n",
        "        self.rot_range = rot_range\n",
        "\n",
        "        self.tfm = A.Compose([\n",
        "            A.Rotate(limit=list(self.rot_range), p=0.5)\n",
        "        ], keypoint_params=A.KeypointParams(format='xy', label_fields=['class_labels']))\n",
        "\n",
        "        self.xv, self.yv = make_grid_vectors(\n",
        "            image_height=self.img_size, \n",
        "            image_width=self.img_size, \n",
        "            output_stride=self.output_stride\n",
        "        )\n",
        "\n",
        "        self.is_train = is_train\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        frame_idx, inst_idx = self.indices[idx]\n",
        "        lf = self.labels[frame_idx]\n",
        "        instance = lf[inst_idx]\n",
        "        img = lf.image\n",
        "        kp = instance.numpy()\n",
        "\n",
        "        # NaNs to 0 and clip.\n",
        "        assert kp.shape == (len(self.node_names), 2)\n",
        "        not_shown_nodes = np.isnan(kp).any(axis=1)\n",
        "        kp = np.nan_to_num(kp, nan=0)\n",
        "        kp = np.concatenate((np.clip(kp[:, :1], 0, img.shape[1]), \n",
        "                              np.clip(kp[:, 1:], 0, img.shape[0])), \n",
        "                            axis=1)\n",
        "\n",
        "        if self.is_train:\n",
        "            # Apply augmentations.\n",
        "            output = self.tfm(image=img, keypoints=kp, class_labels=self.node_names)\n",
        "            img, kp, new_nodes = output[\"image\"], np.array(output[\"keypoints\"]), output[\"class_labels\"]\n",
        "\n",
        "            # Update not_shown_nodes and kp.\n",
        "            not_shown_nodes = update_not_shown_nodes(not_shown_nodes, self.node_names, new_nodes)\n",
        "            kp = update_kp(kp, not_shown_nodes, self.node_names, new_nodes)\n",
        "\n",
        "        # Get bbox coordinate based on centroid.\n",
        "        bbox = get_bbox_coords_on_centroid(\n",
        "          kp[self.node_names.index(self.anchor_name)].tolist(), \n",
        "          self.img_size, img.shape[:2]\n",
        "        )\n",
        "\n",
        "        # Crop and pad.\n",
        "        x1, y1, x2, y2 = bbox\n",
        "        tfm_crop = A.Compose([\n",
        "          A.Crop(int(round(x1)), int(round(y1)), int(round(x2)), int(round(y2))),\n",
        "          A.PadIfNeeded(min_height=self.img_size, min_width=self.img_size)\n",
        "        ], keypoint_params=A.KeypointParams(format='xy', label_fields=['class_labels']))\n",
        "\n",
        "        crop_kp = tfm_crop(image=img, keypoints=kp, class_labels=self.node_names)\n",
        "        crop, kp, new_nodes = crop_kp[\"image\"], np.array(crop_kp[\"keypoints\"]), crop_kp[\"class_labels\"]\n",
        "        crop = torch.Tensor(crop).permute(2, 0, 1)\n",
        "\n",
        "        # Update not_shown_nodes and kp.\n",
        "        not_shown_nodes = update_not_shown_nodes(not_shown_nodes, self.node_names, new_nodes)\n",
        "        kp = update_kp(kp, not_shown_nodes, self.node_names, new_nodes)\n",
        "        kp = torch.Tensor(kp)\n",
        "\n",
        "        # Get confidence map.\n",
        "        xv, yv = make_grid_vectors(\n",
        "          image_height=self.img_size, \n",
        "          image_width=self.img_size, \n",
        "          output_stride=self.output_stride\n",
        "        )\n",
        "\n",
        "        cm = make_confmaps(\n",
        "          points=kp, \n",
        "          xv=self.xv, \n",
        "          yv=self.yv, \n",
        "          sigma=self.sigma\n",
        "        )\n",
        "        cm = cm.permute(2, 0, 1)\n",
        "\n",
        "        return crop, cm"
      ],
      "metadata": {
        "id": "l8Q-1ehtVWbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yo95XzRKkba"
      },
      "source": [
        "# Setting up a neural network model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MaxPool2dWithSamePadding(nn.MaxPool2d):\n",
        "\n",
        "    def _calc_same_pad(self, i: int, k: int, s: int, d: int) -> int:\n",
        "        return max((math.ceil(i / s) - 1) * s + (k - 1) * d + 1 - i, 0)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        if self.padding == \"same\":\n",
        "            ih, iw = x.size()[-2:]\n",
        "\n",
        "            pad_h = self._calc_same_pad(i=ih, \n",
        "                                        k=self.kernel_size if type(self.kernel_size) is int else self.kernel_size[0], \n",
        "                                        s=self.stride if type(self.stride) is int else self.stride[0], \n",
        "                                        d=self.dilation if type(self.dilation) is int else self.dilation[0])\n",
        "            pad_w = self._calc_same_pad(i=iw, \n",
        "                                        k=self.kernel_size if type(self.kernel_size) is int else self.kernel_size[1], \n",
        "                                        s=self.stride if type(self.stride) is int else self.stride[1], \n",
        "                                        d=self.dilation if type(self.dilation) is int else self.dilation[1])\n",
        "\n",
        "            if pad_h > 0 or pad_w > 0:\n",
        "                x = F.pad(\n",
        "                    x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2]\n",
        "                )\n",
        "            self.padding = 0\n",
        "\n",
        "        return F.max_pool2d(x, self.kernel_size, self.stride,\n",
        "                                    self.padding, self.dilation, ceil_mode=self.ceil_mode,\n",
        "                                    return_indices=self.return_indices)\n",
        "\n",
        "def get_act_fn(activation: str) -> nn.Module:\n",
        "    activations = {\n",
        "        'relu': nn.ReLU(),\n",
        "        'sigmoid': nn.Sigmoid(),\n",
        "        'tanh': nn.Tanh()\n",
        "    }\n",
        "\n",
        "    return activations[activation]\n",
        "\n",
        "class SimpleConvBlock(nn.Module):\n",
        "    def __init__(self,\n",
        "        in_channels: int,\n",
        "        pool: bool = True,\n",
        "        pooling_stride: int = 2,\n",
        "        pool_before_convs: bool = False,\n",
        "        num_convs: int = 2,\n",
        "        filters: int = 32,\n",
        "        kernel_size: int = 3,\n",
        "        use_bias: bool = True,\n",
        "        batch_norm: bool = False,\n",
        "        activation: Text = \"relu\"\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.pool = pool\n",
        "        self.pooling_stride = pooling_stride\n",
        "        self.pool_before_convs = pool_before_convs\n",
        "        self.num_convs = num_convs\n",
        "        self.filters = filters\n",
        "        self.kernel_size = kernel_size\n",
        "        self.use_bias = use_bias\n",
        "        self.batch_norm = batch_norm\n",
        "        self.activation = activation\n",
        "\n",
        "        self.blocks = []\n",
        "        if pool and pool_before_convs:\n",
        "            self.blocks.append(\n",
        "                MaxPool2dWithSamePadding(\n",
        "                    kernel_size=2,\n",
        "                    stride=pooling_stride,\n",
        "                    padding=\"same\"\n",
        "                )\n",
        "            )\n",
        "\n",
        "        for i in range(num_convs):\n",
        "            self.blocks.append(\n",
        "                nn.Conv2d(\n",
        "                    in_channels=in_channels if i == 0 else filters,\n",
        "                    out_channels=filters,\n",
        "                    kernel_size=kernel_size,\n",
        "                    stride=1,\n",
        "                    padding=\"same\",\n",
        "                    bias=use_bias\n",
        "                )\n",
        "            )\n",
        "\n",
        "            if batch_norm:\n",
        "                self.blocks.append(\n",
        "                    nn.BatchNorm2d(filters)\n",
        "                )\n",
        "\n",
        "            self.blocks.append(\n",
        "                get_act_fn(activation)  \n",
        "            )\n",
        "\n",
        "\n",
        "        if pool and not pool_before_convs:\n",
        "            self.blocks.append(\n",
        "                MaxPool2dWithSamePadding(\n",
        "                    kernel_size=2,\n",
        "                    stride=pooling_stride,\n",
        "                    padding=\"same\"\n",
        "                )\n",
        "            )\n",
        "\n",
        "        self.blocks = nn.Sequential(*self.blocks)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.blocks(x)\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self,\n",
        "        in_channels: int = 3,\n",
        "        filters: int = 64,\n",
        "        down_blocks: int = 4, \n",
        "        filters_rate: Union[float, int] = 2,\n",
        "        current_stride: int = 2,\n",
        "        stem_blocks: int = 0,\n",
        "        convs_per_block: int = 2,\n",
        "        kernel_size: Union[int, Tuple[int, int]] = 3,\n",
        "        middle_block: bool = True,\n",
        "        block_contraction: bool = False\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.filters = filters\n",
        "        self.down_blocks = down_blocks\n",
        "        self.filters_rate = filters_rate\n",
        "        self.current_stride = current_stride\n",
        "        self.stem_blocks = stem_blocks\n",
        "        self.convs_per_block = convs_per_block\n",
        "        self.kernel_size = kernel_size\n",
        "        self.middle_block = middle_block\n",
        "        self.block_contraction = block_contraction\n",
        "\n",
        "        self.encoder_stack = nn.ModuleList([])\n",
        "        for block in range(down_blocks):\n",
        "            prev_block_filters = -1 if block==0 else block_filters\n",
        "            block_filters = int(\n",
        "                filters * (filters_rate ** (block + stem_blocks))\n",
        "            )\n",
        "\n",
        "            self.encoder_stack.append(\n",
        "                SimpleConvBlock(\n",
        "                    in_channels=in_channels if block == 0 else prev_block_filters,\n",
        "                    pool=(block > 0),\n",
        "                    pool_before_convs=True,\n",
        "                    pooling_stride=2,\n",
        "                    num_convs=convs_per_block,\n",
        "                    filters=block_filters,\n",
        "                    kernel_size=kernel_size,\n",
        "                    use_bias=True,\n",
        "                    batch_norm=False,\n",
        "                    activation=\"relu\"\n",
        "                )\n",
        "            )\n",
        "        after_block_filters = block_filters\n",
        "\n",
        "        self.encoder_stack.append(\n",
        "            MaxPool2dWithSamePadding(\n",
        "                kernel_size=2,\n",
        "                stride=2,\n",
        "                padding=\"same\"\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Create a middle block (like the CARE implementation).\n",
        "        if middle_block:\n",
        "            if convs_per_block > 1:\n",
        "                # First convs are one exponent higher than the last encoder block.\n",
        "                block_filters = int(\n",
        "                    filters * (filters_rate ** (down_blocks + stem_blocks))\n",
        "                )\n",
        "                self.encoder_stack.append(\n",
        "                    SimpleConvBlock(\n",
        "                        in_channels=after_block_filters,\n",
        "                        pool=False,\n",
        "                        pool_before_convs=False,\n",
        "                        pooling_stride=2,\n",
        "                        num_convs=convs_per_block - 1,\n",
        "                        filters=block_filters,\n",
        "                        kernel_size=kernel_size,\n",
        "                        use_bias=True,\n",
        "                        batch_norm=False,\n",
        "                        activation=\"relu\",\n",
        "                    )\n",
        "                )\n",
        "\n",
        "            if block_contraction:\n",
        "                # Contract the channels with an exponent lower than the last encoder block.\n",
        "                block_filters = int(\n",
        "                    filters * (filters_rate ** (down_blocks + stem_blocks - 1))\n",
        "                )\n",
        "            else:\n",
        "                # Keep the block output filters the same.\n",
        "                block_filters = int(\n",
        "                    filters * (filters_rate ** (down_blocks + stem_blocks))\n",
        "                )\n",
        "\n",
        "            self.encoder_stack.append(\n",
        "                SimpleConvBlock(\n",
        "                    in_channels=block_filters,\n",
        "                    pool=False,\n",
        "                    pool_before_convs=False,\n",
        "                    pooling_stride=2,\n",
        "                    num_convs=1,\n",
        "                    filters=block_filters,\n",
        "                    kernel_size=kernel_size,\n",
        "                    use_bias=True,\n",
        "                    batch_norm=False,\n",
        "                    activation=\"relu\",\n",
        "                )\n",
        "            )\n",
        "\n",
        "        self.intermediate_features = {}\n",
        "        for i, block in enumerate(self.encoder_stack):\n",
        "            if isinstance(block, SimpleConvBlock) and block.pool:\n",
        "                current_stride *= block.pooling_stride\n",
        "\n",
        "            if current_stride not in self.intermediate_features.values():\n",
        "                self.intermediate_features[i] = current_stride\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        features = []\n",
        "        for i in range(len(self.encoder_stack)):\n",
        "            x = self.encoder_stack[i](x)\n",
        "            \n",
        "            if i in self.intermediate_features.keys():\n",
        "                features.append(x)\n",
        "\n",
        "        return x, features[1:][::-1]\n",
        "\n",
        "class SimpleUpsamplingBlock(nn.Module):\n",
        "    def __init__(self,\n",
        "        x_in_shape: int, \n",
        "        current_stride: int,\n",
        "        upsampling_stride: int = 2,\n",
        "        interp_method: Text = \"bilinear\",\n",
        "        refine_convs: int = 2,\n",
        "        refine_convs_filters: int = 64,\n",
        "        refine_convs_kernel_size: int = 3,\n",
        "        refine_convs_use_bias: bool = True,\n",
        "        refine_convs_batch_norm: bool = True,\n",
        "        refine_convs_batch_norm_before_activation: bool = True,\n",
        "        refine_convs_activation: Text = \"relu\"\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.x_in_shape = x_in_shape\n",
        "        self.current_stride = current_stride\n",
        "        self.upsampling_stride = upsampling_stride\n",
        "        self.interp_method = interp_method\n",
        "        self.refine_convs = refine_convs\n",
        "        self.refine_convs_filters = refine_convs_filters\n",
        "        self.refine_convs_kernel_size = refine_convs_kernel_size\n",
        "        self.refine_convs_use_bias = refine_convs_use_bias\n",
        "        self.refine_convs_batch_norm = refine_convs_batch_norm\n",
        "        self.refine_convs_batch_norm_before_activation = refine_convs_batch_norm_before_activation\n",
        "        self.refine_convs_activation = refine_convs_activation\n",
        "\n",
        "        self.blocks = nn.ModuleList([])\n",
        "        if current_stride is not None:\n",
        "            # Append the strides to the block prefix.\n",
        "            new_stride = current_stride // upsampling_stride\n",
        "\n",
        "        # Upsample via interpolation.\n",
        "        self.blocks.append(\n",
        "            nn.Upsample(\n",
        "                scale_factor=upsampling_stride,\n",
        "                mode=interp_method,\n",
        "            )\n",
        "        )\n",
        "\n",
        "\n",
        "        # Add further convolutions to refine after upsampling and/or skip.\n",
        "        for i in range(refine_convs):\n",
        "            filters = refine_convs_filters\n",
        "            self.blocks.append(\n",
        "                nn.Conv2d(\n",
        "                    in_channels=x_in_shape if i==0 else filters,\n",
        "                    out_channels=filters,\n",
        "                    kernel_size=refine_convs_kernel_size,\n",
        "                    stride=1,\n",
        "                    padding=\"same\",\n",
        "                    bias=refine_convs_use_bias\n",
        "                )\n",
        "            )\n",
        "\n",
        "            if (\n",
        "                refine_convs_batch_norm\n",
        "                and refine_convs_batch_norm_before_activation\n",
        "            ):\n",
        "                self.blocks.append(nn.BatchNorm2d(num_features=filters))\n",
        "\n",
        "\n",
        "            self.blocks.append(\n",
        "                get_act_fn(refine_convs_activation)  \n",
        "            )\n",
        "\n",
        "            if (\n",
        "                refine_convs_batch_norm\n",
        "                and not refine_convs_batch_norm_before_activation\n",
        "            ):\n",
        "                self.blocks.append(nn.BatchNorm2d(num_features=filters))\n",
        "\n",
        "\n",
        "    def forward(self, x: torch.Tensor, feature: torch.Tensor) -> torch.Tensor:\n",
        "        for idx, b in enumerate(self.blocks):\n",
        "            if idx == 1:  # Right after upsampling or convtranspose2d.\n",
        "                x = torch.concat((x, feature), dim=1)\n",
        "            x = b(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self,\n",
        "        x_in_shape: int,\n",
        "        current_stride: int,\n",
        "        filters: int = 64,\n",
        "        up_blocks: int = 4,\n",
        "        down_blocks: int = 3,\n",
        "        filters_rate: int = 2,\n",
        "        stem_blocks: int = 0,\n",
        "        convs_per_block: int = 2,\n",
        "        kernel_size: int = 3,\n",
        "        block_contraction: bool = False\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.x_in_shape = x_in_shape\n",
        "        self.current_stride = current_stride\n",
        "        self.filters = filters\n",
        "        self.up_blocks = up_blocks\n",
        "        self.down_blocks = down_blocks\n",
        "        self.filters_rate = filters_rate\n",
        "        self.stem_blocks = stem_blocks\n",
        "        self.convs_per_block = convs_per_block\n",
        "        self.kernel_size = kernel_size\n",
        "        self.block_contraction = block_contraction\n",
        "\n",
        "        self.decoder_stack = nn.ModuleList([])\n",
        "        for block in range(up_blocks):\n",
        "            prev_block_filters_in = -1 if block == 0 else block_filters_in\n",
        "            block_filters_in = int(\n",
        "                filters\n",
        "                * (\n",
        "                    filters_rate\n",
        "                    ** (down_blocks + stem_blocks - 1 - block)\n",
        "                )\n",
        "            )\n",
        "            if block_contraction:\n",
        "                block_filters_out = int(\n",
        "                    filters\n",
        "                    * (\n",
        "                        filters_rate\n",
        "                        ** (down_blocks + stem_blocks - 2 - block)\n",
        "                    )\n",
        "                )\n",
        "            else:\n",
        "                block_filters_out = block_filters_in\n",
        "\n",
        "            next_stride = current_stride // 2\n",
        "\n",
        "            self.decoder_stack.append(\n",
        "                SimpleUpsamplingBlock(\n",
        "                    x_in_shape=(x_in_shape + block_filters_in) if block == 0 else (prev_block_filters_in + block_filters_in), \n",
        "                    current_stride=current_stride,\n",
        "                    upsampling_stride=2,\n",
        "                    interp_method=\"bilinear\",\n",
        "                    refine_convs=self.convs_per_block,\n",
        "                    refine_convs_filters=block_filters_out,\n",
        "                    refine_convs_kernel_size=self.kernel_size,\n",
        "                    refine_convs_batch_norm=False,\n",
        "                )\n",
        "            )\n",
        "\n",
        "            current_stride = next_stride\n",
        "\n",
        "    def forward(self, x: torch.Tensor, features: List[torch.Tensor]) -> torch.Tensor:\n",
        "        for i in range(len(self.decoder_stack)):\n",
        "            x = self.decoder_stack[i](x, features[i])\n",
        "\n",
        "        return x\n",
        "\n",
        "class Unet(nn.Module):\n",
        "    def __init__(self,\n",
        "        in_channels: int = 1,\n",
        "        kernel_size: int = 3,\n",
        "        filters: int = 32,\n",
        "        filters_rate: int = 1.5,\n",
        "        stem_blocks: int = 0,\n",
        "        down_blocks: int = 4, \n",
        "        up_blocks: int = 3,\n",
        "        convs_per_block: int = 2,\n",
        "        middle_block: bool = True,\n",
        "        block_contraction: bool = False\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.enc = Encoder(\n",
        "            in_channels=in_channels,\n",
        "            filters=filters,\n",
        "            down_blocks=down_blocks,\n",
        "            filters_rate=filters_rate,\n",
        "            stem_blocks=stem_blocks,\n",
        "            convs_per_block=convs_per_block,\n",
        "            kernel_size=kernel_size,\n",
        "            middle_block=middle_block,\n",
        "            block_contraction=block_contraction\n",
        "        )\n",
        "\n",
        "        current_stride = int(\n",
        "            np.prod(\n",
        "                [block.pooling_stride for block in self.enc.encoder_stack if hasattr(block, \"pool\") and block.pool]\n",
        "                + [1]\n",
        "            )\n",
        "        )\n",
        "        \n",
        "        x_in_shape = int(\n",
        "            filters * (filters_rate ** (down_blocks + stem_blocks))\n",
        "        )\n",
        "\n",
        "        self.dec = Decoder(x_in_shape=x_in_shape, current_stride=current_stride, filters=filters,\n",
        "            up_blocks=up_blocks, down_blocks=down_blocks, filters_rate=filters_rate\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x, features = self.enc(x)\n",
        "        x = self.dec(x, features)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "fCMnTHR9VetA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEfgZT4hLyW4"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filters = 32\n",
        "filters_rate = 1.5\n",
        "down_blocks = 4\n",
        "stem_blocks = 0\n",
        "up_blocks = 3\n",
        "\n",
        "unet = Unet(filters=filters, \n",
        "            filters_rate=filters_rate, \n",
        "            down_blocks=down_blocks, \n",
        "            stem_blocks=stem_blocks, \n",
        "            up_blocks=up_blocks)\n",
        "\n",
        "in_channels = int(\n",
        "    filters\n",
        "    * (\n",
        "        filters_rate\n",
        "        ** (down_blocks + stem_blocks - 1 - up_blocks + 1)\n",
        "    )\n",
        ")\n",
        "model = nn.Sequential(*[\n",
        "    unet, \n",
        "    nn.Conv2d(in_channels=in_channels, out_channels=13, kernel_size=1, padding=\"same\")    \n",
        "])\n",
        "\n",
        "opt = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "scaler = torch.cuda.amp.GradScaler()"
      ],
      "metadata": {
        "id": "QoSLDG5OXWRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "\n",
        "cores = multiprocessing.cpu_count()\n",
        "cores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFNfmlnprhmb",
        "outputId": "fc5c1efe-9cfd-4eff-cd51-58f6ced9f3f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = DataGenerator(labels)\n",
        "train_dl = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=4,\n",
        "    shuffle=True,\n",
        "    num_workers=cores,\n",
        "    pin_memory=True,\n",
        "    drop_last=True,\n",
        "    prefetch_factor=2\n",
        ")\n",
        "\n",
        "val_ds = DataGenerator(val_labels, is_train=False)\n",
        "val_dl = DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=4,\n",
        "    shuffle=False,\n",
        "    num_workers=cores,\n",
        "    pin_memory=True,\n",
        "    drop_last=True,\n",
        "    prefetch_factor=2\n",
        ")"
      ],
      "metadata": {
        "id": "MQgZkAySXpO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = val_ds[0]\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(x[0].permute(1, 2, 0))\n",
        "plt.imshow(x[1].numpy().max(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "mNBBtJV7dIjw",
        "outputId": "7bc47b02-8920-45d4-9d35-89dd02355fc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fd4c6a2ed40>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze > requirements.txt\n",
        "\n",
        "# Some of this code is redundant. I kept the previous cells un-deleted just for reference.\n",
        "for i in range(5): \n",
        "    train_ds = DataGenerator(labels)\n",
        "    train_dl = DataLoader(\n",
        "        train_ds,\n",
        "        batch_size=4,\n",
        "        shuffle=True,\n",
        "        num_workers=cores,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "        prefetch_factor=2\n",
        "    )\n",
        "\n",
        "    val_ds = DataGenerator(val_labels, is_train=False)\n",
        "    val_dl = DataLoader(\n",
        "        val_ds,\n",
        "        batch_size=4,\n",
        "        shuffle=False,\n",
        "        num_workers=cores,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "        prefetch_factor=2\n",
        "    )\n",
        "\n",
        "    unet = Unet(filters=filters, \n",
        "                filters_rate=filters_rate, \n",
        "                down_blocks=down_blocks, \n",
        "                stem_blocks=stem_blocks, \n",
        "                up_blocks=up_blocks)\n",
        "\n",
        "    in_channels = int(\n",
        "        filters\n",
        "        * (\n",
        "            filters_rate\n",
        "            ** (down_blocks + stem_blocks - 1 - up_blocks + 1)\n",
        "        )\n",
        "    )\n",
        "    model = nn.Sequential(*[\n",
        "        unet, \n",
        "        nn.Conv2d(in_channels=in_channels, out_channels=13, kernel_size=1, padding=\"same\")    \n",
        "    ])\n",
        "\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "    model = model.to(\"cuda\")\n",
        "\n",
        "    run = wandb.init(\n",
        "        project=\"torch_vs_tf_talmo_lab\", \n",
        "        name=f\"torch_baseline_run{i}\", \n",
        "        config={\n",
        "            \"is_tf\": False,\n",
        "            \"device_and_memory\": get_vram(),\n",
        "            \"seed\": seed,\n",
        "            \"model_param_count\": get_param_count(model)\n",
        "        }, \n",
        "        tags=[\"baseline\"],\n",
        "        notes=\"This experiment was done in a Google Colab Notebook.\"\n",
        "    )\n",
        "\n",
        "    # Log dependencies.\n",
        "    artifact = wandb.Artifact(\"Dependencies\", type=\"dependencies\")\n",
        "    artifact.add_file(\"requirements.txt\", name=f\"requirements.txt\")\n",
        "    run.log_artifact(artifact)\n",
        "\n",
        "    for epoch in range(3):\n",
        "        _ = model.train()\n",
        "        start_time = time.time()\n",
        "        train_loss = 0\n",
        "        for idx, batch in enumerate(train_dl):\n",
        "            X, y = batch\n",
        "            X = X.to(\"cuda\")\n",
        "            y = y.to(\"cuda\")\n",
        "            \n",
        "            with torch.autocast(\"cuda\"):\n",
        "                y_preds = model(X)\n",
        "                loss = nn.MSELoss()(y_preds, y)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(opt)\n",
        "            scaler.update()\n",
        "            opt.zero_grad()\n",
        "                    \n",
        "            if idx % 100 == 0:\n",
        "              print(f\"Epoch: {epoch} | Loss: {loss:.5f}\")\n",
        "\n",
        "            train_loss += loss\n",
        "\n",
        "        train_loss /= (idx+1)\n",
        "        train_time = time.time() - start_time\n",
        "        print(f\"TRAIN: --- {train_time}s seconds ---\")\n",
        "\n",
        "        _  = model.eval()\n",
        "        start_time = time.time()\n",
        "        val_loss = 0\n",
        "        for idx, batch in enumerate(val_dl):\n",
        "            X, y = batch\n",
        "            X = X.to(\"cuda\")\n",
        "            y = y.to(\"cuda\")\n",
        "\n",
        "            with torch.no_grad():\n",
        "                y_preds = model(X)\n",
        "                loss = nn.MSELoss()(y_preds, y)\n",
        "\n",
        "            val_loss += loss\n",
        "\n",
        "        val_loss /= (idx+1)\n",
        "        val_time = time.time() - start_time\n",
        "        print(f\"VAL: --- {val_time}s seconds ---\")\n",
        "\n",
        "        run.log({\n",
        "            \"train_loss\": train_loss,\n",
        "            \"val_loss\": val_loss,\n",
        "            \"train_time\": train_time,\n",
        "            \"val_time\": val_time,\n",
        "            \"total_time\": train_time + val_time\n",
        "        })\n",
        "\n",
        "    del model, opt, scaler, train_ds, train_dl, val_ds, val_dl\n",
        "    gc.collect()\n",
        "    run.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2ba595c04b184a5ebb825ab243056cd2",
            "1204337a78e94b5cb373221575f4b85b",
            "1aad45af0010477387ac725c9d590809",
            "3694b754c67942fe9d29a491a5de3fc4",
            "9fe7c9770bb04ba680a16b6a4a07819a",
            "cb11a672ec3c45a5a8333668c335302c",
            "25edb8df3df8454499b4624bf99366fb",
            "144f76bf9dc641bebcf23ba805f081b7",
            "b521237ca6714d7a885f6353f55ea827",
            "0fc1afd13aa74548a3158fcfab2c687b",
            "116d13148ac2436f85e06182aba64f70",
            "de0eddee21ac47dc9c286fc953efba4c",
            "520d42cced494dd6aa40dd66da9a301c",
            "54921a9daff44a90af4dcc65d656dadf",
            "0d1ffbd90b04419ebc1d2a3d3e625a11",
            "048e850689aa4d48922b2a3540d5a881"
          ]
        },
        "id": "tDMSgbrrY7E0",
        "outputId": "2e927cbd-87df-4c0b-91de-d8fb1bbef814"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230508_015038-w8uf5804</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab/runs/w8uf5804' target=\"_blank\">torch_baseline_run0</a></strong> to <a href='https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab' target=\"_blank\">https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab/runs/w8uf5804' target=\"_blank\">https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab/runs/w8uf5804</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Loss: 0.05765\n",
            "Epoch: 0 | Loss: 0.00039\n",
            "Epoch: 0 | Loss: 0.00031\n",
            "Epoch: 0 | Loss: 0.00029\n",
            "Epoch: 0 | Loss: 0.00028\n",
            "Epoch: 0 | Loss: 0.00027\n",
            "Epoch: 0 | Loss: 0.00028\n",
            "Epoch: 0 | Loss: 0.00027\n",
            "TRAIN: --- 61.90218806266785s seconds ---\n",
            "VAL: --- 5.363032579421997s seconds ---\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "TRAIN: --- 60.95778775215149s seconds ---\n",
            "VAL: --- 4.487998008728027s seconds ---\n",
            "Epoch: 2 | Loss: 0.00026\n",
            "Epoch: 2 | Loss: 0.00027\n",
            "Epoch: 2 | Loss: 0.00027\n",
            "Epoch: 2 | Loss: 0.00026\n",
            "Epoch: 2 | Loss: 0.00026\n",
            "Epoch: 2 | Loss: 0.00027\n",
            "Epoch: 2 | Loss: 0.00026\n",
            "Epoch: 2 | Loss: 0.00026\n",
            "TRAIN: --- 61.70762300491333s seconds ---\n",
            "VAL: --- 6.7731897830963135s seconds ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.009 MB of 0.009 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ba595c04b184a5ebb825ab243056cd2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>total_time</td><td>▅▁█</td></tr><tr><td>train_loss</td><td>█▁▁</td></tr><tr><td>train_time</td><td>█▁▇</td></tr><tr><td>val_loss</td><td>█▅▁</td></tr><tr><td>val_time</td><td>▄▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_time</td><td>68.48081</td></tr><tr><td>train_loss</td><td>0.00026</td></tr><tr><td>train_time</td><td>61.70762</td></tr><tr><td>val_loss</td><td>0.00026</td></tr><tr><td>val_time</td><td>6.77319</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">torch_baseline_run0</strong> at: <a href='https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab/runs/w8uf5804' target=\"_blank\">https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab/runs/w8uf5804</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230508_015038-w8uf5804/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230508_015407-ijnppgp9</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab/runs/ijnppgp9' target=\"_blank\">torch_baseline_run1</a></strong> to <a href='https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab' target=\"_blank\">https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab/runs/ijnppgp9' target=\"_blank\">https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab/runs/ijnppgp9</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Loss: 0.01179\n",
            "Epoch: 0 | Loss: 0.00042\n",
            "Epoch: 0 | Loss: 0.00030\n",
            "Epoch: 0 | Loss: 0.00028\n",
            "Epoch: 0 | Loss: 0.00028\n",
            "Epoch: 0 | Loss: 0.00027\n",
            "Epoch: 0 | Loss: 0.00027\n",
            "Epoch: 0 | Loss: 0.00027\n",
            "TRAIN: --- 62.089590549468994s seconds ---\n",
            "VAL: --- 6.622607231140137s seconds ---\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00026\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "TRAIN: --- 60.57106566429138s seconds ---\n",
            "VAL: --- 4.546804428100586s seconds ---\n",
            "Epoch: 2 | Loss: 0.00027\n",
            "Epoch: 2 | Loss: 0.00026\n",
            "Epoch: 2 | Loss: 0.00027\n",
            "Epoch: 2 | Loss: 0.00026\n",
            "Epoch: 2 | Loss: 0.00026\n",
            "Epoch: 2 | Loss: 0.00027\n",
            "Epoch: 2 | Loss: 0.00026\n",
            "Epoch: 2 | Loss: 0.00026\n",
            "TRAIN: --- 61.66666841506958s seconds ---\n",
            "VAL: --- 6.935873508453369s seconds ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>total_time</td><td>█▁█</td></tr><tr><td>train_loss</td><td>█▁▁</td></tr><tr><td>train_time</td><td>█▁▆</td></tr><tr><td>val_loss</td><td>█▆▁</td></tr><tr><td>val_time</td><td>▇▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_time</td><td>68.60254</td></tr><tr><td>train_loss</td><td>0.00026</td></tr><tr><td>train_time</td><td>61.66667</td></tr><tr><td>val_loss</td><td>0.00026</td></tr><tr><td>val_time</td><td>6.93587</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">torch_baseline_run1</strong> at: <a href='https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab/runs/ijnppgp9' target=\"_blank\">https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab/runs/ijnppgp9</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230508_015407-ijnppgp9/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230508_015738-ktcap5ef</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab/runs/ktcap5ef' target=\"_blank\">torch_baseline_run2</a></strong> to <a href='https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab' target=\"_blank\">https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab/runs/ktcap5ef' target=\"_blank\">https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab/runs/ktcap5ef</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Loss: 0.01598\n",
            "Epoch: 0 | Loss: 0.00037\n",
            "Epoch: 0 | Loss: 0.00029\n",
            "Epoch: 0 | Loss: 0.00028\n",
            "Epoch: 0 | Loss: 0.00027\n",
            "Epoch: 0 | Loss: 0.00027\n",
            "Epoch: 0 | Loss: 0.00027\n",
            "Epoch: 0 | Loss: 0.00027\n",
            "TRAIN: --- 60.84874200820923s seconds ---\n",
            "VAL: --- 7.674442291259766s seconds ---\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "TRAIN: --- 60.553605794906616s seconds ---\n",
            "VAL: --- 4.426493167877197s seconds ---\n",
            "Epoch: 2 | Loss: 0.00027\n",
            "Epoch: 2 | Loss: 0.00026\n",
            "Epoch: 2 | Loss: 0.00027\n",
            "Epoch: 2 | Loss: 0.00027\n",
            "Epoch: 2 | Loss: 0.00027\n",
            "Epoch: 2 | Loss: 0.00027\n",
            "Epoch: 2 | Loss: 0.00026\n",
            "Epoch: 2 | Loss: 0.00026\n",
            "TRAIN: --- 60.60034894943237s seconds ---\n",
            "VAL: --- 6.059931516647339s seconds ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b521237ca6714d7a885f6353f55ea827"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>total_time</td><td>█▁▄</td></tr><tr><td>train_loss</td><td>█▁▁</td></tr><tr><td>train_time</td><td>█▁▂</td></tr><tr><td>val_loss</td><td>▇█▁</td></tr><tr><td>val_time</td><td>█▁▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_time</td><td>66.66028</td></tr><tr><td>train_loss</td><td>0.00027</td></tr><tr><td>train_time</td><td>60.60035</td></tr><tr><td>val_loss</td><td>0.00026</td></tr><tr><td>val_time</td><td>6.05993</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">torch_baseline_run2</strong> at: <a href='https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab/runs/ktcap5ef' target=\"_blank\">https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab/runs/ktcap5ef</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230508_015738-ktcap5ef/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230508_020105-zp7oiapj</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab/runs/zp7oiapj' target=\"_blank\">torch_baseline_run3</a></strong> to <a href='https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab' target=\"_blank\">https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab/runs/zp7oiapj' target=\"_blank\">https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab/runs/zp7oiapj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Loss: 0.01348\n",
            "Epoch: 0 | Loss: 0.00039\n",
            "Epoch: 0 | Loss: 0.00030\n",
            "Epoch: 0 | Loss: 0.00028\n",
            "Epoch: 0 | Loss: 0.00028\n",
            "Epoch: 0 | Loss: 0.00028\n",
            "Epoch: 0 | Loss: 0.00027\n",
            "Epoch: 0 | Loss: 0.00027\n",
            "TRAIN: --- 60.38003468513489s seconds ---\n",
            "VAL: --- 4.630315780639648s seconds ---\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "TRAIN: --- 61.47210144996643s seconds ---\n",
            "VAL: --- 6.7383105754852295s seconds ---\n",
            "Epoch: 2 | Loss: 0.00027\n",
            "Epoch: 2 | Loss: 0.00027\n",
            "Epoch: 2 | Loss: 0.00026\n",
            "Epoch: 2 | Loss: 0.00027\n",
            "Epoch: 2 | Loss: 0.00027\n",
            "Epoch: 2 | Loss: 0.00027\n",
            "Epoch: 2 | Loss: 0.00027\n",
            "Epoch: 2 | Loss: 0.00027\n",
            "TRAIN: --- 60.27229404449463s seconds ---\n",
            "VAL: --- 4.594135284423828s seconds ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>total_time</td><td>▁█▁</td></tr><tr><td>train_loss</td><td>█▁▁</td></tr><tr><td>train_time</td><td>▂█▁</td></tr><tr><td>val_loss</td><td>█▆▁</td></tr><tr><td>val_time</td><td>▁█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_time</td><td>64.86643</td></tr><tr><td>train_loss</td><td>0.00027</td></tr><tr><td>train_time</td><td>60.27229</td></tr><tr><td>val_loss</td><td>0.00027</td></tr><tr><td>val_time</td><td>4.59414</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">torch_baseline_run3</strong> at: <a href='https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab/runs/zp7oiapj' target=\"_blank\">https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab/runs/zp7oiapj</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230508_020105-zp7oiapj/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230508_020431-bi7ks5xt</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab/runs/bi7ks5xt' target=\"_blank\">torch_baseline_run4</a></strong> to <a href='https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab' target=\"_blank\">https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab/runs/bi7ks5xt' target=\"_blank\">https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab/runs/bi7ks5xt</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Loss: 0.01230\n",
            "Epoch: 0 | Loss: 0.00036\n",
            "Epoch: 0 | Loss: 0.00029\n",
            "Epoch: 0 | Loss: 0.00028\n",
            "Epoch: 0 | Loss: 0.00028\n",
            "Epoch: 0 | Loss: 0.00028\n",
            "Epoch: 0 | Loss: 0.00027\n",
            "Epoch: 0 | Loss: 0.00027\n",
            "TRAIN: --- 60.87558054924011s seconds ---\n",
            "VAL: --- 5.160505056381226s seconds ---\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "TRAIN: --- 60.674776554107666s seconds ---\n",
            "VAL: --- 4.444064378738403s seconds ---\n",
            "Epoch: 2 | Loss: 0.00027\n",
            "Epoch: 2 | Loss: 0.00027\n",
            "Epoch: 2 | Loss: 0.00027\n",
            "Epoch: 2 | Loss: 0.00026\n",
            "Epoch: 2 | Loss: 0.00027\n",
            "Epoch: 2 | Loss: 0.00027\n",
            "Epoch: 2 | Loss: 0.00027\n",
            "Epoch: 2 | Loss: 0.00026\n",
            "TRAIN: --- 61.47237944602966s seconds ---\n",
            "VAL: --- 7.126594066619873s seconds ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>total_time</td><td>▃▁█</td></tr><tr><td>train_loss</td><td>█▁▁</td></tr><tr><td>train_time</td><td>▃▁█</td></tr><tr><td>val_loss</td><td>█▄▁</td></tr><tr><td>val_time</td><td>▃▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_time</td><td>68.59897</td></tr><tr><td>train_loss</td><td>0.00027</td></tr><tr><td>train_time</td><td>61.47238</td></tr><tr><td>val_loss</td><td>0.00027</td></tr><tr><td>val_time</td><td>7.12659</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">torch_baseline_run4</strong> at: <a href='https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab/runs/bi7ks5xt' target=\"_blank\">https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab/runs/bi7ks5xt</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230508_020431-bi7ks5xt/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l_K2JBrPZQVC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}