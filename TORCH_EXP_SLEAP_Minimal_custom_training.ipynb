{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "toc_visible": true,
      "gpuType": "T4",
      "collapsed_sections": [
        "BeeqrLbdupmE",
        "PWl3cG1_9WTK",
        "wSdTJYOdu4L6",
        "5lugn7a_HC0Q",
        "-vYsPusvviiu",
        "0yo95XzRKkba",
        "jzMa-PNPqxxA"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e6afb446b83246939f5708949bbcf3fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_261a86cec67b4262b199ff6a02c165d3",
              "IPY_MODEL_f0117dc5ad3344eb81970230186fa149",
              "IPY_MODEL_59e753d977a240bbb70a2516fdcace09"
            ],
            "layout": "IPY_MODEL_46ca895cc5b3433ea224114fb6ca8f1a"
          }
        },
        "261a86cec67b4262b199ff6a02c165d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d6839e4ebff49b99a7df9b7b276fcdd",
            "placeholder": "​",
            "style": "IPY_MODEL_b5ea6358d0cb410d8994b8147f93c4be",
            "value": "Sanity Checking DataLoader 0: 100%"
          }
        },
        "f0117dc5ad3344eb81970230186fa149": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da77746737854fdf97be9622a18a5faa",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cab20c753c5d4f75b82b049f4128243c",
            "value": 2
          }
        },
        "59e753d977a240bbb70a2516fdcace09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c708750e5a04440a6ef504a300b34e2",
            "placeholder": "​",
            "style": "IPY_MODEL_b7d6f5896f924111af7da17a2fea7806",
            "value": " 2/2 [00:00&lt;00:00, 31.18it/s]"
          }
        },
        "46ca895cc5b3433ea224114fb6ca8f1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "5d6839e4ebff49b99a7df9b7b276fcdd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5ea6358d0cb410d8994b8147f93c4be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da77746737854fdf97be9622a18a5faa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cab20c753c5d4f75b82b049f4128243c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5c708750e5a04440a6ef504a300b34e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7d6f5896f924111af7da17a2fea7806": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3c2d99bc96342918928184c0f2a4a3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c2c9be77aadb44ae87c3264d0dc17954",
              "IPY_MODEL_273013541ed3464c9b3a613c210e75ee",
              "IPY_MODEL_72965da02c1048838715b6abb99c2603"
            ],
            "layout": "IPY_MODEL_fd41dc4b208e43c1ba5ddd131d2770e1"
          }
        },
        "c2c9be77aadb44ae87c3264d0dc17954": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_044fb27e052846b08faff9643a862717",
            "placeholder": "​",
            "style": "IPY_MODEL_fcea6c030fca4e339584636269f7c757",
            "value": "Epoch 0: 100%"
          }
        },
        "273013541ed3464c9b3a613c210e75ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7586fcf8b16142d3af4e0173055ab268",
            "max": 800,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_93fcf1f1304745eb8dc2e8e30de56ef5",
            "value": 800
          }
        },
        "72965da02c1048838715b6abb99c2603": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5af486cc45414581ba6a2c4cb6cbf72c",
            "placeholder": "​",
            "style": "IPY_MODEL_34938f6a525d409b8e702251693ed6df",
            "value": " 800/800 [01:05&lt;00:00, 12.14it/s]"
          }
        },
        "fd41dc4b208e43c1ba5ddd131d2770e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "044fb27e052846b08faff9643a862717": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcea6c030fca4e339584636269f7c757": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7586fcf8b16142d3af4e0173055ab268": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93fcf1f1304745eb8dc2e8e30de56ef5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5af486cc45414581ba6a2c4cb6cbf72c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34938f6a525d409b8e702251693ed6df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5cbea487bfdc439aa6e2960d0d4946c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4baf45822bff42158b3224c068117201",
              "IPY_MODEL_ad0bf3aff7af450383531a07663ec086",
              "IPY_MODEL_39acb089108f4a66b57b96eb5e090a26"
            ],
            "layout": "IPY_MODEL_dfb3e52b72b14eb99b6134f9e4e07e07"
          }
        },
        "4baf45822bff42158b3224c068117201": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f7de84447654001860637ff6e2834f2",
            "placeholder": "​",
            "style": "IPY_MODEL_5809b25ca26a4845830f08d9634ee577",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "ad0bf3aff7af450383531a07663ec086": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_289b41b1b763430eb2482a65b6765fef",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f96ccfe712cb471593adc22567b5ebf7",
            "value": 100
          }
        },
        "39acb089108f4a66b57b96eb5e090a26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_995c5f76c6284750ab6d605e5dd0f994",
            "placeholder": "​",
            "style": "IPY_MODEL_8d9a2a50948b4f1dadbb640da3fc7ba2",
            "value": " 100/100 [00:08&lt;00:00, 12.24it/s]"
          }
        },
        "dfb3e52b72b14eb99b6134f9e4e07e07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "4f7de84447654001860637ff6e2834f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5809b25ca26a4845830f08d9634ee577": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "289b41b1b763430eb2482a65b6765fef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f96ccfe712cb471593adc22567b5ebf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "995c5f76c6284750ab6d605e5dd0f994": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d9a2a50948b4f1dadbb640da3fc7ba2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7c41e414e9042faabba01b618e3252f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a95ebfc9c58245019e2eeb7da19d2a1a",
              "IPY_MODEL_60b4338cdb664c2aab5c2c9c150e9374"
            ],
            "layout": "IPY_MODEL_1540532b162e4e9fb19c0135b7651acb"
          }
        },
        "a95ebfc9c58245019e2eeb7da19d2a1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b36402cfec9745b48f48eb16b8b2dbc2",
            "placeholder": "​",
            "style": "IPY_MODEL_ff340bd4454846778ee64ddac03b3336",
            "value": "Waiting for wandb.init()...\r"
          }
        },
        "60b4338cdb664c2aab5c2c9c150e9374": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0920a30aba649f68625bdfb779879c3",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7082f0c0a8094e99bd8e868877f73b22",
            "value": 0.9841738597500012
          }
        },
        "1540532b162e4e9fb19c0135b7651acb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b36402cfec9745b48f48eb16b8b2dbc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff340bd4454846778ee64ddac03b3336": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0920a30aba649f68625bdfb779879c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7082f0c0a8094e99bd8e868877f73b22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeeqrLbdupmE"
      },
      "source": [
        "# Install SLEAP\n",
        "Don't forget to set **Runtime** -> **Change runtime type...** -> **GPU** as the accelerator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYxJ2rJOMW8B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51d31b4e-7841-4bae-dae4-fb7f74641d53"
      },
      "source": [
        "!pip install sleap -qqq\n",
        "!pip install albumentations -qqq\n",
        "!pip install nvidia-ml-py3 -qqq"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.4/64.4 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m107.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.5/60.5 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.9/84.9 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m104.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m78.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m904.1/904.1 kB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.9/228.9 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.3/214.3 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.2/149.2 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.9/131.9 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.2/88.2 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m498.1/498.1 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.1/156.1 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m832.9/832.9 kB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.3/462.3 kB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.2/192.2 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.1/109.1 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m113.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.6/485.6 kB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pykalman (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for jsmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "flax 0.6.9 requires rich>=11.1, but you have rich 10.16.1 which is incompatible.\n",
            "tensorflow-datasets 4.9.2 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jftAOyvvuQeh",
        "outputId": "9b110c1e-2531-4ecb-80c9-077182f3dae1"
      },
      "source": [
        "import os\n",
        "import gc\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "import collections\n",
        "from typing import Sequence, Tuple, Text, Union, Optional, List\n",
        "\n",
        "import nvidia_smi\n",
        "\n",
        "import numpy as np\n",
        "import albumentations as A\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import sleap\n",
        "\n",
        "sleap.versions()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SLEAP: 1.3.0\n",
            "TensorFlow: 2.8.4\n",
            "Numpy: 1.22.4\n",
            "Python: 3.10.11\n",
            "OS: Linux-5.10.147+-x86_64-with-glibc2.31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb -qqq\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "F31Z_dQfA3Hj",
        "outputId": "faec94ee-cc66-4121-dc94-21d46faa6325"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.3/203.3 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "PWl3cG1_9WTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "def get_vram():\n",
        "    nvidia_smi.nvmlInit()\n",
        "\n",
        "    deviceCount = nvidia_smi.nvmlDeviceGetCount()\n",
        "    for i in range(deviceCount):\n",
        "        handle = nvidia_smi.nvmlDeviceGetHandleByIndex(i)\n",
        "        info = nvidia_smi.nvmlDeviceGetMemoryInfo(handle)\n",
        "        output = (\"Device {}: {}, Memory : ({:.2f}% free): {} (total), {} (free), {} (used)\"\n",
        "              .format(i, nvidia_smi.nvmlDeviceGetName(handle), 100*info.free/info.total, \n",
        "                      info.total/(1024 ** 3), info.free/(1024 ** 3), info.used/(1024 ** 3)))\n",
        "\n",
        "    nvidia_smi.nvmlShutdown()\n",
        "\n",
        "    return output\n",
        "\n",
        "def get_param_count(model):\n",
        "  trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "  total_params = sum(p.numel() for p in model.parameters())\n",
        "  nontrainable_params = total_params - trainable_params\n",
        "\n",
        "  return trainable_params, nontrainable_params, total_params"
      ],
      "metadata": {
        "id": "X2ESLmrn9VnH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 42\n",
        "seed_everything(seed)"
      ],
      "metadata": {
        "id": "2pEmfBalS51R"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSdTJYOdu4L6"
      },
      "source": [
        "# Download training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDIF3RKdM86u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22bf15c7-03d5-4e52-a28a-0ab46292f705"
      },
      "source": [
        "!curl -L --output labels.slp https://storage.googleapis.com/sleap-data/datasets/wt_gold.13pt/tracking_split2/train.pkg.slp\n",
        "!ls -lah\n",
        "\n",
        "!curl -L --output val_labels.slp https://storage.googleapis.com/sleap-data/datasets/wt_gold.13pt/tracking_split2/val.pkg.slp\n",
        "!ls -lah"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  619M  100  619M    0     0  48.0M      0  0:00:12  0:00:12 --:--:-- 49.5M\n",
            "total 620M\n",
            "drwxr-xr-x 1 root root 4.0K May 11 06:16 .\n",
            "drwxr-xr-x 1 root root 4.0K May 11 06:11 ..\n",
            "drwxr-xr-x 4 root root 4.0K May  9 13:34 .config\n",
            "-rw-r--r-- 1 root root 620M May 11 06:16 labels.slp\n",
            "drwxr-xr-x 1 root root 4.0K May  9 13:35 sample_data\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 77.2M  100 77.2M    0     0  42.6M      0  0:00:01  0:00:01 --:--:-- 42.6M\n",
            "total 697M\n",
            "drwxr-xr-x 1 root root 4.0K May 11 06:16 .\n",
            "drwxr-xr-x 1 root root 4.0K May 11 06:11 ..\n",
            "drwxr-xr-x 4 root root 4.0K May  9 13:34 .config\n",
            "-rw-r--r-- 1 root root 620M May 11 06:16 labels.slp\n",
            "drwxr-xr-x 1 root root 4.0K May  9 13:35 sample_data\n",
            "-rw-r--r-- 1 root root  78M May 11 06:16 val_labels.slp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lugn7a_HC0Q"
      },
      "source": [
        "# Load the training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMkSIZrTHCMr",
        "outputId": "1a03cffa-9de2-4bda-e9c0-812bd6a115cc"
      },
      "source": [
        "# SLEAP Labels files (.slp) can include the images as well as labeled instances and\n",
        "# other metadata for a project.\n",
        "labels = sleap.load_file(\"labels.slp\")\n",
        "labels = labels.with_user_labels_only()\n",
        "labels.describe()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skeleton: Skeleton(description=None, nodes=[head, thorax, abdomen, wingL, wingR, forelegL4, forelegR4, midlegL4, midlegR4, hindlegL4, hindlegR4, eyeL, eyeR], edges=[thorax->head, thorax->abdomen, thorax->wingL, thorax->wingR, thorax->forelegL4, thorax->forelegR4, thorax->midlegL4, thorax->midlegR4, thorax->hindlegL4, thorax->hindlegR4, head->eyeL, head->eyeR], symmetries=[midlegL4<->midlegR4, wingL<->wingR, forelegL4<->forelegR4, hindlegL4<->hindlegR4, eyeL<->eyeR])\n",
            "Videos: ['labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp']\n",
            "Frames (user/predicted): 1,600/0\n",
            "Instances (user/predicted): 3,200/0\n",
            "Tracks: [Track(spawned_on=0, name='female'), Track(spawned_on=0, name='male')]\n",
            "Suggestions: 0\n",
            "Provenance: {}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's also do the same for the val labels.\n",
        "val_labels = sleap.load_file(\"val_labels.slp\")\n",
        "val_labels = val_labels.with_user_labels_only()\n",
        "val_labels.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sklyy8NWEyff",
        "outputId": "8c5ba43c-3fd3-478a-d161-16666969e4b2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skeleton: Skeleton(description=None, nodes=[head, thorax, abdomen, wingL, wingR, forelegL4, forelegR4, midlegL4, midlegR4, hindlegL4, hindlegR4, eyeL, eyeR], edges=[thorax->head, thorax->abdomen, thorax->wingL, thorax->wingR, thorax->forelegL4, thorax->forelegR4, thorax->midlegL4, thorax->midlegR4, thorax->hindlegL4, thorax->hindlegR4, head->eyeL, head->eyeR], symmetries=[midlegL4<->midlegR4, forelegL4<->forelegR4, hindlegL4<->hindlegR4, eyeL<->eyeR, wingL<->wingR])\n",
            "Videos: ['val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp']\n",
            "Frames (user/predicted): 200/0\n",
            "Instances (user/predicted): 400/0\n",
            "Tracks: [Track(spawned_on=0, name='female'), Track(spawned_on=0, name='male')]\n",
            "Suggestions: 0\n",
            "Provenance: {}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EK8DDPHDHBr_",
        "outputId": "caf9228d-8d76-4b8e-9264-ab484adeec08"
      },
      "source": [
        "# Labels are list-like containers whose elements are LabeledFrames\n",
        "print(f\"Number of labels: {len(labels)}\")\n",
        "\n",
        "labeled_frame = labels[0]\n",
        "labeled_frame"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of labels: 1600\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LabeledFrame(video=HDF5Video('labels.slp'), frame_idx=166050, instances=2)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pP5uXrU3HX6o",
        "outputId": "000e6ed0-b64b-4423-8eae-6f0b0d03b4b8"
      },
      "source": [
        "# LabeledFrames are containers for instances that were labeled in a single frame\n",
        "instance = labeled_frame[0]\n",
        "instance"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Instance(video=Video(filename=labels.slp, shape=(66, 1024, 1024, 1), backend=HDF5Video), frame_idx=166050, points=[head: (491.6, 187.7), thorax: (474.4, 224.8), abdomen: (459.9, 262.2), wingL: (448.3, 271.7), wingR: (452.1, 273.5), forelegL4: (478.5, 175.9), forelegR4: (499.9, 177.9), midlegL4: (440.6, 216.4), midlegR4: (510.1, 242.7), hindlegL4: (437.2, 234.3), hindlegR4: (490.9, 266.7), eyeL: (477.5, 193.2), eyeR: (498.4, 201.2)], track=Track(spawned_on=0, name='female'))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "700fTPs4Hurg",
        "outputId": "161a8bed-2251-40d0-ca5b-a90b3dc58a35"
      },
      "source": [
        "# They can be converted to numpy arrays where each row corresponds to the coordinates\n",
        "# of a different body part:\n",
        "pts = instance.numpy()\n",
        "pts"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "rec.array([[491.58118169, 187.72078779],\n",
              "           [474.3603939 , 224.80196948],\n",
              "           [459.90098474, 262.16236338],\n",
              "           [448.26137864, 271.72078779],\n",
              "           [452.08118169, 273.54059084],\n",
              "           [478.5       , 175.90098474],\n",
              "           [499.94157558, 177.90098474],\n",
              "           [440.58118169, 216.3603939 ],\n",
              "           [510.12177253, 242.72078779],\n",
              "           [         nan,          nan],\n",
              "           [490.90098474, 266.72078779],\n",
              "           [477.54059084, 193.16236338],\n",
              "           [498.40098474, 201.18019695]],\n",
              "          dtype=float64)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vYsPusvviiu"
      },
      "source": [
        "# Setup training data generation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def update_not_shown_nodes(not_shown_nodes, node_names, new_nodes):\n",
        "  nodes_not_in_aug = np.array(list(set(node_names).difference(set(new_nodes))))\n",
        "  not_shown_in_aug_or_original_ind = np.in1d(node_names, nodes_not_in_aug).nonzero()[0]\n",
        "  not_shown_nodes[not_shown_in_aug_or_original_ind] = True \n",
        "\n",
        "  return not_shown_nodes\n",
        "\n",
        "\n",
        "def update_kp(kp, not_shown_nodes, node_names, new_nodes):\n",
        "  shown_after_aug_ind = np.in1d(node_names, new_nodes).nonzero()[0]\n",
        "  shown_ind = np.in1d(not_shown_nodes, True).nonzero()[0]\n",
        "\n",
        "  assert len(shown_after_aug_ind) == kp.shape[0]\n",
        "\n",
        "  kp_ = np.zeros((len(node_names), 2))\n",
        "  kp_[shown_after_aug_ind] = kp\n",
        "  kp_[shown_ind] = 0\n",
        "\n",
        "  return kp_\n",
        "\n",
        "\n",
        "def make_grid_vectors(\n",
        "    image_height: int, image_width: int, output_stride: int = 1):\n",
        "\n",
        "    xv = torch.arange(0, image_width, step=output_stride).to(torch.float32)\n",
        "    yv = torch.arange(0, image_height, step=output_stride).to(torch.float32)\n",
        "    return xv, yv\n",
        "\n",
        "def make_confmaps(\n",
        "    points: torch.Tensor, xv: torch.Tensor, yv: torch.Tensor, sigma: float):\n",
        "\n",
        "    x = torch.reshape(points[:, 0], (1, 1, -1))\n",
        "    y = torch.reshape(points[:, 1], (1, 1, -1))\n",
        "    cm = torch.exp(\n",
        "        -((torch.reshape(xv, (1, -1, 1)) - x) ** 2 + (torch.reshape(yv, (-1, 1, 1)) - y) ** 2)\n",
        "        / (2 * sigma ** 2)\n",
        "    )\n",
        "\n",
        "    # Replace NaNs with 0.\n",
        "    cm = torch.where(torch.isnan(cm), 0.0, cm)\n",
        "    return cm\n",
        "\n",
        "def get_bbox_coords_on_centroid(anchor_coords, crop_size, img_size):\n",
        "    (cx, cy) = anchor_coords\n",
        "\n",
        "    # [bottom left     top right]\n",
        "    # [  x1, y1,         x2, y2 ]\n",
        "    bbox = [\n",
        "        max(-crop_size / 2 + cx, 0),\n",
        "        max(-crop_size / 2 + cy, 0),\n",
        "        min(crop_size / 2 + cx, img_size[0]),\n",
        "        min(crop_size / 2 + cy, img_size[1])\n",
        "    ]\n",
        "\n",
        "    return bbox\n",
        "\n",
        "# My refactored version of this dataset generator.\n",
        "class DataGenerator(Dataset):\n",
        "    def __init__(self, \n",
        "      labels, \n",
        "      img_size=160,\n",
        "      anchor_name=\"thorax\",\n",
        "      sigma=1.5,\n",
        "      output_stride=2,\n",
        "      rot_range=(-180, 180),\n",
        "      is_train=True\n",
        "    ):\n",
        "        self.labels = labels.with_user_labels_only()\n",
        "        self.labels.remove_empty_instances(keep_empty_frames=False)\n",
        "\n",
        "        self.indices = []\n",
        "        for frame_idx, l in enumerate(self.labels):\n",
        "          inst_indices = np.arange(0, len(l.instances)).tolist()\n",
        "          self.indices.extend([(frame_idx, i) for i in inst_indices])\n",
        "\n",
        "        self.img_size = img_size\n",
        "\n",
        "        assert anchor_name in self.labels.skeleton.node_names\n",
        "        self.anchor_name = anchor_name\n",
        "\n",
        "        # Assuming 1 skeleton.\n",
        "        assert len(labels.skeletons) == 1\n",
        "        self.node_names = labels.skeletons[0].node_names\n",
        "\n",
        "        self.sigma = sigma\n",
        "        self.output_stride = output_stride\n",
        "        self.rot_range = rot_range\n",
        "\n",
        "        self.tfm = A.Compose([\n",
        "            A.Rotate(limit=list(self.rot_range), p=0.5)\n",
        "        ], keypoint_params=A.KeypointParams(format='xy', label_fields=['class_labels']))\n",
        "\n",
        "        self.xv, self.yv = make_grid_vectors(\n",
        "            image_height=self.img_size, \n",
        "            image_width=self.img_size, \n",
        "            output_stride=self.output_stride\n",
        "        )\n",
        "\n",
        "        self.is_train = is_train\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        frame_idx, inst_idx = self.indices[idx]\n",
        "        lf = self.labels[frame_idx]\n",
        "        instance = lf[inst_idx]\n",
        "        img = lf.image\n",
        "        kp = instance.numpy()\n",
        "\n",
        "        # NaNs to 0 and clip.\n",
        "        assert kp.shape == (len(self.node_names), 2)\n",
        "        not_shown_nodes = np.isnan(kp).any(axis=1)\n",
        "        kp = np.nan_to_num(kp, nan=0)\n",
        "        kp = np.concatenate((np.clip(kp[:, :1], 0, img.shape[1]), \n",
        "                              np.clip(kp[:, 1:], 0, img.shape[0])), \n",
        "                            axis=1)\n",
        "\n",
        "        if self.is_train:\n",
        "            # Apply augmentations.\n",
        "            output = self.tfm(image=img, keypoints=kp, class_labels=self.node_names)\n",
        "            img, kp, new_nodes = output[\"image\"], np.array(output[\"keypoints\"]), output[\"class_labels\"]\n",
        "\n",
        "            # Update not_shown_nodes and kp.\n",
        "            not_shown_nodes = update_not_shown_nodes(not_shown_nodes, self.node_names, new_nodes)\n",
        "            kp = update_kp(kp, not_shown_nodes, self.node_names, new_nodes)\n",
        "\n",
        "        # Get bbox coordinate based on centroid.\n",
        "        bbox = get_bbox_coords_on_centroid(\n",
        "          kp[self.node_names.index(self.anchor_name)].tolist(), \n",
        "          self.img_size, img.shape[:2]\n",
        "        )\n",
        "\n",
        "        # Crop and pad.\n",
        "        x1, y1, x2, y2 = bbox\n",
        "        tfm_crop = A.Compose([\n",
        "          A.Crop(int(round(x1)), int(round(y1)), int(round(x2)), int(round(y2))),\n",
        "          A.PadIfNeeded(min_height=self.img_size, min_width=self.img_size)\n",
        "        ], keypoint_params=A.KeypointParams(format='xy', label_fields=['class_labels']))\n",
        "\n",
        "        crop_kp = tfm_crop(image=img, keypoints=kp, class_labels=self.node_names)\n",
        "        crop, kp, new_nodes = crop_kp[\"image\"], np.array(crop_kp[\"keypoints\"]), crop_kp[\"class_labels\"]\n",
        "        crop = torch.Tensor(crop).permute(2, 0, 1)\n",
        "\n",
        "        # Update not_shown_nodes and kp.\n",
        "        not_shown_nodes = update_not_shown_nodes(not_shown_nodes, self.node_names, new_nodes)\n",
        "        kp = update_kp(kp, not_shown_nodes, self.node_names, new_nodes)\n",
        "        kp = torch.Tensor(kp)\n",
        "\n",
        "        # Get confidence map.\n",
        "        xv, yv = make_grid_vectors(\n",
        "          image_height=self.img_size, \n",
        "          image_width=self.img_size, \n",
        "          output_stride=self.output_stride\n",
        "        )\n",
        "\n",
        "        cm = make_confmaps(\n",
        "          points=kp, \n",
        "          xv=self.xv, \n",
        "          yv=self.yv, \n",
        "          sigma=self.sigma\n",
        "        )\n",
        "        cm = cm.permute(2, 0, 1)\n",
        "\n",
        "        return crop, cm"
      ],
      "metadata": {
        "id": "l8Q-1ehtVWbr"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yo95XzRKkba"
      },
      "source": [
        "# Setting up a neural network model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MaxPool2dWithSamePadding(nn.MaxPool2d):\n",
        "\n",
        "    def _calc_same_pad(self, i: int, k: int, s: int, d: int) -> int:\n",
        "        return max((math.ceil(i / s) - 1) * s + (k - 1) * d + 1 - i, 0)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        if self.padding == \"same\":\n",
        "            ih, iw = x.size()[-2:]\n",
        "\n",
        "            pad_h = self._calc_same_pad(i=ih, \n",
        "                                        k=self.kernel_size if type(self.kernel_size) is int else self.kernel_size[0], \n",
        "                                        s=self.stride if type(self.stride) is int else self.stride[0], \n",
        "                                        d=self.dilation if type(self.dilation) is int else self.dilation[0])\n",
        "            pad_w = self._calc_same_pad(i=iw, \n",
        "                                        k=self.kernel_size if type(self.kernel_size) is int else self.kernel_size[1], \n",
        "                                        s=self.stride if type(self.stride) is int else self.stride[1], \n",
        "                                        d=self.dilation if type(self.dilation) is int else self.dilation[1])\n",
        "\n",
        "            if pad_h > 0 or pad_w > 0:\n",
        "                x = F.pad(\n",
        "                    x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2]\n",
        "                )\n",
        "            self.padding = 0\n",
        "\n",
        "        return F.max_pool2d(x, self.kernel_size, self.stride,\n",
        "                                    self.padding, self.dilation, ceil_mode=self.ceil_mode,\n",
        "                                    return_indices=self.return_indices)\n",
        "\n",
        "def get_act_fn(activation: str) -> nn.Module:\n",
        "    activations = {\n",
        "        'relu': nn.ReLU(),\n",
        "        'sigmoid': nn.Sigmoid(),\n",
        "        'tanh': nn.Tanh()\n",
        "    }\n",
        "\n",
        "    return activations[activation]\n",
        "\n",
        "class SimpleConvBlock(nn.Module):\n",
        "    def __init__(self,\n",
        "        in_channels: int,\n",
        "        pool: bool = True,\n",
        "        pooling_stride: int = 2,\n",
        "        pool_before_convs: bool = False,\n",
        "        num_convs: int = 2,\n",
        "        filters: int = 32,\n",
        "        kernel_size: int = 3,\n",
        "        use_bias: bool = True,\n",
        "        batch_norm: bool = False,\n",
        "        activation: Text = \"relu\"\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.pool = pool\n",
        "        self.pooling_stride = pooling_stride\n",
        "        self.pool_before_convs = pool_before_convs\n",
        "        self.num_convs = num_convs\n",
        "        self.filters = filters\n",
        "        self.kernel_size = kernel_size\n",
        "        self.use_bias = use_bias\n",
        "        self.batch_norm = batch_norm\n",
        "        self.activation = activation\n",
        "\n",
        "        self.blocks = []\n",
        "        if pool and pool_before_convs:\n",
        "            self.blocks.append(\n",
        "                MaxPool2dWithSamePadding(\n",
        "                    kernel_size=2,\n",
        "                    stride=pooling_stride,\n",
        "                    padding=\"same\"\n",
        "                )\n",
        "            )\n",
        "\n",
        "        for i in range(num_convs):\n",
        "            self.blocks.append(\n",
        "                nn.Conv2d(\n",
        "                    in_channels=in_channels if i == 0 else filters,\n",
        "                    out_channels=filters,\n",
        "                    kernel_size=kernel_size,\n",
        "                    stride=1,\n",
        "                    padding=\"same\",\n",
        "                    bias=use_bias\n",
        "                )\n",
        "            )\n",
        "\n",
        "            if batch_norm:\n",
        "                self.blocks.append(\n",
        "                    nn.BatchNorm2d(filters)\n",
        "                )\n",
        "\n",
        "            self.blocks.append(\n",
        "                get_act_fn(activation)  \n",
        "            )\n",
        "\n",
        "\n",
        "        if pool and not pool_before_convs:\n",
        "            self.blocks.append(\n",
        "                MaxPool2dWithSamePadding(\n",
        "                    kernel_size=2,\n",
        "                    stride=pooling_stride,\n",
        "                    padding=\"same\"\n",
        "                )\n",
        "            )\n",
        "\n",
        "        self.blocks = nn.Sequential(*self.blocks)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.blocks(x)\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self,\n",
        "        in_channels: int = 3,\n",
        "        filters: int = 64,\n",
        "        down_blocks: int = 4, \n",
        "        filters_rate: Union[float, int] = 2,\n",
        "        current_stride: int = 2,\n",
        "        stem_blocks: int = 0,\n",
        "        convs_per_block: int = 2,\n",
        "        kernel_size: Union[int, Tuple[int, int]] = 3,\n",
        "        middle_block: bool = True,\n",
        "        block_contraction: bool = False\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.filters = filters\n",
        "        self.down_blocks = down_blocks\n",
        "        self.filters_rate = filters_rate\n",
        "        self.current_stride = current_stride\n",
        "        self.stem_blocks = stem_blocks\n",
        "        self.convs_per_block = convs_per_block\n",
        "        self.kernel_size = kernel_size\n",
        "        self.middle_block = middle_block\n",
        "        self.block_contraction = block_contraction\n",
        "\n",
        "        self.encoder_stack = nn.ModuleList([])\n",
        "        for block in range(down_blocks):\n",
        "            prev_block_filters = -1 if block==0 else block_filters\n",
        "            block_filters = int(\n",
        "                filters * (filters_rate ** (block + stem_blocks))\n",
        "            )\n",
        "\n",
        "            self.encoder_stack.append(\n",
        "                SimpleConvBlock(\n",
        "                    in_channels=in_channels if block == 0 else prev_block_filters,\n",
        "                    pool=(block > 0),\n",
        "                    pool_before_convs=True,\n",
        "                    pooling_stride=2,\n",
        "                    num_convs=convs_per_block,\n",
        "                    filters=block_filters,\n",
        "                    kernel_size=kernel_size,\n",
        "                    use_bias=True,\n",
        "                    batch_norm=False,\n",
        "                    activation=\"relu\"\n",
        "                )\n",
        "            )\n",
        "        after_block_filters = block_filters\n",
        "\n",
        "        self.encoder_stack.append(\n",
        "            MaxPool2dWithSamePadding(\n",
        "                kernel_size=2,\n",
        "                stride=2,\n",
        "                padding=\"same\"\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Create a middle block (like the CARE implementation).\n",
        "        if middle_block:\n",
        "            if convs_per_block > 1:\n",
        "                # First convs are one exponent higher than the last encoder block.\n",
        "                block_filters = int(\n",
        "                    filters * (filters_rate ** (down_blocks + stem_blocks))\n",
        "                )\n",
        "                self.encoder_stack.append(\n",
        "                    SimpleConvBlock(\n",
        "                        in_channels=after_block_filters,\n",
        "                        pool=False,\n",
        "                        pool_before_convs=False,\n",
        "                        pooling_stride=2,\n",
        "                        num_convs=convs_per_block - 1,\n",
        "                        filters=block_filters,\n",
        "                        kernel_size=kernel_size,\n",
        "                        use_bias=True,\n",
        "                        batch_norm=False,\n",
        "                        activation=\"relu\",\n",
        "                    )\n",
        "                )\n",
        "\n",
        "            if block_contraction:\n",
        "                # Contract the channels with an exponent lower than the last encoder block.\n",
        "                block_filters = int(\n",
        "                    filters * (filters_rate ** (down_blocks + stem_blocks - 1))\n",
        "                )\n",
        "            else:\n",
        "                # Keep the block output filters the same.\n",
        "                block_filters = int(\n",
        "                    filters * (filters_rate ** (down_blocks + stem_blocks))\n",
        "                )\n",
        "\n",
        "            self.encoder_stack.append(\n",
        "                SimpleConvBlock(\n",
        "                    in_channels=block_filters,\n",
        "                    pool=False,\n",
        "                    pool_before_convs=False,\n",
        "                    pooling_stride=2,\n",
        "                    num_convs=1,\n",
        "                    filters=block_filters,\n",
        "                    kernel_size=kernel_size,\n",
        "                    use_bias=True,\n",
        "                    batch_norm=False,\n",
        "                    activation=\"relu\",\n",
        "                )\n",
        "            )\n",
        "\n",
        "        self.intermediate_features = {}\n",
        "        for i, block in enumerate(self.encoder_stack):\n",
        "            if isinstance(block, SimpleConvBlock) and block.pool:\n",
        "                current_stride *= block.pooling_stride\n",
        "\n",
        "            if current_stride not in self.intermediate_features.values():\n",
        "                self.intermediate_features[i] = current_stride\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        features = []\n",
        "        for i in range(len(self.encoder_stack)):\n",
        "            x = self.encoder_stack[i](x)\n",
        "            \n",
        "            if i in self.intermediate_features.keys():\n",
        "                features.append(x)\n",
        "\n",
        "        return x, features[1:][::-1]\n",
        "\n",
        "class SimpleUpsamplingBlock(nn.Module):\n",
        "    def __init__(self,\n",
        "        x_in_shape: int, \n",
        "        current_stride: int,\n",
        "        upsampling_stride: int = 2,\n",
        "        interp_method: Text = \"bilinear\",\n",
        "        refine_convs: int = 2,\n",
        "        refine_convs_filters: int = 64,\n",
        "        refine_convs_kernel_size: int = 3,\n",
        "        refine_convs_use_bias: bool = True,\n",
        "        refine_convs_batch_norm: bool = True,\n",
        "        refine_convs_batch_norm_before_activation: bool = True,\n",
        "        refine_convs_activation: Text = \"relu\"\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.x_in_shape = x_in_shape\n",
        "        self.current_stride = current_stride\n",
        "        self.upsampling_stride = upsampling_stride\n",
        "        self.interp_method = interp_method\n",
        "        self.refine_convs = refine_convs\n",
        "        self.refine_convs_filters = refine_convs_filters\n",
        "        self.refine_convs_kernel_size = refine_convs_kernel_size\n",
        "        self.refine_convs_use_bias = refine_convs_use_bias\n",
        "        self.refine_convs_batch_norm = refine_convs_batch_norm\n",
        "        self.refine_convs_batch_norm_before_activation = refine_convs_batch_norm_before_activation\n",
        "        self.refine_convs_activation = refine_convs_activation\n",
        "\n",
        "        self.blocks = nn.ModuleList([])\n",
        "        if current_stride is not None:\n",
        "            # Append the strides to the block prefix.\n",
        "            new_stride = current_stride // upsampling_stride\n",
        "\n",
        "        # Upsample via interpolation.\n",
        "        self.blocks.append(\n",
        "            nn.Upsample(\n",
        "                scale_factor=upsampling_stride,\n",
        "                mode=interp_method,\n",
        "            )\n",
        "        )\n",
        "\n",
        "\n",
        "        # Add further convolutions to refine after upsampling and/or skip.\n",
        "        for i in range(refine_convs):\n",
        "            filters = refine_convs_filters\n",
        "            self.blocks.append(\n",
        "                nn.Conv2d(\n",
        "                    in_channels=x_in_shape if i==0 else filters,\n",
        "                    out_channels=filters,\n",
        "                    kernel_size=refine_convs_kernel_size,\n",
        "                    stride=1,\n",
        "                    padding=\"same\",\n",
        "                    bias=refine_convs_use_bias\n",
        "                )\n",
        "            )\n",
        "\n",
        "            if (\n",
        "                refine_convs_batch_norm\n",
        "                and refine_convs_batch_norm_before_activation\n",
        "            ):\n",
        "                self.blocks.append(nn.BatchNorm2d(num_features=filters))\n",
        "\n",
        "\n",
        "            self.blocks.append(\n",
        "                get_act_fn(refine_convs_activation)  \n",
        "            )\n",
        "\n",
        "            if (\n",
        "                refine_convs_batch_norm\n",
        "                and not refine_convs_batch_norm_before_activation\n",
        "            ):\n",
        "                self.blocks.append(nn.BatchNorm2d(num_features=filters))\n",
        "\n",
        "\n",
        "    def forward(self, x: torch.Tensor, feature: torch.Tensor) -> torch.Tensor:\n",
        "        for idx, b in enumerate(self.blocks):\n",
        "            if idx == 1:  # Right after upsampling or convtranspose2d.\n",
        "                x = torch.concat((x, feature), dim=1)\n",
        "            x = b(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self,\n",
        "        x_in_shape: int,\n",
        "        current_stride: int,\n",
        "        filters: int = 64,\n",
        "        up_blocks: int = 4,\n",
        "        down_blocks: int = 3,\n",
        "        filters_rate: int = 2,\n",
        "        stem_blocks: int = 0,\n",
        "        convs_per_block: int = 2,\n",
        "        kernel_size: int = 3,\n",
        "        block_contraction: bool = False\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.x_in_shape = x_in_shape\n",
        "        self.current_stride = current_stride\n",
        "        self.filters = filters\n",
        "        self.up_blocks = up_blocks\n",
        "        self.down_blocks = down_blocks\n",
        "        self.filters_rate = filters_rate\n",
        "        self.stem_blocks = stem_blocks\n",
        "        self.convs_per_block = convs_per_block\n",
        "        self.kernel_size = kernel_size\n",
        "        self.block_contraction = block_contraction\n",
        "\n",
        "        self.decoder_stack = nn.ModuleList([])\n",
        "        for block in range(up_blocks):\n",
        "            prev_block_filters_in = -1 if block == 0 else block_filters_in\n",
        "            block_filters_in = int(\n",
        "                filters\n",
        "                * (\n",
        "                    filters_rate\n",
        "                    ** (down_blocks + stem_blocks - 1 - block)\n",
        "                )\n",
        "            )\n",
        "            if block_contraction:\n",
        "                block_filters_out = int(\n",
        "                    filters\n",
        "                    * (\n",
        "                        filters_rate\n",
        "                        ** (down_blocks + stem_blocks - 2 - block)\n",
        "                    )\n",
        "                )\n",
        "            else:\n",
        "                block_filters_out = block_filters_in\n",
        "\n",
        "            next_stride = current_stride // 2\n",
        "\n",
        "            self.decoder_stack.append(\n",
        "                SimpleUpsamplingBlock(\n",
        "                    x_in_shape=(x_in_shape + block_filters_in) if block == 0 else (prev_block_filters_in + block_filters_in), \n",
        "                    current_stride=current_stride,\n",
        "                    upsampling_stride=2,\n",
        "                    interp_method=\"bilinear\",\n",
        "                    refine_convs=self.convs_per_block,\n",
        "                    refine_convs_filters=block_filters_out,\n",
        "                    refine_convs_kernel_size=self.kernel_size,\n",
        "                    refine_convs_batch_norm=False,\n",
        "                )\n",
        "            )\n",
        "\n",
        "            current_stride = next_stride\n",
        "\n",
        "    def forward(self, x: torch.Tensor, features: List[torch.Tensor]) -> torch.Tensor:\n",
        "        for i in range(len(self.decoder_stack)):\n",
        "            x = self.decoder_stack[i](x, features[i])\n",
        "\n",
        "        return x\n",
        "\n",
        "class Unet(nn.Module):\n",
        "    def __init__(self,\n",
        "        in_channels: int = 1,\n",
        "        kernel_size: int = 3,\n",
        "        filters: int = 32,\n",
        "        filters_rate: int = 1.5,\n",
        "        stem_blocks: int = 0,\n",
        "        down_blocks: int = 4, \n",
        "        up_blocks: int = 3,\n",
        "        convs_per_block: int = 2,\n",
        "        middle_block: bool = True,\n",
        "        block_contraction: bool = False\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.enc = Encoder(\n",
        "            in_channels=in_channels,\n",
        "            filters=filters,\n",
        "            down_blocks=down_blocks,\n",
        "            filters_rate=filters_rate,\n",
        "            stem_blocks=stem_blocks,\n",
        "            convs_per_block=convs_per_block,\n",
        "            kernel_size=kernel_size,\n",
        "            middle_block=middle_block,\n",
        "            block_contraction=block_contraction\n",
        "        )\n",
        "\n",
        "        current_stride = int(\n",
        "            np.prod(\n",
        "                [block.pooling_stride for block in self.enc.encoder_stack if hasattr(block, \"pool\") and block.pool]\n",
        "                + [1]\n",
        "            )\n",
        "        )\n",
        "        \n",
        "        x_in_shape = int(\n",
        "            filters * (filters_rate ** (down_blocks + stem_blocks))\n",
        "        )\n",
        "\n",
        "        self.dec = Decoder(x_in_shape=x_in_shape, current_stride=current_stride, filters=filters,\n",
        "            up_blocks=up_blocks, down_blocks=down_blocks, filters_rate=filters_rate\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x, features = self.enc(x)\n",
        "        x = self.dec(x, features)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "fCMnTHR9VetA"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEfgZT4hLyW4"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "\n",
        "cores = multiprocessing.cpu_count()\n",
        "cores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFNfmlnprhmb",
        "outputId": "dc17659d-a578-41d1-fd05-e2476920ed82"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vanilla PyTorch with Mixed Precision"
      ],
      "metadata": {
        "id": "jzMa-PNPqxxA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze > requirements.txt\n",
        "\n",
        "filters = 32\n",
        "filters_rate = 1.5\n",
        "down_blocks = 4\n",
        "stem_blocks = 0\n",
        "up_blocks = 3\n",
        "\n",
        "# Some of this code is redundant. I kept the previous cells un-deleted just for reference.\n",
        "for i in range(5): \n",
        "    train_ds = DataGenerator(labels)\n",
        "    train_dl = DataLoader(\n",
        "        train_ds,\n",
        "        batch_size=4,\n",
        "        shuffle=True,\n",
        "        num_workers=cores,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "        prefetch_factor=2\n",
        "    )\n",
        "\n",
        "    val_ds = DataGenerator(val_labels, is_train=False)\n",
        "    val_dl = DataLoader(\n",
        "        val_ds,\n",
        "        batch_size=4,\n",
        "        shuffle=False,\n",
        "        num_workers=cores,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "        prefetch_factor=2\n",
        "    )\n",
        "\n",
        "    unet = Unet(filters=filters, \n",
        "                filters_rate=filters_rate, \n",
        "                down_blocks=down_blocks, \n",
        "                stem_blocks=stem_blocks, \n",
        "                up_blocks=up_blocks)\n",
        "\n",
        "    in_channels = int(\n",
        "        filters\n",
        "        * (\n",
        "            filters_rate\n",
        "            ** (down_blocks + stem_blocks - 1 - up_blocks + 1)\n",
        "        )\n",
        "    )\n",
        "    model = nn.Sequential(*[\n",
        "        unet, \n",
        "        nn.Conv2d(in_channels=in_channels, out_channels=13, kernel_size=1, padding=\"same\")    \n",
        "    ])\n",
        "\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "    model = model.to(\"cuda\")\n",
        "\n",
        "    run = wandb.init(\n",
        "        project=\"torch_vs_tf_talmo_lab\", \n",
        "        name=f\"torch_baseline_run{i}\", \n",
        "        config={\n",
        "            \"is_tf\": False,\n",
        "            \"device_and_memory\": get_vram(),\n",
        "            \"seed\": seed,\n",
        "            \"model_param_count\": get_param_count(model)\n",
        "        }, \n",
        "        tags=[\"baseline\"],\n",
        "        notes=\"This experiment was done in a Google Colab Notebook.\"\n",
        "    )\n",
        "\n",
        "    # Log dependencies.\n",
        "    artifact = wandb.Artifact(\"Dependencies\", type=\"dependencies\")\n",
        "    artifact.add_file(\"requirements.txt\", name=f\"requirements.txt\")\n",
        "    run.log_artifact(artifact)\n",
        "\n",
        "    for epoch in range(3):\n",
        "        _ = model.train()\n",
        "        start_time = time.time()\n",
        "        train_loss = 0\n",
        "        for idx, batch in enumerate(train_dl):\n",
        "            X, y = batch\n",
        "            X = X.to(\"cuda\")\n",
        "            y = y.to(\"cuda\")\n",
        "            \n",
        "            with torch.autocast(\"cuda\"):\n",
        "                y_preds = model(X)\n",
        "                loss = nn.MSELoss()(y_preds, y)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(opt)\n",
        "            scaler.update()\n",
        "            opt.zero_grad()\n",
        "                    \n",
        "            if idx % 100 == 0:\n",
        "              print(f\"Epoch: {epoch} | Loss: {loss:.5f}\")\n",
        "\n",
        "            train_loss += loss\n",
        "\n",
        "        train_loss /= (idx+1)\n",
        "        train_time = time.time() - start_time\n",
        "        print(f\"TRAIN: --- {train_time}s seconds ---\")\n",
        "\n",
        "        _  = model.eval()\n",
        "        start_time = time.time()\n",
        "        val_loss = 0\n",
        "        for idx, batch in enumerate(val_dl):\n",
        "            X, y = batch\n",
        "            X = X.to(\"cuda\")\n",
        "            y = y.to(\"cuda\")\n",
        "\n",
        "            with torch.no_grad():\n",
        "                y_preds = model(X)\n",
        "                loss = nn.MSELoss()(y_preds, y)\n",
        "\n",
        "            val_loss += loss\n",
        "\n",
        "        val_loss /= (idx+1)\n",
        "        val_time = time.time() - start_time\n",
        "        print(f\"VAL: --- {val_time}s seconds ---\")\n",
        "\n",
        "        run.log({\n",
        "            \"train_loss\": train_loss,\n",
        "            \"val_loss\": val_loss,\n",
        "            \"train_time\": train_time,\n",
        "            \"val_time\": val_time,\n",
        "            \"total_time\": train_time + val_time\n",
        "        })\n",
        "\n",
        "    del model, opt, scaler, train_ds, train_dl, val_ds, val_dl\n",
        "    gc.collect()\n",
        "    run.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 727
        },
        "id": "tDMSgbrrY7E0",
        "outputId": "55a69286-5a5f-4849-9505-adfb7887d05a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvincenttu\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230511_061720-prexwc7e</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab/runs/prexwc7e' target=\"_blank\">torch_baseline_run0</a></strong> to <a href='https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab' target=\"_blank\">https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab/runs/prexwc7e' target=\"_blank\">https://wandb.ai/vincenttu/torch_vs_tf_talmo_lab/runs/prexwc7e</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Loss: 0.01214\n",
            "Epoch: 0 | Loss: 0.00036\n",
            "Epoch: 0 | Loss: 0.00029\n",
            "Epoch: 0 | Loss: 0.00028\n",
            "Epoch: 0 | Loss: 0.00028\n",
            "Epoch: 0 | Loss: 0.00027\n",
            "Epoch: 0 | Loss: 0.00028\n",
            "Epoch: 0 | Loss: 0.00027\n",
            "TRAIN: --- 70.5167441368103s seconds ---\n",
            "VAL: --- 5.927274465560913s seconds ---\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-c016c2dd3fbc>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                 \u001b[0my_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    457\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 459\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    460\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorch Lightning"
      ],
      "metadata": {
        "id": "vW3i2iTusCg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightning -qqq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQXv6cNwscbL",
        "outputId": "ae5d4448-d38e-4ebb-c779-9e5cd8d22c09"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.7/238.7 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.9/66.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m719.0/719.0 kB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.3/64.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sleap 1.3.0 requires rich==10.16.1, but you have rich 13.3.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lightning.pytorch as pl\n",
        "from lightning.pytorch.callbacks import TQDMProgressBar\n",
        "from lightning.pytorch.loggers import WandbLogger\n",
        "from lightning.pytorch.callbacks import Callback\n",
        "\n",
        "pl.seed_everything(seed, workers=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T383klIGsbd4",
        "outputId": "d5b1fbc4-2e0b-464c-8737-3c2a421beada"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: Global seed set to 42\n",
            "INFO:lightning.fabric.utilities.seed:Global seed set to 42\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FullUNet(pl.LightningModule):\n",
        "  def __init__(self,\n",
        "    n_nodes = 13,\n",
        "    filters = 32,\n",
        "    filters_rate = 1.5,\n",
        "    down_blocks = 4,\n",
        "    stem_blocks = 0,\n",
        "    up_blocks = 3,\n",
        "    lr = 1e-4\n",
        "  ):\n",
        "    super().__init__()\n",
        "    \n",
        "    self.train_losses = []\n",
        "    self.val_losses = []\n",
        "\n",
        "    self.n_nodes = n_nodes\n",
        "    self.filters = filters\n",
        "    self.filters_rate = filters_rate\n",
        "    self.down_blocks = down_blocks\n",
        "    self.stem_blocks = stem_blocks\n",
        "    self.up_blocks = up_blocks\n",
        "    self.lr = lr\n",
        "    \n",
        "    self.unet = Unet(\n",
        "        filters=filters, \n",
        "        filters_rate=filters_rate, \n",
        "        down_blocks=down_blocks, \n",
        "        stem_blocks=stem_blocks, \n",
        "        up_blocks=up_blocks\n",
        "    )\n",
        "\n",
        "    in_channels = int(\n",
        "      filters\n",
        "      * (\n",
        "          filters_rate\n",
        "          ** (down_blocks + stem_blocks - 1 - up_blocks + 1)\n",
        "      )\n",
        "    )\n",
        "\n",
        "    self.last_conv = nn.Conv2d(in_channels=in_channels, out_channels=n_nodes, kernel_size=1, padding=\"same\") \n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.unet(x)\n",
        "    return self.last_conv(x)\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    X, y = batch\n",
        "    y_preds = self.forward(X)\n",
        "    loss = nn.MSELoss()(y_preds, y)\n",
        "    if batch_idx % 100 == 0:\n",
        "        print(f\"Loss: {loss:.5f}\")\n",
        "    self.train_losses.append(loss.item())\n",
        "    return loss\n",
        "\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "    X, y = batch\n",
        "    y_preds = self.forward(X)\n",
        "    loss = nn.MSELoss()(y_preds, y)\n",
        "    self.val_losses.append(loss.item())\n",
        "    return loss\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
        "    return optimizer"
      ],
      "metadata": {
        "id": "l_K2JBrPZQVC"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LogLossAndTimeCallback(Callback):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.state = {\n",
        "        \"train_start_time\": 0,\n",
        "        \"train_time\": 0,\n",
        "        \"val_start_time\": 0,\n",
        "        \"val_time\": 0,\n",
        "    }\n",
        "\n",
        "  def load_state_dict(self, state_dict):\n",
        "    self.state.update(state_dict)\n",
        "\n",
        "  def state_dict(self):\n",
        "    return self.state.copy()\n",
        "\n",
        "  def on_train_epoch_start(self, trainer, pl_module):\n",
        "    self.state[\"train_start_time\"] = time.time()\n",
        "\n",
        "  def on_validation_epoch_start(self, trainer, pl_module):\n",
        "    pl_module.log(\"train_loss\", np.mean(pl_module.train_losses))\n",
        "    self.state[\"train_time\"] = time.time() - self.state[\"train_start_time\"]\n",
        "    pl_module.log(\"train_time\", self.state[\"train_time\"])\n",
        "\n",
        "    self.state[\"val_start_time\"] = time.time()\n",
        "\n",
        "  def on_validation_epoch_end(self, trainer, pl_module):\n",
        "    pl_module.log(\"val_loss\", np.mean(pl_module.val_losses))\n",
        "    self.state[\"val_time\"] = time.time() - self.state[\"val_start_time\"]\n",
        "    pl_module.log(\"val_time\", self.state[\"val_time\"])\n",
        "    pl_module.log(\"total_time\", self.state[\"train_time\"] + self.state[\"val_time\"])\n",
        "\n",
        "  def on_init_start(self, trainer, pl_module):\n",
        "    artifact = wandb.Artifact(\"Dependencies\", type=\"dependencies\")\n",
        "    artifact.add_file(\"requirements.txt\", name=f\"requirements.txt\")\n",
        "    pl_module.logger.experiment.log_artifact(artifact)"
      ],
      "metadata": {
        "id": "asSCx72qoT-V"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze > requirements.txt\n",
        "\n",
        "n_nodes = len(labels.skeleton)\n",
        "filters = 32\n",
        "filters_rate = 1.5\n",
        "down_blocks = 4\n",
        "stem_blocks = 0\n",
        "up_blocks = 3\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "# Some of this code is redundant. I kept the previous cells un-deleted just for reference.\n",
        "for i in range(5): \n",
        "    train_ds = DataGenerator(labels)\n",
        "    train_dl = DataLoader(\n",
        "        train_ds,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=cores,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "        prefetch_factor=2\n",
        "    )\n",
        "\n",
        "    val_ds = DataGenerator(val_labels, is_train=False)\n",
        "    val_dl = DataLoader(\n",
        "        val_ds,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=cores,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "        prefetch_factor=2\n",
        "    )\n",
        "\n",
        "    model = FullUNet(n_nodes)\n",
        "\n",
        "    wandb_logger = WandbLogger(\n",
        "        name=f\"torch_lightning_run{i}\", \n",
        "        project=\"torch_vs_tf_talmo_lab\",\n",
        "        config={\n",
        "            \"is_lightning\": \"true\",\n",
        "            \"is_tf\": False,\n",
        "            \"device_and_memory\": get_vram(),\n",
        "            \"seed\": seed,\n",
        "            \"model_param_count\": get_param_count(model),\n",
        "        }, \n",
        "        tags=[\"lightning\"],\n",
        "        notes=\"This experiment was done in a Google Colab Notebook.\"\n",
        "\n",
        "    )\n",
        "    trainer = pl.Trainer(\n",
        "        precision=16,  # Mixed Precision.\n",
        "        logger=wandb_logger, \n",
        "        fast_dev_run=False,\n",
        "        callbacks=[\n",
        "            TQDMProgressBar(refresh_rate=1),\n",
        "            LogLossAndTimeCallback() \n",
        "        ],\n",
        "        max_epochs=3,\n",
        "        overfit_batches=0.0,\n",
        "        enable_checkpointing=True,\n",
        "        enable_progress_bar=True,\n",
        "        enable_model_summary=True,\n",
        "        deterministic=False,\n",
        "        benchmark=True,\n",
        "        default_root_dir=None\n",
        "    )\n",
        "\n",
        "    # # Log dependencies.\n",
        "    # artifact = wandb.Artifact(\"Dependencies\", type=\"dependencies\")\n",
        "    # artifact.add_file(\"requirements.txt\", name=f\"requirements.txt\")\n",
        "    # run.log_artifact(artifact)\n",
        "\n",
        "    trainer.fit(model, train_dataloaders=train_dl, val_dataloaders=val_dl)\n",
        "\n",
        "    # run.log({\n",
        "    #     \"train_loss\": train_loss,\n",
        "    #     \"val_loss\": val_loss,\n",
        "    #     \"train_time\": train_time,\n",
        "    #     \"val_time\": val_time,\n",
        "    #     \"total_time\": train_time + val_time\n",
        "    # })\n",
        "\n",
        "    # run.finish()\n",
        "\n",
        "\n",
        "    wandb.finish()"
      ],
      "metadata": {
        "id": "3W-BdFVhsmJJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e6afb446b83246939f5708949bbcf3fa",
            "261a86cec67b4262b199ff6a02c165d3",
            "f0117dc5ad3344eb81970230186fa149",
            "59e753d977a240bbb70a2516fdcace09",
            "46ca895cc5b3433ea224114fb6ca8f1a",
            "5d6839e4ebff49b99a7df9b7b276fcdd",
            "b5ea6358d0cb410d8994b8147f93c4be",
            "da77746737854fdf97be9622a18a5faa",
            "cab20c753c5d4f75b82b049f4128243c",
            "5c708750e5a04440a6ef504a300b34e2",
            "b7d6f5896f924111af7da17a2fea7806",
            "d3c2d99bc96342918928184c0f2a4a3f",
            "c2c9be77aadb44ae87c3264d0dc17954",
            "273013541ed3464c9b3a613c210e75ee",
            "72965da02c1048838715b6abb99c2603",
            "fd41dc4b208e43c1ba5ddd131d2770e1",
            "044fb27e052846b08faff9643a862717",
            "fcea6c030fca4e339584636269f7c757",
            "7586fcf8b16142d3af4e0173055ab268",
            "93fcf1f1304745eb8dc2e8e30de56ef5",
            "5af486cc45414581ba6a2c4cb6cbf72c",
            "34938f6a525d409b8e702251693ed6df",
            "5cbea487bfdc439aa6e2960d0d4946c4",
            "4baf45822bff42158b3224c068117201",
            "ad0bf3aff7af450383531a07663ec086",
            "39acb089108f4a66b57b96eb5e090a26",
            "dfb3e52b72b14eb99b6134f9e4e07e07",
            "4f7de84447654001860637ff6e2834f2",
            "5809b25ca26a4845830f08d9634ee577",
            "289b41b1b763430eb2482a65b6765fef",
            "f96ccfe712cb471593adc22567b5ebf7",
            "995c5f76c6284750ab6d605e5dd0f994",
            "8d9a2a50948b4f1dadbb640da3fc7ba2",
            "b7c41e414e9042faabba01b618e3252f",
            "a95ebfc9c58245019e2eeb7da19d2a1a",
            "60b4338cdb664c2aab5c2c9c150e9374",
            "1540532b162e4e9fb19c0135b7651acb",
            "b36402cfec9745b48f48eb16b8b2dbc2",
            "ff340bd4454846778ee64ddac03b3336",
            "e0920a30aba649f68625bdfb779879c3",
            "7082f0c0a8094e99bd8e868877f73b22"
          ]
        },
        "outputId": "21fb07f3-eb79-4f83-ca74-42afea6e04bd"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: Using 16bit Automatic Mixed Precision (AMP)\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Using 16bit Automatic Mixed Precision (AMP)\n",
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name      | Type   | Params\n",
            "-------------------------------------\n",
            "0 | unet      | Unet   | 1.3 M \n",
            "1 | last_conv | Conv2d | 637   \n",
            "-------------------------------------\n",
            "1.3 M     Trainable params\n",
            "0         Non-trainable params\n",
            "1.3 M     Total params\n",
            "5.183     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name      | Type   | Params\n",
            "-------------------------------------\n",
            "0 | unet      | Unet   | 1.3 M \n",
            "1 | last_conv | Conv2d | 637   \n",
            "-------------------------------------\n",
            "1.3 M     Trainable params\n",
            "0         Non-trainable params\n",
            "1.3 M     Total params\n",
            "5.183     Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e6afb446b83246939f5708949bbcf3fa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d3c2d99bc96342918928184c0f2a4a3f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.01214\n",
            "Loss: 0.00039\n",
            "Loss: 0.00030\n",
            "Loss: 0.00028\n",
            "Loss: 0.00028\n",
            "Loss: 0.00027\n",
            "Loss: 0.00028\n",
            "Loss: 0.00027\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5cbea487bfdc439aa6e2960d0d4946c4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016669271116666096, max=1.0…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b7c41e414e9042faabba01b618e3252f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem at: /usr/local/lib/python3.10/dist-packages/lightning/pytorch/loggers/wandb.py 405 experiment\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CommError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCommError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-a5c6c51fce4e>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;31m# run.log_artifact(artifact)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;31m# run.log({\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_unwrap_optimized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lightning_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m         call._call_and_handle_interrupt(\n\u001b[0m\u001b[1;32m    521\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_TunerExitException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0mmodel_connected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         )\n\u001b[0;32m--> 559\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    933\u001b[0m         \u001b[0;31m# RUN THE TRAINER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    976\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_sanity_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detect_anomaly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unexpected state {self.state}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/fit_loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restarting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/fit_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_training_epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/training_epoch_loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restarting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/training_epoch_loop.py\u001b[0m in \u001b[0;36mon_advance_end\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mshould_check_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/utilities.py\u001b[0m in \u001b[0;36m_decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mcontext_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mcontext_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mloop_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_decorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/evaluation_loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restarting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_store_dataloader_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_run_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msetup_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/evaluation_loop.py\u001b[0m in \u001b[0;36mon_run_end\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;31m# log metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logger_connector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_eval_end_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_logged_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;31m# hook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py\u001b[0m in \u001b[0;36mlog_eval_end_metrics\u001b[0;34m(self, metrics)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;31m# log all the metrics as a single dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \"\"\"\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py\u001b[0m in \u001b[0;36mlog_metrics\u001b[0;34m(self, metrics, step)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;31m# log actual metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloggers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalar_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning_utilities/core/rank_zero.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The `rank_zero_only.rank` needs to be set before use\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrank\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loggers/wandb.py\u001b[0m in \u001b[0;36mlog_metrics\u001b[0;34m(self, metrics, step)\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_add_prefix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLOGGER_JOIN_CHAR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"trainer/global_step\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning/fabric/loggers/logger.py\u001b[0m in \u001b[0;36mexperiment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrank_zero_only\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_DummyExperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loggers/wandb.py\u001b[0m in \u001b[0;36mexperiment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0;31m# create new wandb process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wandb_init\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0;31m# define default x-axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0mexcept_exit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_except_exit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m             \u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m             \u001b[0mexcept_exit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_except_exit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    767\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mrun_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# for mypy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCommError\u001b[0m: Run initialization has timed out after 60.0 sec. \nPlease refer to the documentation for additional information: https://docs.wandb.ai/guides/track/tracking-faq#initstarterror-error-communicating-with-wandb-process-"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run.finish()"
      ],
      "metadata": {
        "id": "6PmnqErNedfo"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorch Lightning Fabric"
      ],
      "metadata": {
        "id": "3ulzNNh94AaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightning -qqq"
      ],
      "metadata": {
        "id": "-R1ifesdR63l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from lightning.fabric import Fabric"
      ],
      "metadata": {
        "id": "D7TeM1Lp4DD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze > requirements.txt\n",
        "\n",
        "filters = 32\n",
        "filters_rate = 1.5\n",
        "down_blocks = 4\n",
        "stem_blocks = 0\n",
        "up_blocks = 3\n",
        "\n",
        "# Some of this code is redundant. I kept the previous cells un-deleted just for reference.\n",
        "for i in range(5): \n",
        "    fabric = Fabric(accelerator=\"cuda\", precision=\"16-mixed\")\n",
        "\n",
        "    train_ds = DataGenerator(labels)\n",
        "    train_dl = DataLoader(\n",
        "        train_ds,\n",
        "        batch_size=4,\n",
        "        shuffle=True,\n",
        "        num_workers=cores,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "        prefetch_factor=2\n",
        "    )\n",
        "\n",
        "    val_ds = DataGenerator(val_labels, is_train=False)\n",
        "    val_dl = DataLoader(\n",
        "        val_ds,\n",
        "        batch_size=4,\n",
        "        shuffle=False,\n",
        "        num_workers=cores,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "        prefetch_factor=2\n",
        "    )\n",
        "\n",
        "    unet = Unet(filters=filters, \n",
        "                filters_rate=filters_rate, \n",
        "                down_blocks=down_blocks, \n",
        "                stem_blocks=stem_blocks, \n",
        "                up_blocks=up_blocks)\n",
        "\n",
        "    in_channels = int(\n",
        "        filters\n",
        "        * (\n",
        "            filters_rate\n",
        "            ** (down_blocks + stem_blocks - 1 - up_blocks + 1)\n",
        "        )\n",
        "    )\n",
        "    model = nn.Sequential(*[\n",
        "        unet, \n",
        "        nn.Conv2d(in_channels=in_channels, out_channels=13, kernel_size=1, padding=\"same\")    \n",
        "    ])\n",
        "\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "    model, opt = fabric.setup(model, opt)\n",
        "    train_dl, val_dl = fabric.setup_dataloaders(train_dl, val_dl)\n",
        "\n",
        "    run = wandb.init(\n",
        "        project=\"torch_vs_tf_talmo_lab\", \n",
        "        name=f\"torch_lightning_fabric_run{i}\", \n",
        "        config={\n",
        "            \"is_lightning_fabric\": \"true\",\n",
        "            \"device_and_memory\": get_vram(),\n",
        "            \"seed\": seed,\n",
        "            \"model_param_count\": get_param_count(model)\n",
        "        }, \n",
        "        tags=[\"lightning_fabric\"],\n",
        "        notes=\"This experiment was done in a Google Colab Notebook.\"\n",
        "    )\n",
        "\n",
        "    # Log dependencies.\n",
        "    artifact = wandb.Artifact(\"Dependencies\", type=\"dependencies\")\n",
        "    artifact.add_file(\"requirements.txt\", name=f\"requirements.txt\")\n",
        "    run.log_artifact(artifact)\n",
        "\n",
        "    for epoch in range(3):\n",
        "        _ = model.train()\n",
        "        start_time = time.time()\n",
        "        train_loss = 0\n",
        "        for idx, batch in enumerate(train_dl):\n",
        "            X, y = batch\n",
        "\n",
        "            with fabric.autocast():\n",
        "                y_preds = model(X)\n",
        "                loss = nn.MSELoss()(y_preds, y)\n",
        "            fabric.backward(loss)\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "                    \n",
        "            if idx % 100 == 0:\n",
        "              print(f\"Epoch: {epoch} | Loss: {loss:.5f}\")\n",
        "\n",
        "            train_loss += loss\n",
        "\n",
        "        train_loss /= (idx+1)\n",
        "        train_time = time.time() - start_time\n",
        "        print(f\"TRAIN: --- {train_time}s seconds ---\")\n",
        "\n",
        "        _  = model.eval()\n",
        "        start_time = time.time()\n",
        "        val_loss = 0\n",
        "        for idx, batch in enumerate(val_dl):\n",
        "            X, y = batch\n",
        "\n",
        "            with torch.no_grad():\n",
        "                y_preds = model(X)\n",
        "                loss = nn.MSELoss()(y_preds, y)\n",
        "\n",
        "            val_loss += loss\n",
        "\n",
        "        val_loss /= (idx+1)\n",
        "        val_time = time.time() - start_time\n",
        "        print(f\"VAL: --- {val_time}s seconds ---\")\n",
        "\n",
        "        run.log({\n",
        "            \"train_loss\": train_loss,\n",
        "            \"val_loss\": val_loss,\n",
        "            \"train_time\": train_time,\n",
        "            \"val_time\": val_time,\n",
        "            \"total_time\": train_time + val_time\n",
        "        })\n",
        "\n",
        "    del fabric, model, opt, train_ds, train_dl, val_ds, val_dl\n",
        "    gc.collect()\n",
        "    run.finish()"
      ],
      "metadata": {
        "id": "bhkg2SWG4FpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hugging Face Accelerate"
      ],
      "metadata": {
        "id": "BvkJXDQW4IPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate -qqq"
      ],
      "metadata": {
        "id": "jILtm6p94NCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from accelerate import Accelerator"
      ],
      "metadata": {
        "id": "MrjSvihV4JyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze > requirements.txt\n",
        "\n",
        "filters = 32\n",
        "filters_rate = 1.5\n",
        "down_blocks = 4\n",
        "stem_blocks = 0\n",
        "up_blocks = 3\n",
        "\n",
        "# Some of this code is redundant. I kept the previous cells un-deleted just for reference.\n",
        "for i in range(5): \n",
        "    accelerator = Accelerator(mixed_precision=\"fp16\")\n",
        "    device = accelerator.device\n",
        "\n",
        "    train_ds = DataGenerator(labels)\n",
        "    train_dl = DataLoader(\n",
        "        train_ds,\n",
        "        batch_size=4,\n",
        "        shuffle=True,\n",
        "        num_workers=cores,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "        prefetch_factor=2\n",
        "    )\n",
        "\n",
        "    val_ds = DataGenerator(val_labels, is_train=False)\n",
        "    val_dl = DataLoader(\n",
        "        val_ds,\n",
        "        batch_size=4,\n",
        "        shuffle=False,\n",
        "        num_workers=cores,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "        prefetch_factor=2\n",
        "    )\n",
        "\n",
        "    unet = Unet(filters=filters, \n",
        "                filters_rate=filters_rate, \n",
        "                down_blocks=down_blocks, \n",
        "                stem_blocks=stem_blocks, \n",
        "                up_blocks=up_blocks)\n",
        "\n",
        "    in_channels = int(\n",
        "        filters\n",
        "        * (\n",
        "            filters_rate\n",
        "            ** (down_blocks + stem_blocks - 1 - up_blocks + 1)\n",
        "        )\n",
        "    )\n",
        "    model = nn.Sequential(*[\n",
        "        unet, \n",
        "        nn.Conv2d(in_channels=in_channels, out_channels=13, kernel_size=1, padding=\"same\")    \n",
        "    ])\n",
        "\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "    model, opt, train_dl, val_dl = accelerator.prepare(\n",
        "        model, opt, train_dl, val_dl\n",
        "    )\n",
        "\n",
        "    run = wandb.init(\n",
        "        project=\"torch_vs_tf_talmo_lab\", \n",
        "        name=f\"torch_accelerate_run{i}\", \n",
        "        config={\n",
        "            \"is_accelerate\": \"true\",\n",
        "            \"device_and_memory\": get_vram(),\n",
        "            \"seed\": seed,\n",
        "            \"model_param_count\": get_param_count(model)\n",
        "        }, \n",
        "        tags=[\"accelerate\"],\n",
        "        notes=\"This experiment was done in a Google Colab Notebook.\"\n",
        "    )\n",
        "\n",
        "    # Log dependencies.\n",
        "    artifact = wandb.Artifact(\"Dependencies\", type=\"dependencies\")\n",
        "    artifact.add_file(\"requirements.txt\", name=f\"requirements.txt\")\n",
        "    run.log_artifact(artifact)\n",
        "\n",
        "    for epoch in range(3):\n",
        "        _ = model.train()\n",
        "        start_time = time.time()\n",
        "        train_loss = 0\n",
        "        for idx, batch in enumerate(train_dl):\n",
        "            X, y = batch\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            \n",
        "            y_preds = model(X)\n",
        "            loss = nn.MSELoss()(y_preds, y)\n",
        "\n",
        "            accelerator.backward(loss)\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "                    \n",
        "            if idx % 100 == 0:\n",
        "              print(f\"Epoch: {epoch} | Loss: {loss:.5f}\")\n",
        "\n",
        "            train_loss += loss\n",
        "\n",
        "        train_loss /= (idx+1)\n",
        "        train_time = time.time() - start_time\n",
        "        print(f\"TRAIN: --- {train_time}s seconds ---\")\n",
        "\n",
        "        _  = model.eval()\n",
        "        start_time = time.time()\n",
        "        val_loss = 0\n",
        "        for idx, batch in enumerate(val_dl):\n",
        "            X, y = batch\n",
        "            X = X.to(\"cuda\")\n",
        "            y = y.to(\"cuda\")\n",
        "\n",
        "            with torch.no_grad():\n",
        "                y_preds = model(X)\n",
        "                loss = nn.MSELoss()(y_preds, y)\n",
        "\n",
        "            val_loss += loss\n",
        "\n",
        "        val_loss /= (idx+1)\n",
        "        val_time = time.time() - start_time\n",
        "        print(f\"VAL: --- {val_time}s seconds ---\")\n",
        "\n",
        "        run.log({\n",
        "            \"train_loss\": train_loss,\n",
        "            \"val_loss\": val_loss,\n",
        "            \"train_time\": train_time,\n",
        "            \"val_time\": val_time,\n",
        "            \"total_time\": train_time + val_time\n",
        "        })\n",
        "\n",
        "    del model, opt, train_ds, train_dl, val_ds, val_dl\n",
        "    gc.collect()\n",
        "    run.finish()"
      ],
      "metadata": {
        "id": "yQeb6OUI4O1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cDR_lPyk8COk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}