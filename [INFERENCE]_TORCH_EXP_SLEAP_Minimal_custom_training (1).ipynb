{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "toc_visible": true,
      "gpuType": "T4",
      "collapsed_sections": [
        "BeeqrLbdupmE",
        "PWl3cG1_9WTK",
        "wSdTJYOdu4L6",
        "5lugn7a_HC0Q",
        "-vYsPusvviiu",
        "0yo95XzRKkba",
        "jzMa-PNPqxxA"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeeqrLbdupmE"
      },
      "source": [
        "# Install SLEAP\n",
        "Don't forget to set **Runtime** -> **Change runtime type...** -> **GPU** as the accelerator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYxJ2rJOMW8B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0521b3c6-0a1a-42e5-9dc3-4a4fa4e3b2bc"
      },
      "source": [
        "!pip install sleap -qqq\n",
        "!pip install albumentations -qqq\n",
        "!pip install nvidia-ml-py3 -qqq"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.4/64.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m105.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m89.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.5/60.5 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.9/84.9 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m103.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m904.1/904.1 kB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.9/228.9 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.3/214.3 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.2/149.2 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.9/131.9 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.2/88.2 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m498.1/498.1 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.1/156.1 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m832.9/832.9 kB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m92.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.3/462.3 kB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m197.1/197.1 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.6/485.6 kB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pykalman (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for jsmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "flax 0.6.10 requires rich>=11.1, but you have rich 10.16.1 which is incompatible.\n",
            "tensorflow-datasets 4.9.2 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jftAOyvvuQeh",
        "outputId": "b7659fce-82ef-41cb-c64b-d2bde21568f5"
      },
      "source": [
        "import os\n",
        "import gc\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "import collections\n",
        "from typing import Sequence, Tuple, Text, Union, Optional, List\n",
        "\n",
        "import nvidia_smi\n",
        "\n",
        "import numpy as np\n",
        "import albumentations as A\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import sleap\n",
        "\n",
        "sleap.versions()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SLEAP: 1.3.1\n",
            "TensorFlow: 2.8.4\n",
            "Numpy: 1.22.4\n",
            "Python: 3.10.12\n",
            "OS: Linux-5.15.107+-x86_64-with-glibc2.31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "PWl3cG1_9WTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "def get_vram():\n",
        "    nvidia_smi.nvmlInit()\n",
        "\n",
        "    deviceCount = nvidia_smi.nvmlDeviceGetCount()\n",
        "    for i in range(deviceCount):\n",
        "        handle = nvidia_smi.nvmlDeviceGetHandleByIndex(i)\n",
        "        info = nvidia_smi.nvmlDeviceGetMemoryInfo(handle)\n",
        "        output = (\"Device {}: {}, Memory : ({:.2f}% free): {} (total), {} (free), {} (used)\"\n",
        "              .format(i, nvidia_smi.nvmlDeviceGetName(handle), 100*info.free/info.total,\n",
        "                      info.total/(1024 ** 3), info.free/(1024 ** 3), info.used/(1024 ** 3)))\n",
        "\n",
        "    nvidia_smi.nvmlShutdown()\n",
        "\n",
        "    return output\n",
        "\n",
        "def get_param_count(model):\n",
        "  trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "  total_params = sum(p.numel() for p in model.parameters())\n",
        "  nontrainable_params = total_params - trainable_params\n",
        "\n",
        "  return trainable_params, nontrainable_params, total_params"
      ],
      "metadata": {
        "id": "X2ESLmrn9VnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 42\n",
        "seed_everything(seed)"
      ],
      "metadata": {
        "id": "2pEmfBalS51R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSdTJYOdu4L6"
      },
      "source": [
        "# Download training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDIF3RKdM86u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4275673-7597-4427-dbc3-e75daef41144"
      },
      "source": [
        "!curl -L --output labels.slp https://storage.googleapis.com/sleap-data/datasets/wt_gold.13pt/tracking_split2/train.pkg.slp\n",
        "!ls -lah\n",
        "\n",
        "!curl -L --output val_labels.slp https://storage.googleapis.com/sleap-data/datasets/wt_gold.13pt/tracking_split2/val.pkg.slp\n",
        "!ls -lah"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  619M  100  619M    0     0  33.1M      0  0:00:18  0:00:18 --:--:-- 39.0M\n",
            "total 620M\n",
            "drwxr-xr-x 1 root root 4.0K Jun 25 02:58 .\n",
            "drwxr-xr-x 1 root root 4.0K Jun 25 02:49 ..\n",
            "drwxr-xr-x 4 root root 4.0K Jun 23 01:14 .config\n",
            "-rw-r--r-- 1 root root 620M Jun 25 02:58 labels.slp\n",
            "drwxr-xr-x 1 root root 4.0K Jun 23 01:15 sample_data\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 77.2M  100 77.2M    0     0  19.6M      0  0:00:03  0:00:03 --:--:-- 19.6M\n",
            "total 697M\n",
            "drwxr-xr-x 1 root root 4.0K Jun 25 02:58 .\n",
            "drwxr-xr-x 1 root root 4.0K Jun 25 02:49 ..\n",
            "drwxr-xr-x 4 root root 4.0K Jun 23 01:14 .config\n",
            "-rw-r--r-- 1 root root 620M Jun 25 02:58 labels.slp\n",
            "drwxr-xr-x 1 root root 4.0K Jun 23 01:15 sample_data\n",
            "-rw-r--r-- 1 root root  78M Jun 25 02:58 val_labels.slp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lugn7a_HC0Q"
      },
      "source": [
        "# Load the training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMkSIZrTHCMr",
        "outputId": "21833b9a-ef64-4a11-c6b7-a4d61a4750be"
      },
      "source": [
        "# SLEAP Labels files (.slp) can include the images as well as labeled instances and\n",
        "# other metadata for a project.\n",
        "labels = sleap.load_file(\"labels.slp\")\n",
        "labels = labels.with_user_labels_only()\n",
        "labels.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skeleton: Skeleton(description=None, nodes=[head, thorax, abdomen, wingL, wingR, forelegL4, forelegR4, midlegL4, midlegR4, hindlegL4, hindlegR4, eyeL, eyeR], edges=[thorax->head, thorax->abdomen, thorax->wingL, thorax->wingR, thorax->forelegL4, thorax->forelegR4, thorax->midlegL4, thorax->midlegR4, thorax->hindlegL4, thorax->hindlegR4, head->eyeL, head->eyeR], symmetries=[forelegL4<->forelegR4, hindlegL4<->hindlegR4, wingL<->wingR, eyeL<->eyeR, midlegL4<->midlegR4])\n",
            "Videos: ['labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp', 'labels.slp']\n",
            "Frames (user/predicted): 1,600/0\n",
            "Instances (user/predicted): 3,200/0\n",
            "Tracks: [Track(spawned_on=0, name='female'), Track(spawned_on=0, name='male')]\n",
            "Suggestions: 0\n",
            "Provenance: {}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's also do the same for the val labels.\n",
        "val_labels = sleap.load_file(\"val_labels.slp\")\n",
        "val_labels = val_labels.with_user_labels_only()\n",
        "val_labels.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sklyy8NWEyff",
        "outputId": "009a1b95-0935-49fb-f86d-466b2b91540f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skeleton: Skeleton(description=None, nodes=[head, thorax, abdomen, wingL, wingR, forelegL4, forelegR4, midlegL4, midlegR4, hindlegL4, hindlegR4, eyeL, eyeR], edges=[thorax->head, thorax->abdomen, thorax->wingL, thorax->wingR, thorax->forelegL4, thorax->forelegR4, thorax->midlegL4, thorax->midlegR4, thorax->hindlegL4, thorax->hindlegR4, head->eyeL, head->eyeR], symmetries=[hindlegL4<->hindlegR4, midlegL4<->midlegR4, eyeL<->eyeR, wingL<->wingR, forelegL4<->forelegR4])\n",
            "Videos: ['val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp', 'val_labels.slp']\n",
            "Frames (user/predicted): 200/0\n",
            "Instances (user/predicted): 400/0\n",
            "Tracks: [Track(spawned_on=0, name='female'), Track(spawned_on=0, name='male')]\n",
            "Suggestions: 0\n",
            "Provenance: {}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EK8DDPHDHBr_",
        "outputId": "ccd74bdb-1195-4aa2-d392-55c15cb33aec"
      },
      "source": [
        "# Labels are list-like containers whose elements are LabeledFrames\n",
        "print(f\"Number of labels: {len(labels)}\")\n",
        "\n",
        "labeled_frame = labels[0]\n",
        "labeled_frame"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of labels: 1600\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LabeledFrame(video=HDF5Video('labels.slp'), frame_idx=166050, instances=2)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pP5uXrU3HX6o",
        "outputId": "4f62f505-c26b-4b3d-f6ee-8a17a8b2242a"
      },
      "source": [
        "# LabeledFrames are containers for instances that were labeled in a single frame\n",
        "instance = labeled_frame[0]\n",
        "instance"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Instance(video=Video(filename=labels.slp, shape=(66, 1024, 1024, 1), backend=HDF5Video), frame_idx=166050, points=[head: (491.6, 187.7), thorax: (474.4, 224.8), abdomen: (459.9, 262.2), wingL: (448.3, 271.7), wingR: (452.1, 273.5), forelegL4: (478.5, 175.9), forelegR4: (499.9, 177.9), midlegL4: (440.6, 216.4), midlegR4: (510.1, 242.7), hindlegL4: (437.2, 234.3), hindlegR4: (490.9, 266.7), eyeL: (477.5, 193.2), eyeR: (498.4, 201.2)], track=Track(spawned_on=0, name='female'))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "700fTPs4Hurg",
        "outputId": "b51adfde-8ddc-4467-f34f-2e7c7cfef687"
      },
      "source": [
        "# They can be converted to numpy arrays where each row corresponds to the coordinates\n",
        "# of a different body part:\n",
        "pts = instance.numpy()\n",
        "pts"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "rec.array([[491.58118169, 187.72078779],\n",
              "           [474.3603939 , 224.80196948],\n",
              "           [459.90098474, 262.16236338],\n",
              "           [448.26137864, 271.72078779],\n",
              "           [452.08118169, 273.54059084],\n",
              "           [478.5       , 175.90098474],\n",
              "           [499.94157558, 177.90098474],\n",
              "           [440.58118169, 216.3603939 ],\n",
              "           [510.12177253, 242.72078779],\n",
              "           [         nan,          nan],\n",
              "           [490.90098474, 266.72078779],\n",
              "           [477.54059084, 193.16236338],\n",
              "           [498.40098474, 201.18019695]],\n",
              "          dtype=float64)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vYsPusvviiu"
      },
      "source": [
        "# Setup training data generation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def update_not_shown_nodes(not_shown_nodes, node_names, new_nodes):\n",
        "  nodes_not_in_aug = np.array(list(set(node_names).difference(set(new_nodes))))\n",
        "  not_shown_in_aug_or_original_ind = np.in1d(node_names, nodes_not_in_aug).nonzero()[0]\n",
        "  not_shown_nodes[not_shown_in_aug_or_original_ind] = True\n",
        "\n",
        "  return not_shown_nodes\n",
        "\n",
        "\n",
        "def update_kp(kp, not_shown_nodes, node_names, new_nodes):\n",
        "  shown_after_aug_ind = np.in1d(node_names, new_nodes).nonzero()[0]\n",
        "  shown_ind = np.in1d(not_shown_nodes, True).nonzero()[0]\n",
        "\n",
        "  assert len(shown_after_aug_ind) == kp.shape[0]\n",
        "\n",
        "  kp_ = np.zeros((len(node_names), 2))\n",
        "  kp_[shown_after_aug_ind] = kp\n",
        "  kp_[shown_ind] = 0\n",
        "\n",
        "  return kp_\n",
        "\n",
        "\n",
        "def make_grid_vectors(\n",
        "    image_height: int, image_width: int, output_stride: int = 1):\n",
        "\n",
        "    xv = torch.arange(0, image_width, step=output_stride).to(torch.float32)\n",
        "    yv = torch.arange(0, image_height, step=output_stride).to(torch.float32)\n",
        "    return xv, yv\n",
        "\n",
        "def make_confmaps(\n",
        "    points: torch.Tensor, xv: torch.Tensor, yv: torch.Tensor, sigma: float):\n",
        "\n",
        "    x = torch.reshape(points[:, 0], (1, 1, -1))\n",
        "    y = torch.reshape(points[:, 1], (1, 1, -1))\n",
        "    cm = torch.exp(\n",
        "        -((torch.reshape(xv, (1, -1, 1)) - x) ** 2 + (torch.reshape(yv, (-1, 1, 1)) - y) ** 2)\n",
        "        / (2 * sigma ** 2)\n",
        "    )\n",
        "\n",
        "    # Replace NaNs with 0.\n",
        "    cm = torch.where(torch.isnan(cm), 0.0, cm)\n",
        "    return cm\n",
        "\n",
        "def get_bbox_coords_on_centroid(anchor_coords, crop_size, img_size):\n",
        "    (cx, cy) = anchor_coords\n",
        "\n",
        "    # [bottom left     top right]\n",
        "    # [  x1, y1,         x2, y2 ]\n",
        "    bbox = [\n",
        "        max(-crop_size / 2 + cx, 0),\n",
        "        max(-crop_size / 2 + cy, 0),\n",
        "        min(crop_size / 2 + cx, img_size[0]),\n",
        "        min(crop_size / 2 + cy, img_size[1])\n",
        "    ]\n",
        "\n",
        "    return bbox\n",
        "\n",
        "# My refactored version of this dataset generator.\n",
        "class DataGenerator(Dataset):\n",
        "    def __init__(self,\n",
        "      labels,\n",
        "      img_size=160,\n",
        "      anchor_name=\"thorax\",\n",
        "      sigma=1.5,\n",
        "      output_stride=2,\n",
        "      rot_range=(-180, 180),\n",
        "      is_train=True\n",
        "    ):\n",
        "        self.labels = labels.with_user_labels_only()\n",
        "        self.labels.remove_empty_instances(keep_empty_frames=False)\n",
        "\n",
        "        self.indices = []\n",
        "        for frame_idx, l in enumerate(self.labels):\n",
        "          inst_indices = np.arange(0, len(l.instances)).tolist()\n",
        "          self.indices.extend([(frame_idx, i) for i in inst_indices])\n",
        "\n",
        "        self.img_size = img_size\n",
        "\n",
        "        assert anchor_name in self.labels.skeleton.node_names\n",
        "        self.anchor_name = anchor_name\n",
        "\n",
        "        # Assuming 1 skeleton.\n",
        "        assert len(labels.skeletons) == 1\n",
        "        self.node_names = labels.skeletons[0].node_names\n",
        "\n",
        "        self.sigma = sigma\n",
        "        self.output_stride = output_stride\n",
        "        self.rot_range = rot_range\n",
        "\n",
        "        self.tfm = A.Compose([\n",
        "            A.Rotate(limit=list(self.rot_range), p=0.5)\n",
        "        ], keypoint_params=A.KeypointParams(format='xy', label_fields=['class_labels']))\n",
        "\n",
        "        self.xv, self.yv = make_grid_vectors(\n",
        "            image_height=self.img_size,\n",
        "            image_width=self.img_size,\n",
        "            output_stride=self.output_stride\n",
        "        )\n",
        "\n",
        "        self.is_train = is_train\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        frame_idx, inst_idx = self.indices[idx]\n",
        "        lf = self.labels[frame_idx]\n",
        "        instance = lf[inst_idx]\n",
        "        img = lf.image\n",
        "        kp = instance.numpy()\n",
        "\n",
        "        # NaNs to 0 and clip.\n",
        "        assert kp.shape == (len(self.node_names), 2)\n",
        "        not_shown_nodes = np.isnan(kp).any(axis=1)\n",
        "        kp = np.nan_to_num(kp, nan=0)\n",
        "        kp = np.concatenate((np.clip(kp[:, :1], 0, img.shape[1]),\n",
        "                              np.clip(kp[:, 1:], 0, img.shape[0])),\n",
        "                            axis=1)\n",
        "\n",
        "        if self.is_train:\n",
        "            # Apply augmentations.\n",
        "            output = self.tfm(image=img, keypoints=kp, class_labels=self.node_names)\n",
        "            img, kp, new_nodes = output[\"image\"], np.array(output[\"keypoints\"]), output[\"class_labels\"]\n",
        "\n",
        "            # Update not_shown_nodes and kp.\n",
        "            not_shown_nodes = update_not_shown_nodes(not_shown_nodes, self.node_names, new_nodes)\n",
        "            kp = update_kp(kp, not_shown_nodes, self.node_names, new_nodes)\n",
        "\n",
        "        # Get bbox coordinate based on centroid.\n",
        "        bbox = get_bbox_coords_on_centroid(\n",
        "          kp[self.node_names.index(self.anchor_name)].tolist(),\n",
        "          self.img_size, img.shape[:2]\n",
        "        )\n",
        "\n",
        "        # Crop and pad.\n",
        "        x1, y1, x2, y2 = bbox\n",
        "        tfm_crop = A.Compose([\n",
        "          A.Crop(int(round(x1)), int(round(y1)), int(round(x2)), int(round(y2))),\n",
        "          A.PadIfNeeded(min_height=self.img_size, min_width=self.img_size)\n",
        "        ], keypoint_params=A.KeypointParams(format='xy', label_fields=['class_labels']))\n",
        "\n",
        "        crop_kp = tfm_crop(image=img, keypoints=kp, class_labels=self.node_names)\n",
        "        crop, kp, new_nodes = crop_kp[\"image\"], np.array(crop_kp[\"keypoints\"]), crop_kp[\"class_labels\"]\n",
        "        crop = torch.Tensor(crop).permute(2, 0, 1)\n",
        "\n",
        "        # Update not_shown_nodes and kp.\n",
        "        not_shown_nodes = update_not_shown_nodes(not_shown_nodes, self.node_names, new_nodes)\n",
        "        kp = update_kp(kp, not_shown_nodes, self.node_names, new_nodes)\n",
        "        kp = torch.Tensor(kp)\n",
        "\n",
        "        # Get confidence map.\n",
        "        xv, yv = make_grid_vectors(\n",
        "          image_height=self.img_size,\n",
        "          image_width=self.img_size,\n",
        "          output_stride=self.output_stride\n",
        "        )\n",
        "\n",
        "        cm = make_confmaps(\n",
        "          points=kp,\n",
        "          xv=self.xv,\n",
        "          yv=self.yv,\n",
        "          sigma=self.sigma\n",
        "        )\n",
        "        cm = cm.permute(2, 0, 1)\n",
        "\n",
        "        return crop, kp, cm"
      ],
      "metadata": {
        "id": "l8Q-1ehtVWbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yo95XzRKkba"
      },
      "source": [
        "# Setting up a neural network model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MaxPool2dWithSamePadding(nn.MaxPool2d):\n",
        "\n",
        "    def _calc_same_pad(self, i: int, k: int, s: int, d: int) -> int:\n",
        "        return max((math.ceil(i / s) - 1) * s + (k - 1) * d + 1 - i, 0)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        if self.padding == \"same\":\n",
        "            ih, iw = x.size()[-2:]\n",
        "\n",
        "            pad_h = self._calc_same_pad(i=ih,\n",
        "                                        k=self.kernel_size if type(self.kernel_size) is int else self.kernel_size[0],\n",
        "                                        s=self.stride if type(self.stride) is int else self.stride[0],\n",
        "                                        d=self.dilation if type(self.dilation) is int else self.dilation[0])\n",
        "            pad_w = self._calc_same_pad(i=iw,\n",
        "                                        k=self.kernel_size if type(self.kernel_size) is int else self.kernel_size[1],\n",
        "                                        s=self.stride if type(self.stride) is int else self.stride[1],\n",
        "                                        d=self.dilation if type(self.dilation) is int else self.dilation[1])\n",
        "\n",
        "            if pad_h > 0 or pad_w > 0:\n",
        "                x = F.pad(\n",
        "                    x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2]\n",
        "                )\n",
        "            self.padding = 0\n",
        "\n",
        "        return F.max_pool2d(x, self.kernel_size, self.stride,\n",
        "                                    self.padding, self.dilation, ceil_mode=self.ceil_mode,\n",
        "                                    return_indices=self.return_indices)\n",
        "\n",
        "def get_act_fn(activation: str) -> nn.Module:\n",
        "    activations = {\n",
        "        'relu': nn.ReLU(),\n",
        "        'sigmoid': nn.Sigmoid(),\n",
        "        'tanh': nn.Tanh()\n",
        "    }\n",
        "\n",
        "    return activations[activation]\n",
        "\n",
        "class SimpleConvBlock(nn.Module):\n",
        "    def __init__(self,\n",
        "        in_channels: int,\n",
        "        pool: bool = True,\n",
        "        pooling_stride: int = 2,\n",
        "        pool_before_convs: bool = False,\n",
        "        num_convs: int = 2,\n",
        "        filters: int = 32,\n",
        "        kernel_size: int = 3,\n",
        "        use_bias: bool = True,\n",
        "        batch_norm: bool = False,\n",
        "        activation: Text = \"relu\"\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.pool = pool\n",
        "        self.pooling_stride = pooling_stride\n",
        "        self.pool_before_convs = pool_before_convs\n",
        "        self.num_convs = num_convs\n",
        "        self.filters = filters\n",
        "        self.kernel_size = kernel_size\n",
        "        self.use_bias = use_bias\n",
        "        self.batch_norm = batch_norm\n",
        "        self.activation = activation\n",
        "\n",
        "        self.blocks = []\n",
        "        if pool and pool_before_convs:\n",
        "            self.blocks.append(\n",
        "                MaxPool2dWithSamePadding(\n",
        "                    kernel_size=2,\n",
        "                    stride=pooling_stride,\n",
        "                    padding=\"same\"\n",
        "                )\n",
        "            )\n",
        "\n",
        "        for i in range(num_convs):\n",
        "            self.blocks.append(\n",
        "                nn.Conv2d(\n",
        "                    in_channels=in_channels if i == 0 else filters,\n",
        "                    out_channels=filters,\n",
        "                    kernel_size=kernel_size,\n",
        "                    stride=1,\n",
        "                    padding=\"same\",\n",
        "                    bias=use_bias\n",
        "                )\n",
        "            )\n",
        "\n",
        "            if batch_norm:\n",
        "                self.blocks.append(\n",
        "                    nn.BatchNorm2d(filters)\n",
        "                )\n",
        "\n",
        "            self.blocks.append(\n",
        "                get_act_fn(activation)\n",
        "            )\n",
        "\n",
        "\n",
        "        if pool and not pool_before_convs:\n",
        "            self.blocks.append(\n",
        "                MaxPool2dWithSamePadding(\n",
        "                    kernel_size=2,\n",
        "                    stride=pooling_stride,\n",
        "                    padding=\"same\"\n",
        "                )\n",
        "            )\n",
        "\n",
        "        self.blocks = nn.Sequential(*self.blocks)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.blocks(x)\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self,\n",
        "        in_channels: int = 3,\n",
        "        filters: int = 64,\n",
        "        down_blocks: int = 4,\n",
        "        filters_rate: Union[float, int] = 2,\n",
        "        current_stride: int = 2,\n",
        "        stem_blocks: int = 0,\n",
        "        convs_per_block: int = 2,\n",
        "        kernel_size: Union[int, Tuple[int, int]] = 3,\n",
        "        middle_block: bool = True,\n",
        "        block_contraction: bool = False\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.filters = filters\n",
        "        self.down_blocks = down_blocks\n",
        "        self.filters_rate = filters_rate\n",
        "        self.current_stride = current_stride\n",
        "        self.stem_blocks = stem_blocks\n",
        "        self.convs_per_block = convs_per_block\n",
        "        self.kernel_size = kernel_size\n",
        "        self.middle_block = middle_block\n",
        "        self.block_contraction = block_contraction\n",
        "\n",
        "        self.encoder_stack = nn.ModuleList([])\n",
        "        for block in range(down_blocks):\n",
        "            prev_block_filters = -1 if block==0 else block_filters\n",
        "            block_filters = int(\n",
        "                filters * (filters_rate ** (block + stem_blocks))\n",
        "            )\n",
        "\n",
        "            self.encoder_stack.append(\n",
        "                SimpleConvBlock(\n",
        "                    in_channels=in_channels if block == 0 else prev_block_filters,\n",
        "                    pool=(block > 0),\n",
        "                    pool_before_convs=True,\n",
        "                    pooling_stride=2,\n",
        "                    num_convs=convs_per_block,\n",
        "                    filters=block_filters,\n",
        "                    kernel_size=kernel_size,\n",
        "                    use_bias=True,\n",
        "                    batch_norm=False,\n",
        "                    activation=\"relu\"\n",
        "                )\n",
        "            )\n",
        "        after_block_filters = block_filters\n",
        "\n",
        "        self.encoder_stack.append(\n",
        "            MaxPool2dWithSamePadding(\n",
        "                kernel_size=2,\n",
        "                stride=2,\n",
        "                padding=\"same\"\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Create a middle block (like the CARE implementation).\n",
        "        if middle_block:\n",
        "            if convs_per_block > 1:\n",
        "                # First convs are one exponent higher than the last encoder block.\n",
        "                block_filters = int(\n",
        "                    filters * (filters_rate ** (down_blocks + stem_blocks))\n",
        "                )\n",
        "                self.encoder_stack.append(\n",
        "                    SimpleConvBlock(\n",
        "                        in_channels=after_block_filters,\n",
        "                        pool=False,\n",
        "                        pool_before_convs=False,\n",
        "                        pooling_stride=2,\n",
        "                        num_convs=convs_per_block - 1,\n",
        "                        filters=block_filters,\n",
        "                        kernel_size=kernel_size,\n",
        "                        use_bias=True,\n",
        "                        batch_norm=False,\n",
        "                        activation=\"relu\",\n",
        "                    )\n",
        "                )\n",
        "\n",
        "            if block_contraction:\n",
        "                # Contract the channels with an exponent lower than the last encoder block.\n",
        "                block_filters = int(\n",
        "                    filters * (filters_rate ** (down_blocks + stem_blocks - 1))\n",
        "                )\n",
        "            else:\n",
        "                # Keep the block output filters the same.\n",
        "                block_filters = int(\n",
        "                    filters * (filters_rate ** (down_blocks + stem_blocks))\n",
        "                )\n",
        "\n",
        "            self.encoder_stack.append(\n",
        "                SimpleConvBlock(\n",
        "                    in_channels=block_filters,\n",
        "                    pool=False,\n",
        "                    pool_before_convs=False,\n",
        "                    pooling_stride=2,\n",
        "                    num_convs=1,\n",
        "                    filters=block_filters,\n",
        "                    kernel_size=kernel_size,\n",
        "                    use_bias=True,\n",
        "                    batch_norm=False,\n",
        "                    activation=\"relu\",\n",
        "                )\n",
        "            )\n",
        "\n",
        "        self.intermediate_features = {}\n",
        "        for i, block in enumerate(self.encoder_stack):\n",
        "            if isinstance(block, SimpleConvBlock) and block.pool:\n",
        "                current_stride *= block.pooling_stride\n",
        "\n",
        "            if current_stride not in self.intermediate_features.values():\n",
        "                self.intermediate_features[i] = current_stride\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        features = []\n",
        "        for i in range(len(self.encoder_stack)):\n",
        "            x = self.encoder_stack[i](x)\n",
        "\n",
        "            if i in self.intermediate_features.keys():\n",
        "                features.append(x)\n",
        "\n",
        "        return x, features[1:][::-1]\n",
        "\n",
        "class SimpleUpsamplingBlock(nn.Module):\n",
        "    def __init__(self,\n",
        "        x_in_shape: int,\n",
        "        current_stride: int,\n",
        "        upsampling_stride: int = 2,\n",
        "        interp_method: Text = \"bilinear\",\n",
        "        refine_convs: int = 2,\n",
        "        refine_convs_filters: int = 64,\n",
        "        refine_convs_kernel_size: int = 3,\n",
        "        refine_convs_use_bias: bool = True,\n",
        "        refine_convs_batch_norm: bool = True,\n",
        "        refine_convs_batch_norm_before_activation: bool = True,\n",
        "        refine_convs_activation: Text = \"relu\"\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.x_in_shape = x_in_shape\n",
        "        self.current_stride = current_stride\n",
        "        self.upsampling_stride = upsampling_stride\n",
        "        self.interp_method = interp_method\n",
        "        self.refine_convs = refine_convs\n",
        "        self.refine_convs_filters = refine_convs_filters\n",
        "        self.refine_convs_kernel_size = refine_convs_kernel_size\n",
        "        self.refine_convs_use_bias = refine_convs_use_bias\n",
        "        self.refine_convs_batch_norm = refine_convs_batch_norm\n",
        "        self.refine_convs_batch_norm_before_activation = refine_convs_batch_norm_before_activation\n",
        "        self.refine_convs_activation = refine_convs_activation\n",
        "\n",
        "        self.blocks = nn.ModuleList([])\n",
        "        if current_stride is not None:\n",
        "            # Append the strides to the block prefix.\n",
        "            new_stride = current_stride // upsampling_stride\n",
        "\n",
        "        # Upsample via interpolation.\n",
        "        self.blocks.append(\n",
        "            nn.Upsample(\n",
        "                scale_factor=upsampling_stride,\n",
        "                mode=interp_method,\n",
        "            )\n",
        "        )\n",
        "\n",
        "\n",
        "        # Add further convolutions to refine after upsampling and/or skip.\n",
        "        for i in range(refine_convs):\n",
        "            filters = refine_convs_filters\n",
        "            self.blocks.append(\n",
        "                nn.Conv2d(\n",
        "                    in_channels=x_in_shape if i==0 else filters,\n",
        "                    out_channels=filters,\n",
        "                    kernel_size=refine_convs_kernel_size,\n",
        "                    stride=1,\n",
        "                    padding=\"same\",\n",
        "                    bias=refine_convs_use_bias\n",
        "                )\n",
        "            )\n",
        "\n",
        "            if (\n",
        "                refine_convs_batch_norm\n",
        "                and refine_convs_batch_norm_before_activation\n",
        "            ):\n",
        "                self.blocks.append(nn.BatchNorm2d(num_features=filters))\n",
        "\n",
        "\n",
        "            self.blocks.append(\n",
        "                get_act_fn(refine_convs_activation)\n",
        "            )\n",
        "\n",
        "            if (\n",
        "                refine_convs_batch_norm\n",
        "                and not refine_convs_batch_norm_before_activation\n",
        "            ):\n",
        "                self.blocks.append(nn.BatchNorm2d(num_features=filters))\n",
        "\n",
        "\n",
        "    def forward(self, x: torch.Tensor, feature: torch.Tensor) -> torch.Tensor:\n",
        "        for idx, b in enumerate(self.blocks):\n",
        "            if idx == 1:  # Right after upsampling or convtranspose2d.\n",
        "                x = torch.concat((x, feature), dim=1)\n",
        "            x = b(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self,\n",
        "        x_in_shape: int,\n",
        "        current_stride: int,\n",
        "        filters: int = 64,\n",
        "        up_blocks: int = 4,\n",
        "        down_blocks: int = 3,\n",
        "        filters_rate: int = 2,\n",
        "        stem_blocks: int = 0,\n",
        "        convs_per_block: int = 2,\n",
        "        kernel_size: int = 3,\n",
        "        block_contraction: bool = False\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.x_in_shape = x_in_shape\n",
        "        self.current_stride = current_stride\n",
        "        self.filters = filters\n",
        "        self.up_blocks = up_blocks\n",
        "        self.down_blocks = down_blocks\n",
        "        self.filters_rate = filters_rate\n",
        "        self.stem_blocks = stem_blocks\n",
        "        self.convs_per_block = convs_per_block\n",
        "        self.kernel_size = kernel_size\n",
        "        self.block_contraction = block_contraction\n",
        "\n",
        "        self.decoder_stack = nn.ModuleList([])\n",
        "        for block in range(up_blocks):\n",
        "            prev_block_filters_in = -1 if block == 0 else block_filters_in\n",
        "            block_filters_in = int(\n",
        "                filters\n",
        "                * (\n",
        "                    filters_rate\n",
        "                    ** (down_blocks + stem_blocks - 1 - block)\n",
        "                )\n",
        "            )\n",
        "            if block_contraction:\n",
        "                block_filters_out = int(\n",
        "                    filters\n",
        "                    * (\n",
        "                        filters_rate\n",
        "                        ** (down_blocks + stem_blocks - 2 - block)\n",
        "                    )\n",
        "                )\n",
        "            else:\n",
        "                block_filters_out = block_filters_in\n",
        "\n",
        "            next_stride = current_stride // 2\n",
        "\n",
        "            self.decoder_stack.append(\n",
        "                SimpleUpsamplingBlock(\n",
        "                    x_in_shape=(x_in_shape + block_filters_in) if block == 0 else (prev_block_filters_in + block_filters_in),\n",
        "                    current_stride=current_stride,\n",
        "                    upsampling_stride=2,\n",
        "                    interp_method=\"bilinear\",\n",
        "                    refine_convs=self.convs_per_block,\n",
        "                    refine_convs_filters=block_filters_out,\n",
        "                    refine_convs_kernel_size=self.kernel_size,\n",
        "                    refine_convs_batch_norm=False,\n",
        "                )\n",
        "            )\n",
        "\n",
        "            current_stride = next_stride\n",
        "\n",
        "    def forward(self, x: torch.Tensor, features: List[torch.Tensor]) -> torch.Tensor:\n",
        "        for i in range(len(self.decoder_stack)):\n",
        "            x = self.decoder_stack[i](x, features[i])\n",
        "\n",
        "        return x\n",
        "\n",
        "class Unet(nn.Module):\n",
        "    def __init__(self,\n",
        "        in_channels: int = 1,\n",
        "        kernel_size: int = 3,\n",
        "        filters: int = 32,\n",
        "        filters_rate: int = 1.5,\n",
        "        stem_blocks: int = 0,\n",
        "        down_blocks: int = 4,\n",
        "        up_blocks: int = 3,\n",
        "        convs_per_block: int = 2,\n",
        "        middle_block: bool = True,\n",
        "        block_contraction: bool = False\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.enc = Encoder(\n",
        "            in_channels=in_channels,\n",
        "            filters=filters,\n",
        "            down_blocks=down_blocks,\n",
        "            filters_rate=filters_rate,\n",
        "            stem_blocks=stem_blocks,\n",
        "            convs_per_block=convs_per_block,\n",
        "            kernel_size=kernel_size,\n",
        "            middle_block=middle_block,\n",
        "            block_contraction=block_contraction\n",
        "        )\n",
        "\n",
        "        current_stride = int(\n",
        "            np.prod(\n",
        "                [block.pooling_stride for block in self.enc.encoder_stack if hasattr(block, \"pool\") and block.pool]\n",
        "                + [1]\n",
        "            )\n",
        "        )\n",
        "\n",
        "        x_in_shape = int(\n",
        "            filters * (filters_rate ** (down_blocks + stem_blocks))\n",
        "        )\n",
        "\n",
        "        self.dec = Decoder(x_in_shape=x_in_shape, current_stride=current_stride, filters=filters,\n",
        "            up_blocks=up_blocks, down_blocks=down_blocks, filters_rate=filters_rate\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x, features = self.enc(x)\n",
        "        x = self.dec(x, features)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "fCMnTHR9VetA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEfgZT4hLyW4"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "\n",
        "cores = multiprocessing.cpu_count()\n",
        "cores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFNfmlnprhmb",
        "outputId": "fc2f5934-f42e-4a2c-95e0-c6224d531e1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "FP7r_rzYvDy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filters = 32\n",
        "filters_rate = 1.5\n",
        "down_blocks = 4\n",
        "stem_blocks = 0\n",
        "up_blocks = 3\n",
        "\n",
        "train_ds = DataGenerator(labels)\n",
        "train_dl = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=4,\n",
        "    shuffle=True,\n",
        "    num_workers=cores,\n",
        "    pin_memory=True,\n",
        "    drop_last=True,\n",
        "    prefetch_factor=2\n",
        ")\n",
        "\n",
        "val_ds = DataGenerator(val_labels, is_train=False)\n",
        "val_dl = DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=4,\n",
        "    shuffle=False,\n",
        "    num_workers=cores,\n",
        "    pin_memory=True,\n",
        "    drop_last=True,\n",
        "    prefetch_factor=2\n",
        ")\n",
        "\n",
        "unet = Unet(filters=filters,\n",
        "            filters_rate=filters_rate,\n",
        "            down_blocks=down_blocks,\n",
        "            stem_blocks=stem_blocks,\n",
        "            up_blocks=up_blocks)\n",
        "\n",
        "in_channels = int(\n",
        "    filters\n",
        "    * (\n",
        "        filters_rate\n",
        "        ** (down_blocks + stem_blocks - 1 - up_blocks + 1)\n",
        "    )\n",
        ")\n",
        "model = nn.Sequential(*[\n",
        "    unet,\n",
        "    nn.Conv2d(in_channels=in_channels, out_channels=13, kernel_size=1, padding=\"same\")\n",
        "])\n",
        "\n",
        "opt = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "model = model.to(device)\n",
        "\n",
        "for epoch in range(40):\n",
        "    _ = model.train()\n",
        "    start_time = time.time()\n",
        "    train_loss = 0\n",
        "    for idx, batch in enumerate(train_dl):\n",
        "        X, _, y = batch\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        with torch.autocast(device):\n",
        "            y_preds = model(X)\n",
        "            loss = nn.MSELoss()(y_preds, y)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(opt)\n",
        "        scaler.update()\n",
        "        opt.zero_grad()\n",
        "\n",
        "        if idx % 100 == 0:\n",
        "          print(f\"Epoch: {epoch} | Loss: {loss:.5f}\")\n",
        "\n",
        "        train_loss += loss\n",
        "\n",
        "    train_loss /= (idx+1)\n",
        "    train_time = time.time() - start_time\n",
        "    print(f\"TRAIN: --- {train_time}s seconds ---\")\n",
        "\n",
        "    _  = model.eval()\n",
        "    start_time = time.time()\n",
        "    val_loss = 0\n",
        "    for idx, batch in enumerate(val_dl):\n",
        "        X, _, y = batch\n",
        "        X = X.to(\"cuda\")\n",
        "        y = y.to(\"cuda\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "            y_preds = model(X)\n",
        "            loss = nn.MSELoss()(y_preds, y)\n",
        "\n",
        "        val_loss += loss\n",
        "\n",
        "    val_loss /= (idx+1)\n",
        "    val_time = time.time() - start_time\n",
        "    print(f\"VAL: --- {val_time}s seconds ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDMSgbrrY7E0",
        "outputId": "e745f53a-1106-4a05-f523-d6ad7b718ea6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Loss: 0.01165\n",
            "Epoch: 0 | Loss: 0.00037\n",
            "Epoch: 0 | Loss: 0.00029\n",
            "Epoch: 0 | Loss: 0.00028\n",
            "Epoch: 0 | Loss: 0.00027\n",
            "Epoch: 0 | Loss: 0.00028\n",
            "Epoch: 0 | Loss: 0.00027\n",
            "Epoch: 0 | Loss: 0.00027\n",
            "TRAIN: --- 73.94701409339905s seconds ---\n",
            "VAL: --- 5.413044452667236s seconds ---\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00026\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "Epoch: 1 | Loss: 0.00027\n",
            "TRAIN: --- 70.95584797859192s seconds ---\n",
            "VAL: --- 5.485888481140137s seconds ---\n",
            "Epoch: 2 | Loss: 0.00027\n",
            "Epoch: 2 | Loss: 0.00027\n",
            "Epoch: 2 | Loss: 0.00027\n",
            "Epoch: 2 | Loss: 0.00027\n",
            "Epoch: 2 | Loss: 0.00026\n",
            "Epoch: 2 | Loss: 0.00027\n",
            "Epoch: 2 | Loss: 0.00027\n",
            "Epoch: 2 | Loss: 0.00027\n",
            "TRAIN: --- 68.93617725372314s seconds ---\n",
            "VAL: --- 6.217429876327515s seconds ---\n",
            "Epoch: 3 | Loss: 0.00027\n",
            "Epoch: 3 | Loss: 0.00026\n",
            "Epoch: 3 | Loss: 0.00027\n",
            "Epoch: 3 | Loss: 0.00026\n",
            "Epoch: 3 | Loss: 0.00026\n",
            "Epoch: 3 | Loss: 0.00026\n",
            "Epoch: 3 | Loss: 0.00025\n",
            "Epoch: 3 | Loss: 0.00026\n",
            "TRAIN: --- 72.09603309631348s seconds ---\n",
            "VAL: --- 5.758113622665405s seconds ---\n",
            "Epoch: 4 | Loss: 0.00025\n",
            "Epoch: 4 | Loss: 0.00025\n",
            "Epoch: 4 | Loss: 0.00025\n",
            "Epoch: 4 | Loss: 0.00024\n",
            "Epoch: 4 | Loss: 0.00025\n",
            "Epoch: 4 | Loss: 0.00024\n",
            "Epoch: 4 | Loss: 0.00025\n",
            "Epoch: 4 | Loss: 0.00023\n",
            "TRAIN: --- 71.93285036087036s seconds ---\n",
            "VAL: --- 5.211551904678345s seconds ---\n",
            "Epoch: 5 | Loss: 0.00024\n",
            "Epoch: 5 | Loss: 0.00024\n",
            "Epoch: 5 | Loss: 0.00023\n",
            "Epoch: 5 | Loss: 0.00023\n",
            "Epoch: 5 | Loss: 0.00023\n",
            "Epoch: 5 | Loss: 0.00022\n",
            "Epoch: 5 | Loss: 0.00023\n",
            "Epoch: 5 | Loss: 0.00022\n",
            "TRAIN: --- 69.70802450180054s seconds ---\n",
            "VAL: --- 5.80074405670166s seconds ---\n",
            "Epoch: 6 | Loss: 0.00023\n",
            "Epoch: 6 | Loss: 0.00023\n",
            "Epoch: 6 | Loss: 0.00022\n",
            "Epoch: 6 | Loss: 0.00022\n",
            "Epoch: 6 | Loss: 0.00023\n",
            "Epoch: 6 | Loss: 0.00021\n",
            "Epoch: 6 | Loss: 0.00022\n",
            "Epoch: 6 | Loss: 0.00022\n",
            "TRAIN: --- 70.33799982070923s seconds ---\n",
            "VAL: --- 6.020227909088135s seconds ---\n",
            "Epoch: 7 | Loss: 0.00023\n",
            "Epoch: 7 | Loss: 0.00022\n",
            "Epoch: 7 | Loss: 0.00021\n",
            "Epoch: 7 | Loss: 0.00020\n",
            "Epoch: 7 | Loss: 0.00022\n",
            "Epoch: 7 | Loss: 0.00021\n",
            "Epoch: 7 | Loss: 0.00023\n",
            "Epoch: 7 | Loss: 0.00020\n",
            "TRAIN: --- 68.54581451416016s seconds ---\n",
            "VAL: --- 6.628276109695435s seconds ---\n",
            "Epoch: 8 | Loss: 0.00020\n",
            "Epoch: 8 | Loss: 0.00021\n",
            "Epoch: 8 | Loss: 0.00020\n",
            "Epoch: 8 | Loss: 0.00021\n",
            "Epoch: 8 | Loss: 0.00019\n",
            "Epoch: 8 | Loss: 0.00021\n",
            "Epoch: 8 | Loss: 0.00019\n",
            "Epoch: 8 | Loss: 0.00019\n",
            "TRAIN: --- 68.44097232818604s seconds ---\n",
            "VAL: --- 6.597244739532471s seconds ---\n",
            "Epoch: 9 | Loss: 0.00018\n",
            "Epoch: 9 | Loss: 0.00020\n",
            "Epoch: 9 | Loss: 0.00018\n",
            "Epoch: 9 | Loss: 0.00018\n",
            "Epoch: 9 | Loss: 0.00018\n",
            "Epoch: 9 | Loss: 0.00019\n",
            "Epoch: 9 | Loss: 0.00019\n",
            "Epoch: 9 | Loss: 0.00019\n",
            "TRAIN: --- 68.4811372756958s seconds ---\n",
            "VAL: --- 7.103419780731201s seconds ---\n",
            "Epoch: 10 | Loss: 0.00018\n",
            "Epoch: 10 | Loss: 0.00021\n",
            "Epoch: 10 | Loss: 0.00018\n",
            "Epoch: 10 | Loss: 0.00019\n",
            "Epoch: 10 | Loss: 0.00019\n",
            "Epoch: 10 | Loss: 0.00018\n",
            "Epoch: 10 | Loss: 0.00017\n",
            "Epoch: 10 | Loss: 0.00021\n",
            "TRAIN: --- 67.519047498703s seconds ---\n",
            "VAL: --- 7.5910255908966064s seconds ---\n",
            "Epoch: 11 | Loss: 0.00016\n",
            "Epoch: 11 | Loss: 0.00018\n",
            "Epoch: 11 | Loss: 0.00019\n",
            "Epoch: 11 | Loss: 0.00017\n",
            "Epoch: 11 | Loss: 0.00017\n",
            "Epoch: 11 | Loss: 0.00016\n",
            "Epoch: 11 | Loss: 0.00015\n",
            "Epoch: 11 | Loss: 0.00017\n",
            "TRAIN: --- 67.21635413169861s seconds ---\n",
            "VAL: --- 8.032925128936768s seconds ---\n",
            "Epoch: 12 | Loss: 0.00017\n",
            "Epoch: 12 | Loss: 0.00016\n",
            "Epoch: 12 | Loss: 0.00015\n",
            "Epoch: 12 | Loss: 0.00016\n",
            "Epoch: 12 | Loss: 0.00018\n",
            "Epoch: 12 | Loss: 0.00016\n",
            "Epoch: 12 | Loss: 0.00016\n",
            "Epoch: 12 | Loss: 0.00015\n",
            "TRAIN: --- 66.8997712135315s seconds ---\n",
            "VAL: --- 8.352481842041016s seconds ---\n",
            "Epoch: 13 | Loss: 0.00016\n",
            "Epoch: 13 | Loss: 0.00013\n",
            "Epoch: 13 | Loss: 0.00014\n",
            "Epoch: 13 | Loss: 0.00014\n",
            "Epoch: 13 | Loss: 0.00015\n",
            "Epoch: 13 | Loss: 0.00013\n",
            "Epoch: 13 | Loss: 0.00011\n",
            "Epoch: 13 | Loss: 0.00011\n",
            "TRAIN: --- 67.00724864006042s seconds ---\n",
            "VAL: --- 8.52524709701538s seconds ---\n",
            "Epoch: 14 | Loss: 0.00014\n",
            "Epoch: 14 | Loss: 0.00011\n",
            "Epoch: 14 | Loss: 0.00015\n",
            "Epoch: 14 | Loss: 0.00012\n",
            "Epoch: 14 | Loss: 0.00011\n",
            "Epoch: 14 | Loss: 0.00012\n",
            "Epoch: 14 | Loss: 0.00017\n",
            "Epoch: 14 | Loss: 0.00011\n",
            "TRAIN: --- 66.90601968765259s seconds ---\n",
            "VAL: --- 8.26732611656189s seconds ---\n",
            "Epoch: 15 | Loss: 0.00014\n",
            "Epoch: 15 | Loss: 0.00012\n",
            "Epoch: 15 | Loss: 0.00010\n",
            "Epoch: 15 | Loss: 0.00012\n",
            "Epoch: 15 | Loss: 0.00010\n",
            "Epoch: 15 | Loss: 0.00014\n",
            "Epoch: 15 | Loss: 0.00011\n",
            "Epoch: 15 | Loss: 0.00013\n",
            "TRAIN: --- 66.78250527381897s seconds ---\n",
            "VAL: --- 7.4339964389801025s seconds ---\n",
            "Epoch: 16 | Loss: 0.00011\n",
            "Epoch: 16 | Loss: 0.00012\n",
            "Epoch: 16 | Loss: 0.00009\n",
            "Epoch: 16 | Loss: 0.00010\n",
            "Epoch: 16 | Loss: 0.00007\n",
            "Epoch: 16 | Loss: 0.00012\n",
            "Epoch: 16 | Loss: 0.00009\n",
            "Epoch: 16 | Loss: 0.00014\n",
            "TRAIN: --- 67.33026218414307s seconds ---\n",
            "VAL: --- 7.352325439453125s seconds ---\n",
            "Epoch: 17 | Loss: 0.00012\n",
            "Epoch: 17 | Loss: 0.00012\n",
            "Epoch: 17 | Loss: 0.00013\n",
            "Epoch: 17 | Loss: 0.00010\n",
            "Epoch: 17 | Loss: 0.00013\n",
            "Epoch: 17 | Loss: 0.00014\n",
            "Epoch: 17 | Loss: 0.00014\n",
            "Epoch: 17 | Loss: 0.00012\n",
            "TRAIN: --- 67.79122257232666s seconds ---\n",
            "VAL: --- 6.729104995727539s seconds ---\n",
            "Epoch: 18 | Loss: 0.00007\n",
            "Epoch: 18 | Loss: 0.00009\n",
            "Epoch: 18 | Loss: 0.00011\n",
            "Epoch: 18 | Loss: 0.00010\n",
            "Epoch: 18 | Loss: 0.00010\n",
            "Epoch: 18 | Loss: 0.00010\n",
            "Epoch: 18 | Loss: 0.00010\n",
            "Epoch: 18 | Loss: 0.00011\n",
            "TRAIN: --- 68.47124934196472s seconds ---\n",
            "VAL: --- 5.430939435958862s seconds ---\n",
            "Epoch: 19 | Loss: 0.00008\n",
            "Epoch: 19 | Loss: 0.00011\n",
            "Epoch: 19 | Loss: 0.00012\n",
            "Epoch: 19 | Loss: 0.00008\n",
            "Epoch: 19 | Loss: 0.00010\n",
            "Epoch: 19 | Loss: 0.00008\n",
            "Epoch: 19 | Loss: 0.00010\n",
            "Epoch: 19 | Loss: 0.00013\n",
            "TRAIN: --- 69.86891674995422s seconds ---\n",
            "VAL: --- 4.901953220367432s seconds ---\n",
            "Epoch: 20 | Loss: 0.00015\n",
            "Epoch: 20 | Loss: 0.00009\n",
            "Epoch: 20 | Loss: 0.00012\n",
            "Epoch: 20 | Loss: 0.00009\n",
            "Epoch: 20 | Loss: 0.00007\n",
            "Epoch: 20 | Loss: 0.00013\n",
            "Epoch: 20 | Loss: 0.00011\n",
            "Epoch: 20 | Loss: 0.00007\n",
            "TRAIN: --- 70.73429083824158s seconds ---\n",
            "VAL: --- 4.916454315185547s seconds ---\n",
            "Epoch: 21 | Loss: 0.00011\n",
            "Epoch: 21 | Loss: 0.00011\n",
            "Epoch: 21 | Loss: 0.00007\n",
            "Epoch: 21 | Loss: 0.00007\n",
            "Epoch: 21 | Loss: 0.00011\n",
            "Epoch: 21 | Loss: 0.00007\n",
            "Epoch: 21 | Loss: 0.00008\n",
            "Epoch: 21 | Loss: 0.00009\n",
            "TRAIN: --- 70.45517158508301s seconds ---\n",
            "VAL: --- 5.020462512969971s seconds ---\n",
            "Epoch: 22 | Loss: 0.00008\n",
            "Epoch: 22 | Loss: 0.00012\n",
            "Epoch: 22 | Loss: 0.00011\n",
            "Epoch: 22 | Loss: 0.00008\n",
            "Epoch: 22 | Loss: 0.00011\n",
            "Epoch: 22 | Loss: 0.00012\n",
            "Epoch: 22 | Loss: 0.00012\n",
            "Epoch: 22 | Loss: 0.00011\n",
            "TRAIN: --- 70.49485802650452s seconds ---\n",
            "VAL: --- 4.993178606033325s seconds ---\n",
            "Epoch: 23 | Loss: 0.00011\n",
            "Epoch: 23 | Loss: 0.00008\n",
            "Epoch: 23 | Loss: 0.00007\n",
            "Epoch: 23 | Loss: 0.00006\n",
            "Epoch: 23 | Loss: 0.00011\n",
            "Epoch: 23 | Loss: 0.00010\n",
            "Epoch: 23 | Loss: 0.00009\n",
            "Epoch: 23 | Loss: 0.00005\n",
            "TRAIN: --- 69.2286729812622s seconds ---\n",
            "VAL: --- 5.483245611190796s seconds ---\n",
            "Epoch: 24 | Loss: 0.00007\n",
            "Epoch: 24 | Loss: 0.00011\n",
            "Epoch: 24 | Loss: 0.00009\n",
            "Epoch: 24 | Loss: 0.00010\n",
            "Epoch: 24 | Loss: 0.00009\n",
            "Epoch: 24 | Loss: 0.00007\n",
            "Epoch: 24 | Loss: 0.00008\n",
            "Epoch: 24 | Loss: 0.00012\n",
            "TRAIN: --- 68.74302363395691s seconds ---\n",
            "VAL: --- 6.130484342575073s seconds ---\n",
            "Epoch: 25 | Loss: 0.00015\n",
            "Epoch: 25 | Loss: 0.00007\n",
            "Epoch: 25 | Loss: 0.00006\n",
            "Epoch: 25 | Loss: 0.00007\n",
            "Epoch: 25 | Loss: 0.00010\n",
            "Epoch: 25 | Loss: 0.00012\n",
            "Epoch: 25 | Loss: 0.00007\n",
            "Epoch: 25 | Loss: 0.00013\n",
            "TRAIN: --- 66.71809148788452s seconds ---\n",
            "VAL: --- 7.431727886199951s seconds ---\n",
            "Epoch: 26 | Loss: 0.00008\n",
            "Epoch: 26 | Loss: 0.00008\n",
            "Epoch: 26 | Loss: 0.00010\n",
            "Epoch: 26 | Loss: 0.00006\n",
            "Epoch: 26 | Loss: 0.00009\n",
            "Epoch: 26 | Loss: 0.00013\n",
            "Epoch: 26 | Loss: 0.00008\n",
            "Epoch: 26 | Loss: 0.00013\n",
            "TRAIN: --- 66.50797033309937s seconds ---\n",
            "VAL: --- 8.397551536560059s seconds ---\n",
            "Epoch: 27 | Loss: 0.00007\n",
            "Epoch: 27 | Loss: 0.00008\n",
            "Epoch: 27 | Loss: 0.00011\n",
            "Epoch: 27 | Loss: 0.00010\n",
            "Epoch: 27 | Loss: 0.00013\n",
            "Epoch: 27 | Loss: 0.00006\n",
            "Epoch: 27 | Loss: 0.00007\n",
            "Epoch: 27 | Loss: 0.00008\n",
            "TRAIN: --- 66.27501320838928s seconds ---\n",
            "VAL: --- 8.145585060119629s seconds ---\n",
            "Epoch: 28 | Loss: 0.00005\n",
            "Epoch: 28 | Loss: 0.00012\n",
            "Epoch: 28 | Loss: 0.00010\n",
            "Epoch: 28 | Loss: 0.00008\n",
            "Epoch: 28 | Loss: 0.00009\n",
            "Epoch: 28 | Loss: 0.00008\n",
            "Epoch: 28 | Loss: 0.00010\n",
            "Epoch: 28 | Loss: 0.00007\n",
            "TRAIN: --- 66.88267374038696s seconds ---\n",
            "VAL: --- 8.164303302764893s seconds ---\n",
            "Epoch: 29 | Loss: 0.00006\n",
            "Epoch: 29 | Loss: 0.00006\n",
            "Epoch: 29 | Loss: 0.00009\n",
            "Epoch: 29 | Loss: 0.00010\n",
            "Epoch: 29 | Loss: 0.00008\n",
            "Epoch: 29 | Loss: 0.00007\n",
            "Epoch: 29 | Loss: 0.00012\n",
            "Epoch: 29 | Loss: 0.00006\n",
            "TRAIN: --- 66.39921188354492s seconds ---\n",
            "VAL: --- 7.725443363189697s seconds ---\n",
            "Epoch: 30 | Loss: 0.00007\n",
            "Epoch: 30 | Loss: 0.00008\n",
            "Epoch: 30 | Loss: 0.00006\n",
            "Epoch: 30 | Loss: 0.00011\n",
            "Epoch: 30 | Loss: 0.00009\n",
            "Epoch: 30 | Loss: 0.00007\n",
            "Epoch: 30 | Loss: 0.00008\n",
            "Epoch: 30 | Loss: 0.00007\n",
            "TRAIN: --- 66.83563613891602s seconds ---\n",
            "VAL: --- 7.183795213699341s seconds ---\n",
            "Epoch: 31 | Loss: 0.00005\n",
            "Epoch: 31 | Loss: 0.00011\n",
            "Epoch: 31 | Loss: 0.00014\n",
            "Epoch: 31 | Loss: 0.00007\n",
            "Epoch: 31 | Loss: 0.00009\n",
            "Epoch: 31 | Loss: 0.00010\n",
            "Epoch: 31 | Loss: 0.00007\n",
            "Epoch: 31 | Loss: 0.00006\n",
            "TRAIN: --- 67.27126359939575s seconds ---\n",
            "VAL: --- 6.2227301597595215s seconds ---\n",
            "Epoch: 32 | Loss: 0.00006\n",
            "Epoch: 32 | Loss: 0.00007\n",
            "Epoch: 32 | Loss: 0.00006\n",
            "Epoch: 32 | Loss: 0.00005\n",
            "Epoch: 32 | Loss: 0.00006\n",
            "Epoch: 32 | Loss: 0.00010\n",
            "Epoch: 32 | Loss: 0.00007\n",
            "Epoch: 32 | Loss: 0.00010\n",
            "TRAIN: --- 67.58134341239929s seconds ---\n",
            "VAL: --- 4.908783912658691s seconds ---\n",
            "Epoch: 33 | Loss: 0.00009\n",
            "Epoch: 33 | Loss: 0.00008\n",
            "Epoch: 33 | Loss: 0.00006\n",
            "Epoch: 33 | Loss: 0.00005\n",
            "Epoch: 33 | Loss: 0.00008\n",
            "Epoch: 33 | Loss: 0.00007\n",
            "Epoch: 33 | Loss: 0.00009\n",
            "Epoch: 33 | Loss: 0.00007\n",
            "TRAIN: --- 69.42930293083191s seconds ---\n",
            "VAL: --- 4.955087184906006s seconds ---\n",
            "Epoch: 34 | Loss: 0.00009\n",
            "Epoch: 34 | Loss: 0.00006\n",
            "Epoch: 34 | Loss: 0.00008\n",
            "Epoch: 34 | Loss: 0.00007\n",
            "Epoch: 34 | Loss: 0.00008\n",
            "Epoch: 34 | Loss: 0.00009\n",
            "Epoch: 34 | Loss: 0.00010\n",
            "Epoch: 34 | Loss: 0.00008\n",
            "TRAIN: --- 69.88276743888855s seconds ---\n",
            "VAL: --- 4.89745020866394s seconds ---\n",
            "Epoch: 35 | Loss: 0.00004\n",
            "Epoch: 35 | Loss: 0.00007\n",
            "Epoch: 35 | Loss: 0.00011\n",
            "Epoch: 35 | Loss: 0.00005\n",
            "Epoch: 35 | Loss: 0.00008\n",
            "Epoch: 35 | Loss: 0.00008\n",
            "Epoch: 35 | Loss: 0.00006\n",
            "Epoch: 35 | Loss: 0.00007\n",
            "TRAIN: --- 69.63415479660034s seconds ---\n",
            "VAL: --- 4.981689453125s seconds ---\n",
            "Epoch: 36 | Loss: 0.00007\n",
            "Epoch: 36 | Loss: 0.00006\n",
            "Epoch: 36 | Loss: 0.00007\n",
            "Epoch: 36 | Loss: 0.00007\n",
            "Epoch: 36 | Loss: 0.00009\n",
            "Epoch: 36 | Loss: 0.00008\n",
            "Epoch: 36 | Loss: 0.00008\n",
            "Epoch: 36 | Loss: 0.00007\n",
            "TRAIN: --- 68.46587872505188s seconds ---\n",
            "VAL: --- 5.787508964538574s seconds ---\n",
            "Epoch: 37 | Loss: 0.00006\n",
            "Epoch: 37 | Loss: 0.00008\n",
            "Epoch: 37 | Loss: 0.00006\n",
            "Epoch: 37 | Loss: 0.00009\n",
            "Epoch: 37 | Loss: 0.00006\n",
            "Epoch: 37 | Loss: 0.00007\n",
            "Epoch: 37 | Loss: 0.00006\n",
            "Epoch: 37 | Loss: 0.00007\n",
            "TRAIN: --- 68.49646615982056s seconds ---\n",
            "VAL: --- 6.759146213531494s seconds ---\n",
            "Epoch: 38 | Loss: 0.00007\n",
            "Epoch: 38 | Loss: 0.00006\n",
            "Epoch: 38 | Loss: 0.00009\n",
            "Epoch: 38 | Loss: 0.00007\n",
            "Epoch: 38 | Loss: 0.00012\n",
            "Epoch: 38 | Loss: 0.00009\n",
            "Epoch: 38 | Loss: 0.00007\n",
            "Epoch: 38 | Loss: 0.00007\n",
            "TRAIN: --- 66.28750324249268s seconds ---\n",
            "VAL: --- 8.295421838760376s seconds ---\n",
            "Epoch: 39 | Loss: 0.00008\n",
            "Epoch: 39 | Loss: 0.00006\n",
            "Epoch: 39 | Loss: 0.00005\n",
            "Epoch: 39 | Loss: 0.00010\n",
            "Epoch: 39 | Loss: 0.00008\n",
            "Epoch: 39 | Loss: 0.00008\n",
            "Epoch: 39 | Loss: 0.00007\n",
            "Epoch: 39 | Loss: 0.00010\n",
            "TRAIN: --- 66.61282587051392s seconds ---\n",
            "VAL: --- 7.376425743103027s seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference & Evaluation"
      ],
      "metadata": {
        "id": "TfCrTPwPOm_d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utility Functions"
      ],
      "metadata": {
        "id": "Dyb-Lsqs0gzI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. find instance peaks\n",
        "def find_peaks(cms, xv, yv):\n",
        "    \"\"\"Find peaks in a set of confidence maps via integral regression.\n",
        "\n",
        "    Args:\n",
        "        cms: A batch of confidence maps of shape (batch_size, height, width, n_points).\n",
        "        xv: X-sampling vector of shape (grid_width,).\n",
        "        yv: Y-sampling vector of shape (grid_width,).\n",
        "\n",
        "    Returns:\n",
        "        A set of estimated peaks of shape (batch_size, n_points, 2).\n",
        "\n",
        "    Notes:\n",
        "        This function can also accept confidence maps of shape (height, width, n_points)\n",
        "        and returns peaks as (n_points, 2).\n",
        "    \"\"\"\n",
        "    is_singleton = cms.ndim == 3\n",
        "    if is_singleton:\n",
        "        cms = np.expand_dims(cms, axis=0)\n",
        "\n",
        "    # Find integral over height and width.\n",
        "    z = cms.reshape(cms.shape[0], -1, cms.shape[-1]).sum(axis=1)\n",
        "\n",
        "    # Compute x- and y-coordinates.\n",
        "    x = (cms * xv.reshape(1, 1, -1, 1)).reshape(cms.shape[0], -1, cms.shape[-1]).sum(axis=1) / z\n",
        "    y = (cms * yv.reshape(1, -1, 1, 1)).reshape(cms.shape[0], -1, cms.shape[-1]).sum(axis=1) / z\n",
        "\n",
        "    # Stack the coordinates into (batch_size, n_points, 2).\n",
        "    pts_pr = np.stack([x, y], axis=-1)\n",
        "\n",
        "    if is_singleton:\n",
        "        pts_pr = pts_pr.squeeze(axis=0)\n",
        "    return pts_pr\n",
        "\n",
        "# 2. get OKS scores\n",
        "# 3. get correct data structures -> match_instances/match_frames\n",
        "# 4. compute voc mAP scores"
      ],
      "metadata": {
        "id": "lvEsjPCLOni8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_instance_area(points: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Compute the area of the bounding box of a set of keypoints.\n",
        "\n",
        "    Args:\n",
        "        points: A numpy array of coordinates.\n",
        "\n",
        "    Returns:\n",
        "        The area of the bounding box of the points.\n",
        "    \"\"\"\n",
        "    if points.ndim == 2:\n",
        "        points = np.expand_dims(points, axis=0)\n",
        "\n",
        "    min_pt = np.nanmin(points, axis=-2)\n",
        "    max_pt = np.nanmax(points, axis=-2)\n",
        "\n",
        "    return np.prod(max_pt - min_pt, axis=-1)\n",
        "\n",
        "\n",
        "\n",
        "def compute_oks(\n",
        "    points_gt: np.ndarray,\n",
        "    points_pr: np.ndarray,\n",
        "    scale: Optional[float] = None,\n",
        "    stddev: float = 0.025,\n",
        ") -> np.ndarray:\n",
        "    \"\"\"Compute the object keypoints similarity between sets of points.\n",
        "\n",
        "    Args:\n",
        "        points_gt: Ground truth instances of shape (n_gt, n_nodes, n_ed),\n",
        "            where n_nodes is the number of body parts/keypoint types, and n_ed\n",
        "            is the number of Euclidean dimensions (typically 2 or 3). Keypoints\n",
        "            that are missing/not visible should be represented as NaNs.\n",
        "        points_pr: Predicted instance of shape (n_pr, n_nodes, n_ed).\n",
        "        scale: Size scaling factor to use when weighing the scores, typically\n",
        "            the area of the bounding box of the instance (in pixels). This\n",
        "            should be of the length n_gt. If a scalar is provided, the same\n",
        "            number is used for all ground truth instances. If set to None, the\n",
        "            bounding box area of the ground truth instances will be calculated.\n",
        "        stddev: The standard deviation associated with the spread in the\n",
        "            localization accuracy of each node/keypoint type. This should be of\n",
        "            the length n_nodes. \"Easier\" keypoint types will have lower values\n",
        "            to reflect the smaller spread expected in localizing it.\n",
        "\n",
        "    Returns:\n",
        "        The object keypoints similarity between every pair of ground truth and\n",
        "        predicted instance, a numpy array of of shape (n_gt, n_pr) in the range\n",
        "        of [0, 1.0], with 1.0 denoting a perfect match.\n",
        "\n",
        "    Notes:\n",
        "        It's important to set the stddev appropriately when accounting for the\n",
        "        difficulty of each keypoint type. For reference, the median value for\n",
        "        all keypoint types in COCO is 0.072. The \"easiest\" keypoint is the left\n",
        "        eye, with stddev of 0.025, since it is easy to precisely locate the\n",
        "        eyes when labeling. The \"hardest\" keypoint is the left hip, with stddev\n",
        "        of 0.107, since it's hard to locate the left hip bone without external\n",
        "        anatomical features and since it is often occluded by clothing.\n",
        "\n",
        "        The implementation here is based off of the descriptions in:\n",
        "        Ronch & Perona. \"Benchmarking and Error Diagnosis in Multi-Instance Pose\n",
        "        Estimation.\" ICCV (2017).\n",
        "    \"\"\"\n",
        "    if points_gt.ndim == 2:\n",
        "        points_gt = np.expand_dims(points_gt, axis=0)\n",
        "    if points_pr.ndim == 2:\n",
        "        points_pr = np.expand_dims(points_pr, axis=0)\n",
        "\n",
        "    if scale is None:\n",
        "        scale = compute_instance_area(points_gt)\n",
        "\n",
        "    n_gt, n_nodes, n_ed = points_gt.shape  # n_ed = 2 or 3 (euclidean dimensions)\n",
        "    n_pr = points_pr.shape[0]\n",
        "\n",
        "    # If scalar scale was provided, use the same for each ground truth instance.\n",
        "    if np.isscalar(scale):\n",
        "        scale = np.full(n_gt, scale)\n",
        "\n",
        "    # If scalar standard deviation was provided, use the same for each node.\n",
        "    if np.isscalar(stddev):\n",
        "        stddev = np.full(n_nodes, stddev)\n",
        "\n",
        "    # Compute displacement between each pair.\n",
        "    displacement = np.reshape(points_gt, (n_gt, 1, n_nodes, n_ed)) - np.reshape(\n",
        "        points_pr, (1, n_pr, n_nodes, n_ed)\n",
        "    )\n",
        "    assert displacement.shape == (n_gt, n_pr, n_nodes, n_ed)\n",
        "\n",
        "    # Convert to pairwise Euclidean distances.\n",
        "    distance = (displacement ** 2).sum(axis=-1)  # (n_gt, n_pr, n_nodes)\n",
        "    assert distance.shape == (n_gt, n_pr, n_nodes)\n",
        "\n",
        "    # Compute the normalization factor per keypoint.\n",
        "    spread_factor = (2 * stddev) ** 2\n",
        "    scale_factor = 2 * (scale + np.spacing(1))\n",
        "    normalization_factor = np.reshape(spread_factor, (1, 1, n_nodes)) * np.reshape(\n",
        "        scale_factor, (n_gt, 1, 1)\n",
        "    )\n",
        "    assert normalization_factor.shape == (n_gt, 1, n_nodes)\n",
        "\n",
        "    # Since a \"miss\" is considered as KS < 0.5, we'll set the\n",
        "    # distances for predicted points that are missing to inf.\n",
        "    missing_pr = np.any(np.isnan(points_pr), axis=-1)  # (n_pr, n_nodes)\n",
        "    assert missing_pr.shape == (n_pr, n_nodes)\n",
        "    distance[:, missing_pr] = np.inf\n",
        "\n",
        "    # Compute the keypoint similarity as per the top of Eq. 1.\n",
        "    ks = np.exp(-(distance / normalization_factor))  # (n_gt, n_pr, n_nodes)\n",
        "    assert ks.shape == (n_gt, n_pr, n_nodes)\n",
        "\n",
        "    # Set the KS for missing ground truth points to 0.\n",
        "    # This is equivalent to the visibility delta function of the bottom\n",
        "    # of Eq. 1.\n",
        "    missing_gt = np.any(np.isnan(points_gt), axis=-1)  # (n_gt, n_nodes)\n",
        "    assert missing_gt.shape == (n_gt, n_nodes)\n",
        "    ks[np.expand_dims(missing_gt, axis=1)] = 0\n",
        "\n",
        "    # Compute the OKS.\n",
        "    n_visible_gt = np.sum(\n",
        "        (~missing_gt).astype(\"float64\"), axis=-1, keepdims=True\n",
        "    )  # (n_gt, 1)\n",
        "    oks = np.sum(ks, axis=-1) / n_visible_gt\n",
        "    assert oks.shape == (n_gt, n_pr)\n",
        "\n",
        "    return oks"
      ],
      "metadata": {
        "id": "CSHr435pcvMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inference(model, device, X, xv, yv):\n",
        "  model = model.to(device)\n",
        "  _ = model.eval()\n",
        "  X = X.to(device)\n",
        "  with torch.no_grad():\n",
        "    y_preds = model(X)\n",
        "    peaks = find_peaks(y_preds.cpu().permute(0, 2, 3, 1).numpy(), xv.numpy(), yv.numpy())\n",
        "\n",
        "  return peaks\n",
        "\n",
        "def clip_peaks(peaks):\n",
        "  for p in peaks:\n",
        "    out_of_bounds = np.logical_not(np.logical_and(np.all(np.where(0 <= p, True, False), axis=1),\n",
        "                                                  np.all(np.where(p <= 160, True, False), axis=1)))\n",
        "    p[out_of_bounds, :] = np.nan\n",
        "\n",
        "  return peaks\n",
        "\n",
        "def get_match_scores(all_y_preds, all_y_gt, stddev=0.25):\n",
        "  match_scores = []\n",
        "  for i, j in zip(all_y_gt, all_y_preds):\n",
        "    oks = compute_oks(i, j, stddev=stddev)[0][0]\n",
        "    match_scores.append(oks)\n",
        "\n",
        "  return match_scores\n",
        "\n",
        "def evaluate(\n",
        "  match_scores,\n",
        "  num_positive_pairs,\n",
        "  num_false_negatives,\n",
        "  recall_thresholds,\n",
        "  match_score_thresholds,\n",
        "):\n",
        "\n",
        "  precisions = []\n",
        "  recalls = []\n",
        "\n",
        "  npig = num_positive_pairs + num_false_negatives  # total number of GT instances\n",
        "\n",
        "  for match_score_threshold in match_score_thresholds:\n",
        "\n",
        "      tp = np.cumsum(match_scores >= match_score_threshold)\n",
        "      fp = np.cumsum(match_scores < match_score_threshold)\n",
        "\n",
        "      rc = tp / npig\n",
        "      pr = tp / (fp + tp + np.spacing(1))\n",
        "\n",
        "      recall = rc[-1]  # best recall at this OKS threshold\n",
        "\n",
        "      # Ensure strictly decreasing precisions.\n",
        "      for i in range(len(pr) - 1, 0, -1):\n",
        "          if pr[i] > pr[i - 1]:\n",
        "              pr[i - 1] = pr[i]\n",
        "\n",
        "      # Find best precision at each recall threshold.\n",
        "      rc_inds = np.searchsorted(rc, recall_thresholds, side=\"left\")\n",
        "      precision = np.zeros(rc_inds.shape)\n",
        "      is_valid_rc_ind = rc_inds < len(pr)\n",
        "      precision[is_valid_rc_ind] = pr[rc_inds[is_valid_rc_ind]]\n",
        "\n",
        "      precisions.append(precision)\n",
        "      recalls.append(recall)\n",
        "\n",
        "  precisions = np.array(precisions)\n",
        "  recalls = np.array(recalls)\n",
        "\n",
        "  AP = precisions.mean(\n",
        "      axis=1\n",
        "  )  # AP = average precision over fixed set of recall thresholds\n",
        "  AR = recalls  # AR = max recall given a fixed number of detections per image\n",
        "\n",
        "  mAP = precisions.mean()  # mAP = mean over all OKS thresholds\n",
        "  mAR = recalls.mean()  # mAR = mean over all OKS thresholds\n",
        "\n",
        "  return precisions, AP, mAP, mAR"
      ],
      "metadata": {
        "id": "U3MLxrqQRdfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation Code"
      ],
      "metadata": {
        "id": "jKbaoESL0jgx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from matplotlib import pyplot as plt\n",
        "\n",
        "# fig, (ax1, ax2) = plt.subplots(1, 2, frameon=False)\n",
        "# ax1.imshow(X[0].cpu().permute(1, 2, 0).numpy(), cmap=\"gray\")\n",
        "# ax2.imshow(X[0].cpu().permute(1, 2, 0).numpy(), cmap=\"gray\")\n",
        "# ax1.scatter(all_y_preds[0][:, 0], all_y_preds[0][:, 1])\n",
        "# ax2.scatter(all_y_gt[0][:, 0], all_y_gt[0][:, 1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "iIA4Sp94gr77",
        "outputId": "d378a24f-7efc-4151-bed7-e6855f69a55c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f73b7eaeb60>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xv, yv = make_grid_vectors(\n",
        "    image_height=160,\n",
        "    image_width=160,\n",
        "    output_stride=2\n",
        ")\n",
        "\n",
        "# Get all y_preds and y_gt.\n",
        "all_y_preds, all_y_gt = [], []\n",
        "_ = model.eval()\n",
        "for x in val_dl:\n",
        "  peaks = inference(model, device, X, xv, yv)\n",
        "  peaks = clip_peaks(peaks)\n",
        "\n",
        "  all_y_preds.append(peaks)\n",
        "\n",
        "  out_of_bounds = np.where(np.all(np.isclose(gt_kp.cpu().numpy(), 0), axis=1))[0].tolist()\n",
        "  gt_kp[out_of_bounds, :] = np.nan\n",
        "  all_y_gt.append(gt_kp)\n",
        "\n",
        "all_y_preds = np.concatenate(all_y_preds, axis=0)\n",
        "all_y_gt = np.concatenate(all_y_gt, axis=0)\n",
        "\n",
        "# Define thresholds.\n",
        "match_score_thresholds = np.linspace(0.5, 0.95, 10)\n",
        "recall_thresholds = np.linspace(0, 1, 101)\n",
        "\n",
        "# Get evaluation metrics.\n",
        "match_scores = get_match_scores(all_y_preds, all_y_gt)\n",
        "precisions, AP, mAP, mAR = evaluate(match_scores, 400, 0, recall_thresholds, match_score_thresholds)"
      ],
      "metadata": {
        "id": "89r928d3WcwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mAP"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rA_guHXjxQM",
        "outputId": "5d5090bd-e97f-45ed-a866-07b2559b166c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7393531379546477"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precisions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TG3kqGsdjx2b",
        "outputId": "1bccf5ba-309f-442d-d86b-c753b40ba2f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 1.        , 1.        , ..., 1.        , 1.        ,\n",
              "        1.        ],\n",
              "       [1.        , 1.        , 1.        , ..., 1.        , 1.        ,\n",
              "        1.        ],\n",
              "       [1.        , 1.        , 1.        , ..., 0.985     , 0.        ,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [1.        , 1.        , 0.83028721, ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.57142857, 0.57142857, 0.30769231, ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SxZ_rL0I_AHX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}